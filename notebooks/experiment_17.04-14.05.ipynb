{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## История изменений"
      ],
      "metadata": {
        "id": "9tW38cLZdMsW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj-6qLnHBiH1"
      },
      "source": [
        "\n",
        "\n",
        "#### Базовый эксперимент\n",
        "\n",
        "1. Что сделано.\n",
        "  \n",
        "  - Загружен датасет GSM8K\n",
        "\n",
        "  - Проведено обучение qwen2.5-0.5B на датасете GSM8K-main на трех эпохах\n",
        "\n",
        "2. Полученные результаты\n",
        "\n",
        "  - Обученная модель с данными лоссов на обучающей выборке\n",
        "\n",
        "3. Выводы\n",
        "\n",
        "  - Предельное значение количества параметров - 500M, так как даже для обучения qwen2.5-0.5B на датасете 3 тысячах объектов GSM8K-main понадобилось 10 GB GPU и нельзя было использовать `batch_size > 3`.\n",
        "\n",
        "  - Обучение больших моделей на сравнительно небольшом объеме данных занимает до часу времени. (личный вывод)\n",
        "\n",
        "\n",
        "4. Чему научился\n",
        "\n",
        "  - Пользоваться интерфейсом HuggingFace\n",
        "\n",
        "  - Библиотека transformer, datasetы\n",
        "\n",
        "  - Лучше изучил задачу text generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Вычислительный эксперимент: обучение Qwen lora_r = 8\n",
        "\n",
        "1. Что сделано.\n",
        "  \n",
        "  - Настроен пайплайн обучения через trl, использование SPIN\n",
        "\n",
        "  - Обучена модель Qwen2.5-0.5B с `lora_r = 8`, на двух итерациях метода SPIN.\n",
        "\n",
        "2. Полученные результаты\n",
        "\n",
        "  - Обученная модель с данными лоссов на обучающей выборке\n"
      ],
      "metadata": {
        "id": "3i8njJOSdOdB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4HNpQyhBXiq"
      },
      "source": [
        "## Библиотеки\n",
        "\n",
        "В этой секции будут описаны базовые библиотеки, используемые практически для всех экспериментов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers peft\n",
        "! pip install datasets trl hf-xet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NxcdOSrRXPHp",
        "outputId": "10a5b428-ca05-4c20-c50c-c070ff77f3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting trl\n",
            "  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: hf-xet in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.17.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 trl-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRepUj0TBml2",
        "outputId": "ea769061-c5ed-4df3-ce29-3b9a64b473ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# basic libraries\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "from peft import LoraConfig, PeftModel, get_peft_model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmlk18XMLhyi",
        "outputId": "ea35c47f-e5bf-4ac3-ed93-1e1d58b68c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmHarWI5bGYO"
      },
      "source": [
        "-----------------\n",
        "## Датасеты\n",
        "\n",
        "На данный момент используются датасеты:\n",
        "\n",
        "- gsm8k: main и socratic\n",
        "\n",
        "- ultrachat_200k: train_sft и test_sft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mh0Ez74bI1X"
      },
      "outputs": [],
      "source": [
        "datasets = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5f4518db013f47ba8f016731e8bafaee",
            "603174f1cf664768a03c634a679545cf",
            "92914d1d4cc141fa8ab75b645353055e",
            "87182e8fd02b4ed596cf935f6510289c",
            "fd53a31116d44d8590c455ab1445a02d",
            "5c43048129d64db1bd7daf64cab84460",
            "0f42fba990ac4885bcea2c2b3acc00b0",
            "205a1af6d9e546728a07b60401a9a5c8",
            "9c3d54b1be9c4043bf56a018e2b11a28",
            "643fe7f0af394d38aea9c42baf7ef2d7",
            "c8bb4057ec2c4620939c9a503be0b4d7",
            "fa81d75047f347fb900b141a19d4d62c",
            "23302160b0d6478f9d238a4d55c8be07",
            "9cd09181f59a433bb395c5ca83a7c1c8",
            "254241a8d89249a8b4757de5aacedcc8",
            "80e073d2b22e479c8d24aa2738fe5322",
            "173d3010db714e3fb1ff2582ba2b1ff8",
            "d86d87f222e44c86bcd3e66d2c2744ba",
            "44624ec41b0d4ba694b6fbb1a7c59a50",
            "df201a1ea6cf4b7c821f28365f90eb06",
            "a9c3f143688e41978b8b7761d2f4e9a4",
            "7adb7c8cab2a4802ad7fee84d732291d",
            "3512374e48124836a4c5a50cefa8afa4",
            "5f8c064eab514909aff4c668b6303869",
            "ad677f5bb6bc4b3094d3db6b3648dbb6",
            "2089b8ffde5846d8afe931d879f2ca29",
            "d14d10fa1b5b4f01b33af2216a70130d",
            "3bcd3fa67cf74aa2b877f34db4eb0146",
            "4369939f51634591bc805ff77e376820",
            "c6660f38e3e94d84b63da62d34a07054",
            "432834a28b484871a52ce6c143383a80",
            "3659bc79773d4ed1879b9fa8275267c5",
            "e9769e0332a74ab0913295b99e33e646",
            "a674d5c5241e4714980f679f024b5976",
            "89a5a3b298a4494088c2c9c929c7efaf",
            "6a01c29cfcb24eff9658c2aaeb4cbb47",
            "4ec9185604af49788f88467d2b7cea8a",
            "acb981d824404a1caf0c8b38f5c78003",
            "c10cdb1fd1ca4fe394bebded8961efb5",
            "008aaa00f4cc4393a985ead019f88f86",
            "e5a4756cafef4312b228f1166438072c",
            "5fb0d7a7f5bf4e71aeaeadeec02dc381",
            "9bec6458ad5f4d1ca0333971e7828681",
            "dc6e4820e1df47b8bd7c5469b0ec3a64",
            "ae1ffec497f5438a86b954f73831b934",
            "e2c04e62b1464118bfdaa2287d3c505c",
            "da1d16c6626f435fa5748398a07828b5",
            "b4fa8cd6894b4c6fbd69680bf48faa3b",
            "db6f686722d241e8a808e6c58939a623",
            "429362dc369e47938429dbb3bfdff66b",
            "8052e131d26c40ae9e51a7a4c760d8ba",
            "215a2212d1084bd1aa44673698feda65",
            "dd54a46d12874d699940636f51a333a5",
            "219d364b27fb42349fe77aabbd8d8714",
            "a943c0d1f6804cf7b5a13f4f3bc65f45",
            "b1dda09d93db4713bf9e415d70c75033",
            "1717dbfb76534dd4891639e2effcf051",
            "8e188c07cf74402ab562f8c0c5004ce9",
            "28ddac5738bb43028601c7867def334f",
            "bf5c6b5e5f064f3c9f33f4a0abe7a2e7",
            "70e6c5742edf4f40bcffd5f41a5b1c88",
            "f642280d8a27493a95b0221219c4f15f",
            "a31c38377bf34953bc591c246f95e765",
            "165a0752484a4a3bb7d3c662d5550a3e",
            "aca2f295cd8e4de09f96cbb2157c9ee3",
            "e53567ab10574686af47650ffe59fe76",
            "4c64b4b51815468c9832d4e3312f0375",
            "a010d598a4774b5abef66193d6dfe0c0",
            "b20ac6056b7545de8c3709aedf18fcf2",
            "18bde319cc514cea997706d9f10d1dec",
            "1111c2c9964f49f583a97cb3e6aea956",
            "2bc5d1beebe44f5080a55209f0fc28ec",
            "dbba694433864af28e2aa51ecf556802",
            "0e0d4db60dae4916b6da11ddd3c0390b",
            "04ac5116eaa7479280da8a0b3ac2bc39",
            "13dae3fb7fbb4ec692923794ed6979bd",
            "cd07779102544e42b311bb05b0af0bf9",
            "cf631a93cd584ad78d12b2c0e20f426a",
            "c8dbf2bc65a04b8a82c271176a428b3a",
            "4d27cea275dc404c9610144711b7b55b",
            "775cd8af5ae8478aabfe144772be7021",
            "9695fc6bc6bc4fe7af76f714ad155466",
            "d6c98936ebe146978a69f944957a738a",
            "4d33d796bf134f4e9b695a510599ef3b",
            "67b06d226dee44468510342c3541f34c",
            "a32675f2952742c8810d885030afcd3f",
            "6f22a29fc97f4d29926d162dbb658d3d",
            "0c392623c4314fc590ecdfc1bedc63bc",
            "36a720e2791d4c559ef5f95009f4997c",
            "7e63ac12eaf34d808c2a04f77c03519e",
            "0bcfb8c55e3c4c19bb8a63ceb736f676",
            "281d360a51f647a6adc89c5a7ba64e88",
            "6ded1ac78f204c698fe70b83c0373863",
            "43fc86122ee24a478c107d5139bbe6fe",
            "be5bbf67fe074e7993f47d6cb622db4a",
            "e9c14e8c8fdd4cf3a4fb496a709fc8b5",
            "318ede025c4e4b0f937409a40df714f0",
            "a56639be934b406c8fe4ddaf14de79a6",
            "3394522336b6454fa58b4ea1cfe41f67"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "JOljcDDXbPQ_",
        "outputId": "156ffc22-bba1-45b6-c47a-62da0b5a04f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f4518db013f47ba8f016731e8bafaee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa81d75047f347fb900b141a19d4d62c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3512374e48124836a4c5a50cefa8afa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a674d5c5241e4714980f679f024b5976"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae1ffec497f5438a86b954f73831b934"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.68M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1dda09d93db4713bf9e415d70c75033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/487k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c64b4b51815468c9832d4e3312f0375"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf631a93cd584ad78d12b2c0e20f426a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36a720e2791d4c559ef5f95009f4997c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "datasets['gsm_main'] = load_dataset(\"openai/gsm8k\", \"main\")\n",
        "datasets['gsm_socratic'] = load_dataset(\"openai/gsm8k\", \"socratic\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['uchat_train'] = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split='train_sft[:1%]')\n",
        "datasets['uchat_test'] = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split='test_sft[:1%]')"
      ],
      "metadata": {
        "id": "6c145GQwJDKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "4cc0cf80f4aa4cbabed4eebf3ac8af02",
            "c54ce85f5a324d2a9053c9dda910fa11",
            "77ceec90adc44a36a85fe1ef976b72f9",
            "ce03b09fee624e17aec23fd73736a3f1",
            "340837bbe79f48e0a396b2bb3d334ea7",
            "53473547fd7d4b4a92bbbecd379def23",
            "4e778c4fc7034e49b5e985d9e0f7c8e2",
            "0c7cef2021d74963bc5ded0b1593feb8",
            "06705d048dae430ab025c8a0933e9223",
            "65b27e10917d4784ba40792e16c7234b",
            "b1610d8f56fc480f939110acc060829a",
            "129109f6cf2c4c2b850aa844ab133911",
            "69a11b64c19a4cd7a7e6f850372fe22d",
            "c53cc8a5d02041179bb84d30b44af9f4",
            "ce83278fff8e42a48a623b59d70ecc8c",
            "d6a2ba39f506497a8833dc35bf9594e2",
            "79b8ee9619a243aa9f47b83b5832ab3f",
            "bcef9db476474ef990f0d086af8364c2",
            "508bfa67bc7d4a87a5d30fcffa1b73c6",
            "a9bd5c74f53b4e26937d01264e6eca2a",
            "811a1a5f66fd4b9cbd913a608cd42071",
            "4575b6c1063a43d395e042c79c29ba5b",
            "14d2ae52b0e9481d87ecd0a1dc2151ad",
            "df67f546be3746618dbee09ba9c062c8",
            "a11bcb37f6714f63a40918566c2ad424",
            "cb6568d89ee6436d99642cec6d10ce08",
            "0873f799b8154173abc96f7b9136e41a",
            "6eb34d00b5cb4320862f0d7464279b54",
            "0c10203fdd2e459690ec4cc44eb450a4",
            "85461f29f85e46898f337742dbf2e413",
            "99eaa1a0749448a58c440d4ec8a68f05",
            "6c2cb64e65fa4bf2a98f0901b448a043",
            "46b44b011afb4aaa8575dea429b9314d",
            "8670eec6bea1440fb3c79e7356d0bc6b",
            "eab5cc1ca16c4fa5ab5bb7061f215c2b",
            "2932c37098a74f68b8a64968ddf894be",
            "303c5205fc50450bb953c449ec9f6003",
            "2bf36dd3bcc44621a2147da13248f572",
            "717b7ce100784145a7ae693ae46c9844",
            "039ee33d882a4497975403fe5188efe3",
            "312cda29b4aa40d18e3ead3617e91bfe",
            "f838b196d37f4924b80027c003580ceb",
            "7537213b3cd643d599ab704d7258aa13",
            "fea2665bc3de421bb58e9c7f6144a6e8",
            "d5486ed2b2d74f23b74c5133f995fa87",
            "8d3bd8193b3b4c6ead3cd81c68be3603",
            "0909e9d2790b4ecc844158a37e2306c4",
            "86151317d7084977be22798cf5038dec",
            "50bff602a2bc45548fa153047a76468b",
            "57e307d5d31241a68eec3770fdd59bed",
            "e33340525234469aa134e1f14b8a4ef9",
            "d6ae457c88324cf98aaea7529a8c26ac",
            "33ca7c514296401d8158e17faf841c79",
            "701ad11494004bafb6a9a1727fcacbc4",
            "b06983b4847943e993d6fb5438384cf2",
            "f06f58424b7d4545be10c50a76cc90f5",
            "18cb0a858002426dae97635cfd915604",
            "2cbd9d7dd57e46d7a231b5c3c6b646d9",
            "84e77de13d854a2da2d9321512cc6d21",
            "b79e665908b6443b9143a35d869bf226",
            "0f891becbf5c44f491af8123195b16bf",
            "1c54a1d03cc041efa577f526872ed18a",
            "6a81a5fbbebc446a8e81a3b3d62b6724",
            "945f78ab75d14e3f9ba5300063af1a78",
            "eef7657d34c14e5c8802a1280e42ab39",
            "da6c38cf81d64f86968e44e7970934a6",
            "f7b1e06be0054e5084a22ad1cb5cec90",
            "f62737c6f3004af58b000dd0eeccab31",
            "82fed2b25087428dac4f24ab10fdb304",
            "a27dcaed95034de1b8d62b83803333c0",
            "5cdbbffbd86f4bfaaacb9132754bddd5",
            "d3284dd64069437e95c50ca3a3b6aec3",
            "270a629ca0e348bbbe65fac72e134859",
            "e644e591056d45cdb2dc84040c43a344",
            "8d02ececb04b4c9aa028182a22f7a7f9",
            "6b9fe853ce8243ce8fd2f573b8ffcab9",
            "6caa0f5d1b6d407f838e88f0690a7b7f",
            "7ead27161f8f454c989816ffccf884c4",
            "edeee90b44ab42cb9cd21235fdcd8000",
            "f3c268f412fb485285b40d6c208a1753",
            "08680b03bf194c7c8aa421d14ba363a5",
            "619afd85a80f454494996df7839cf744",
            "b264557294794e2a8b002a2ac0831b89",
            "ec55df8b446343ee8b258493f77bff22",
            "3f554659d4244b278a2054bd27bf3521",
            "5977003e876f4cd9a951b71298a5aa48",
            "2662da3cf9714128adeb4158004afbc6",
            "e6b9c981a4104240b0f0a37087795edc",
            "b8c95fbcff8043f485f937a04c18edc6",
            "9d9fbaf1e32b4f06a36b5dd00eb2af65",
            "bc260a702ecb4525838afc021f65b771",
            "ac74f6a8ae6447a9a03cdd90e4bcac3a",
            "64b771abd79641bd91e2bc85729da97a",
            "fffc4d9e34f2423fa62b8eeededccfb4",
            "0e8032231547496493f15c714eaa74b3",
            "56f1c86a02924e058e4d387443d802e5",
            "62a6d504dee34a66bfc904275eb21f68",
            "305f8d3e9b594be1ab2a3691b41b2dae",
            "6c672ee3af2c4b309951a9882e0ab5da",
            "b6f7fc4eba8c4ed9b9715ea34d7deadd",
            "474cfcdc6c154a70b0673fa3e5d125b7",
            "5900747e4650400695b8e7f6608c4205",
            "4720a751ab2f47cb9af7a747cf9e7871",
            "2d6ddaf50bec44ccb7ee0fa3ecd7bb4c",
            "b7e489bf56c34020b651723dd5497571",
            "c5307deb99be419a847aa63d88a5255b",
            "56b831d4073e40c398874905c80df9be",
            "50e1a323a2874941b185112e21d52fef",
            "f6e96d3e57f54e25bbdb8db340d092cb",
            "1349a0e1d1434532ba6f2063b7cf0f5b",
            "fb0c4b479a184d4daf9ea881ee2b224b",
            "3e24b6114cb44c9abe6b5c9cc933503f",
            "5708d3e5e6404806b6eeb1703c5c2c26",
            "3e302d58b7294c95ab325501e424a726",
            "7ba78dbd7bea4967b1b2657bba6ce81e",
            "a5b5a575829d423899842d8081935aa1",
            "1420649a21c04885bf4d167b64d787df",
            "1c858caa1750400b8d3374d57e4389ca",
            "86d77fd7f1be4402a7e29e0063d87da1",
            "9a7b6869201740c8a30d7a56d4bf983d",
            "0b0dbc1c191f4f0f8970be475022095c",
            "5db220faea264a6997a488ce0eee0b71",
            "75ba3b78a7c14dd6adca43006b87420a",
            "57faec1e2a6749e98caebeeac60c0757",
            "c1b425f2698044c19998a3ca634bb8ab",
            "f1aed59fee2c461c98b21a3961a3fd1c",
            "caf6e946ff8841cdbd4726999a2fae29",
            "c577b7605fef4dd099495036c9183c26",
            "5b2611b89b134906a102580fc0378783",
            "9e5e4a513dc145439256f35b0a43d161",
            "b4c71b9cd8d74022bd48569893db7f55",
            "4b19e986d6ae4f10a0609af5b62b6079",
            "c6f03755c4974eb4a6461c5bdbd87807",
            "97c3b5cb5d73424d96d855d8b7be39d4",
            "248008561e6441d898d427afa6a48057",
            "5521a044a60e46eaa1fa14cd37b50ab1",
            "df28826c487b4322aed8c0a9ca524ebb",
            "71e31ca5e79c4300b50f237a42daacfe",
            "cce90975169c482ca345f27e67a6b6bc",
            "ba8d82417af14abaa4233338beeb9326",
            "9f388351b238498d93bee8f6df74df1a",
            "431a088340804fd89e9bf96ab3f970e1",
            "6844400476e64d24bf068183bee54948"
          ]
        },
        "outputId": "468deb46-c847-46b2-a4a7-d7254932eac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cc0cf80f4aa4cbabed4eebf3ac8af02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00003-a3ecf92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "129109f6cf2c4c2b850aa844ab133911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00001-of-00003-0a1804bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d2ae52b0e9481d87ecd0a1dc2151ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00002-of-00003-ee46ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8670eec6bea1440fb3c79e7356d0bc6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-f7dfac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5486ed2b2d74f23b74c5133f995fa87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00003-a6c9fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f06f58424b7d4545be10c50a76cc90f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00001-of-00003-d6a0402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7b1e06be0054e5084a22ad1cb5cec90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00002-of-00003-c0db75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ead27161f8f454c989816ffccf884c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-3d4cd8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8c95fbcff8043f485f937a04c18edc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6f7fc4eba8c4ed9b9715ea34d7deadd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0c4b479a184d4daf9ea881ee2b224b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db220faea264a6997a488ce0eee0b71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f03755c4974eb4a6461c5bdbd87807"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCBKC7p0ai4X"
      },
      "source": [
        "--------------\n",
        "\n",
        "## Обучение моделей\n",
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnw5A6UQJLbV"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "549yHdnVao1w"
      },
      "source": [
        "#### Qwen 2.5-0.5B only LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AavNxUoxcbnx"
      },
      "source": [
        "Обучим модель Qwen2.5-0.5B, используя только адаптеры LoRA для получения бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "3ab65d926acf4f518a1bea898683dc26",
            "c59740bf40ab4e9c8a2bb1a9037f7111",
            "a07ae49134c94bc1ad1c1357cd35752e",
            "bc1a23a65d9a4d7aa5cefff997800f74",
            "a23e1aa224084e84a5f26fadcece5d64",
            "3c2d5d0a8fca4bdcb511fcad7dfabeb5",
            "fe9d5ebd66e942fd9703391952dc741a",
            "c3574e8c76a8491eaeca4a2ab4446e99",
            "4bc4e20ccd884074bf12adbd96cabc43",
            "23a3d492e4434564a3554f88e71bed58",
            "7196aa0a5ae244a18ceab58176881225",
            "36f6c9f2be664c73be0355af2d3de4ab",
            "257623bbd53b4f71b6cc226b3fcccfbb",
            "fef49f363a354fafb249d4fae77a5fd5",
            "cb783b4e62634034893f4b25db87177e",
            "3bf8128e58f94ae3899ccd993e77e291",
            "26d803c3fbee44dbb9cc624d9ddc3111",
            "53ee87eb5d2944bf8db3ac4b9e409c5e",
            "f8a46dfa6bf34a6083a126be3fadfc69",
            "00e64bb1a98b4e67951b693a63be12d7",
            "aa1581cfff1943aea43f8c36ecb80fcb",
            "9a50f09d31844b2cb4456a1a015fc019"
          ]
        },
        "id": "8-5vSikpDMCp",
        "outputId": "9b45036f-ff54-491c-9dd3-8bde799e7b0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ab65d926acf4f518a1bea898683dc26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36f6c9f2be664c73be0355af2d3de4ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1abd2ce4e3f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Подгружаем токенайзер и модель\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Qwen/Qwen2.5-0.5B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Qwen/Qwen2.5-0.5B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 )\n\u001b[0;32m-> 1008\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m                     \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m                 resolved_vocab_files[file_id] = cached_file(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                     \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    959\u001b[0m         )\n\u001b[1;32m    960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1673\u001b[0m                     \u001b[0;34m\"For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 )\n\u001b[0;32m-> 1675\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1676\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Подгружаем токенайзер и модель\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LtH8vTz5YgK",
        "outputId": "87941aa9-c3b1-406b-f565-1b2034c4d46d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь поработаем с данными, а именно нужно токенизировать и провести padding"
      ],
      "metadata": {
        "id": "2Dxf6u0RYFfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkFM1WoGdWMj",
        "outputId": "3a8070c3-0873-4cb7-aba0-ae8088f7a178"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer'],\n",
              "    num_rows: 7473\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "datasets['gsm_main']['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gS2-lsbd3qA",
        "outputId": "acfaa309-8150-40a1-818a-de731b7892bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
              " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "next(iter(datasets['gsm_main']['train']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0\n",
        "for text in datasets['gsm_main']['train']['question']:\n",
        "    max_length = max(max_length, len(text))\n",
        "tokenizer.model_max_length = max_length"
      ],
      "metadata": {
        "id": "wmBoWNdFYM0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как Qwen2.5-0.5B использует примерно 2.1 Gb памяти и оставшейся памяти не хватает для обучения, то сократим размер датасета вдвое."
      ],
      "metadata": {
        "id": "1nOhppcWdse3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "47e9f7ca50f547618825e60d207abc51",
            "9020dce0628e40fdbe89ed59eaa4ecf2",
            "c827704c72cb4fb0bb4d8bf0c62d98d2",
            "b00e578121cd42af88cb77543940fd0f",
            "624321bc7c404aa79f2575a49950cd49",
            "76b37b26202946e283a22df66aab676e",
            "e3be7df0b8af4598b3807c8fe38ca93e",
            "d59aa8f81b9545c58c25f34de09087a5",
            "0676b7582963499b8f9c865e6008ab21",
            "6e048d44bdb441d880dabc655a08c005",
            "68187f0b7a0c4f18bba2568c706eeabf",
            "e754f83a39cf44c6942e9c48a8fc5b0b",
            "5a4f3e484ced4ab09fdd0b71be9e31a4",
            "cb5ccc20dc35446693ea42be8604b2ae",
            "1b98bb69c60a4d358aa65ae8049e56c2",
            "da0396b78e1a430e9c1b410a5aadb5b6",
            "1460d5bd1e0144b783ba0e16bcbee139",
            "42eee685f16e4aa59e5575a4d5cbc9a8",
            "0170a2d3d8aa4b1fa71e5666116fef4c",
            "3fddd0734b584a58a9e36111564aa8d8",
            "030ef5e4b90c493cac58dbf92a556dbc",
            "1cae6794fa004cb0863e301ba7a73d6d"
          ]
        },
        "id": "65UyTMAlcq6l",
        "outputId": "0d591822-37a5-4af1-fc7d-6136be6825c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47e9f7ca50f547618825e60d207abc51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e754f83a39cf44c6942e9c48a8fc5b0b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Преобразование данных\n",
        "def format_row_qwen_gsm(elem, tokenizer):\n",
        "    messages = [{\"role\": \"user\", \"content\": elem['question']}]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    answer_ids = tokenizer(\n",
        "        elem['answer'],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )['input_ids'].to(device)\n",
        "    inputs['labels'] = answer_ids[0]\n",
        "    inputs['input_ids'] = inputs['input_ids'][0]\n",
        "    inputs['attention_mask'] = inputs['attention_mask'][0]\n",
        "\n",
        "    return inputs\n",
        "\n",
        "def format_dataset_qwen_gsm(dataset, tokenizer):\n",
        "    return dataset.map(lambda elem: format_row_qwen_gsm(elem, tokenizer))\n",
        "\n",
        "\n",
        "# Ограничение датасетов\n",
        "train_size = 3000\n",
        "test_size = 1000\n",
        "train_dataset = Dataset.from_dict(datasets['gsm_main']['train'][:train_size])\n",
        "val_dataset = Dataset.from_dict(datasets['gsm_main']['test'][:train_size])\n",
        "\n",
        "# Токенизация\n",
        "train_dataset = format_dataset_qwen_gsm(train_dataset, tokenizer)\n",
        "val_dataset = format_dataset_qwen_gsm(val_dataset, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8GXItV_voNx"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.remove_columns(['question', 'answer'])\n",
        "val_dataset = val_dataset.remove_columns(['question', 'answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W86Cqm4dkpbq",
        "outputId": "a0ea71d5-9ed9-4a6b-8e72-69c702626a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 737,280 || all params: 494,770,048 || trainable%: 0.1490\n"
          ]
        }
      ],
      "source": [
        "# настройка параметров Лоры\n",
        "lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]\n",
        "    )\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDVZTfKwlT2d"
      },
      "outputs": [],
      "source": [
        "account = \"MuQianyu\"\n",
        "peft_model_id = f\"{account}/qwen2.5-0.5B_only_lora\"\n",
        "batch_size = 2\n",
        "\n",
        "args = TrainingArguments(\n",
        "    peft_model_id,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-3,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=10,\n",
        "    label_names=[\"answer_ids\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIt-onQxzdSB"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "8rtRobf_mpNL",
        "outputId": "4fff58b3-5aee-47e8-fb0e-8565e5bd7b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-b3f53e6d1164>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmu_qianyu\u001b[0m (\u001b[33mmu_qianyu-mipt\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250320_002203-qapodojw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mu_qianyu-mipt/huggingface/runs/qapodojw' target=\"_blank\">MuQianyu/qwen2.5-0.5B_only_lora</a></strong> to <a href='https://wandb.ai/mu_qianyu-mipt/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mu_qianyu-mipt/huggingface' target=\"_blank\">https://wandb.ai/mu_qianyu-mipt/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mu_qianyu-mipt/huggingface/runs/qapodojw' target=\"_blank\">https://wandb.ai/mu_qianyu-mipt/huggingface/runs/qapodojw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 1:39:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.769000</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.906200</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=1.1117058957417807, metrics={'train_runtime': 5989.6674, 'train_samples_per_second': 1.002, 'train_steps_per_second': 0.501, 'total_flos': 1.271721100032e+16, 'train_loss': 1.1117058957417807, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем обучить еще на одной эпохе"
      ],
      "metadata": {
        "id": "oOYkV-g4wOJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    peft_model_id,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-3,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=10,\n",
        "    label_names=[\"answer_ids\"],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Yc-MR1xXSUj4",
        "outputId": "80a3f248-7adc-48bf-8a83-4522026977c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-da16a88a45a4>:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 49:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.737700</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=0.7162192662556967, metrics={'train_runtime': 2965.7117, 'train_samples_per_second': 1.012, 'train_steps_per_second': 0.506, 'total_flos': 6358605500160000.0, 'train_loss': 0.7162192662556967, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('qwen2.5-5b__gsm__only_lora', from_pt=True)"
      ],
      "metadata": {
        "id": "QfTAGgJId59u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "results = [0.769000, 0.906200, 0.737700]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.title('График обучения qwen2.5-0.5B')\n",
        "plt.xlabel('Номер Эпохи')\n",
        "plt.ylabel('Train loss')\n",
        "plt.plot(np.arange(1, 4), results, label='qwen2.5-0.5B_only_lora')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "9nvZhLrfhnga",
        "outputId": "126fa3c3-8fd7-4a5d-bfae-19da216003ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def color_map_color(value, cmap_name='YlOrRd', vmin=8, vmax=15):\n",
        "    # norm = plt.Normalize(vmin, vmax)\n",
        "    norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
        "    cmap = cm.get_cmap(cmap_name)  # PiYG\n",
        "    rgb = cmap(norm(abs(value)))[:3]  # will return rgba, we take only first 3 so we get rgb\n",
        "    color = matplotlib.colors.rgb2hex(rgb)\n",
        "    return color"
      ],
      "metadata": {
        "id": "ZCyVes0waXuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib\n",
        "results = [0.769000, 0.906200, 0.737700]\n",
        "train_time = np.array([2995, 5990, 8955]) / 3600\n",
        "memory_usage = [10.5, 10.7, 10.3]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.title('График обучения qwen2.5-0.5B')\n",
        "plt.xlabel('Время обучения (часы)')\n",
        "plt.ylabel('Train loss')\n",
        "plt.ylim([0.7, 0.95])\n",
        "plt.xlim([0, 4])\n",
        "plt.plot(train_time, results, label='qwen2.5-0.5B_only_lora')\n",
        "\n",
        "for result, time, memory in zip(results, train_time, memory_usage):\n",
        "    plt.annotate(\n",
        "        f'Memory: {memory} Gb\\nLoss:{result}\\ntime: {time:2f}',\n",
        "        (time, result),\n",
        "        textcoords=\"offset points\",\n",
        "        xytext=(0,10),\n",
        "        ha='center',\n",
        "        fontsize=10,\n",
        "        color=color_map_color(memory)\n",
        "    )\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "O0UrJdHIX7s_",
        "outputId": "c20d7e0d-739b-42d7-a5dd-c81761286c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-b1fd6ab1578b>:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = cm.get_cmap(cmap_name)  # PiYG\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAIjCAYAAADC/VtFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqAtJREFUeJzs3Xd4VGX2wPHvnfTeO4FAaAlVAiJNFIIoih3FhqJrx8baV8Wyiq6uDbtiWXX9KepiRwEBaYqA9IQaSkJ6Jb3M+/vjzUwyJCEJJMwkOZ/nmQfmznvvPTOUOXnbMZRSCiGEEEIIB2WydwBCCCGEEMciyYoQQgghHJokK0IIIYRwaJKsCCGEEMKhSbIihBBCCIcmyYoQQgghHJokK0IIIYRwaJKsCCGEEMKhSbIiRBdTUlLCoUOHyM/Pt3coQgjRIpKsCNEFLFiwgIkTJ+Lj44O3tzfdu3fnX//6l73DEkKIFpFkRTisDz/8EMMwmnykpqae1Hi8vb257rrrTuo928KDDz7IZZddho+PD++++y6LFy9myZIl3HbbbfYOTbSRP//8k1mzZjFgwAC8vLzo3r07l112Gbt27WrR+cf6t5aRkdHiOObPn09cXBzu7u706dOHefPmtei85cuXN3n/33//3aZtTEyMzeuWe913333k5eW1OFbRsTjbOwAhmvPkk0/Ss2fPBscDAwPtEE3HsmLFCp577jnmzp3Lgw8+aO9wRDt57rnnWL16NdOmTWPw4MFkZGTw2muvMWzYMH7//XcGDhzYous09m/N39+/Ree+/fbb3HLLLVxyySXMnj2blStXcuedd1JaWsoDDzzQomvceeedjBgxwuZY7969G7QbOnQof//73wEoLy9nw4YNvPzyy6xYsYJ169a16F6ig1FCOKgPPvhAAerPP/+0dyhKKaW8vLzUtddea+8wWuW8885To0ePtncYop2tXr1aVVRU2BzbtWuXcnNzU1dddVWz55/ov7XS0lIVFBSkzj33XJvjV111lfLy8lJ5eXnHPH/ZsmUKUAsWLGj2Xj169GhwH6WUuvfeexWgdu3a1brgRYcgw0Ciw7N0Yf/222/cfPPNBAUF4evry4wZMxpMIv3mm28499xziYyMxM3NjdjYWJ566ilqamps2pnNZu677z78/PyIiYlh0aJF1tceeOABfHx86NOnDz/99JPNeddddx0xMTE2xw4dOoSHhweGYbB//37r8ZiYmAbDSjfddBPu7u4sX7682ff966+/Mm7cOLy8vPD39+eCCy4gKSnJpo3lp+rp06cTGBiIh4cHI0aMYOHChdY2xcXFeHl5cddddzW4R2pqKk5OTsydO7fJ9wdgGAaPP/64zbG0tDSuv/56wsLCcHNzY8CAAbz//vs2bSzd/19++WWDax497Gb5c67/GZrNZgYPHoxhGHz44Yc253/55ZcMHz4cHx8fm2GDF154ocG9jrZ9+3YmTJiAh4cH3bp145///Cfvv/++zf1nz55NUFAQql7h+jvuuAPDMHj11VetxzIzMzEMgzfffNN6rKKigjlz5tC7d2/c3NyIjo7m/vvvp6KiwiYOwzCYNWsWCxcuZODAgdbPsf7fR4DRo0fj6upqc6xPnz4MGDCgwd+J5hw5cqTBv4fmLFu2jNzc3AZDi7fffjslJSX88MMPrbp/dXV1q+4PEB4eDoCzswwYdEaSrIhOY9asWSQlJfH4448zY8YMPv30Uy688EKbL5MPP/wQb29vZs+ezSuvvEJCQgKPPfZYgyGS5557jhdeeIELLriAe+65h3vuuYfKykp++OEHNm7cyNNPP42HhwcXX3wxKSkpx4zrscceo7y8vNn458yZw/z58/nkk08444wzjtl2yZIlTJ48maysLB5//HFmz57NmjVrGDNmjM2XeW5uLu+88w4//PADt956K3PnzkUpxcUXX8xnn30G6KTgoosu4vPPP2/wJfXZZ5+hlOKqq65qNv76MjMzOe2001iyZAmzZs3ilVdeoXfv3txwww28/PLLrbrWsXz88cds3bq1wfG1a9dy2WWXUVNTw7PPPsvHH3/MSy+91KJrZmRkcOaZZ7Jp0yYefPBB7r77bv7zn//wyiuv2LQbN24ceXl5bN++3Xps5cqVmEwmVq5caXMM4PTTTwd0gnX++efzwgsvMHXqVObNm8eFF17ISy+9xOWXX94gnlWrVnHbbbcxffp0/vWvf1FeXs4ll1xCbm7uMd+HUorMzEyCg4Nb9L4BzjzzTHx9ffH09OT8889n9+7dLTrvr7/+AmD48OE2xxMSEjCZTNbXmzNz5kx8fX1xd3fnzDPPZP369Y22q6qqIicnh5ycHFJTU/nuu+948cUXOf300xsdMhadgF37dYQ4hpZ2TVvaJSQkqMrKSuvxf/3rXwpQ33zzjfVYaWlpg/Nvvvlm5enpqcrLy5VSSpWXl6vQ0FB1xRVXWNts3rxZOTk5qSFDhli723NycpSPj4+66667rO2uvfZa1aNHD+vzbdu2KZPJpM455xwFqJSUFOtrPXr0sA4rvf322wpQ8+bNa/ZzUUqpoUOHqtDQUJWbm2sTo8lkUjNmzLAeAxSgli9fbvMZxMXFqfDwcOvn9fPPPytA/fTTTzb3GTx4sBo/frz1+cyZM1X37t0bxAOoOXPmWJ/fcMMNKiIiQuXk5Ni0mz59uvLz87P+ORyr+//oYTfLn7PlMywvL1fdu3e3frYffPCBte1DDz2kAJWenm49lpKSogD1/PPPN7hXfXfffbcC1B9//GE9lpWVpfz8/Gzun5WVpQD1xhtvKKWUKigoUCaTSU2bNk2FhYVZz73zzjtVYGCgMpvNSimlPv74Y2UymdTKlStt7vvWW28pQK1evdp6DFCurq5qz5491mObN29u0d+Vjz/+WAFq/vz5x2ynlFKff/65uu6669RHH32k/ve//6lHHnlEeXp6quDgYHXw4MFmz7/99tuVk5NTo6+FhISo6dOnH/P81atXq0suuUTNnz9fffPNN2ru3LkqKChIubu7q40bN9q07dGjh/Xvdf3HmDFjGvx9E52H9KyITuOmm27CxcXF+vzWW2/F2dmZH3/80XrMw8PD+vsjR46Qk5PDuHHjKC0tJTk5GYCtW7eSlZXFxRdfbG07ePBg3N3dGTp0qLW7PSgoiNNPP52lS5c2GdNDDz3EsGHDmDZtWpNtvvnmG2677Tbuu+8+Zs2a1ez7TE9PZ9OmTVx33XU2k4wHDx7MpEmTbN4vwIgRIxg/frzNZ3DbbbeRkZHBxo0bAUhMTCQyMpJPP/3U2m7btm1s2bKFq6++2nosNDSUrKwsKisrm4xPKcVXX33F1KlTUUpZfwLOyclh8uTJFBYWWu9rYfmzqP9ozuuvv05ubi5z5sxp8NqRI0cwmUwtnhxa348//shpp53Gqaeeaj0WEhLSoHcpJCSE/v3789tvvwGwevVqnJycuO+++8jMzLT2SqxcuZKxY8diGAagl5HHxcXRv39/m/c7YcIEQA+p1JeYmEhsbKz1+eDBg/H19WXfvn1Nvofk5GRuv/12Ro0axbXXXtvse77sssv44IMPmDFjBhdeeCFPPfUUP//8M7m5uTz99NPNnl9WVtZgGMrC3d2dsrKyY54/evRovvzyS66//nrOP/98HnzwQX7//XcMw+Chhx5q0H7kyJEsXryYxYsX8/333/P000+zfft2zj///GbvJTomSVZEp9GnTx+b597e3kRERNgMi2zfvp2LLroIPz8/fH19CQkJsX4ZFxYWAnqOCUBUVFSz94yKirK2P9qqVav47rvveO6556xfVEfbtGkTV1xxBTU1NS1ednngwAEA+vXr1+C1uLg4cnJyKCkpsR7r379/o+0A62djMpm46qqrWLhwIaWlpQB8+umnuLu72yRao0ePpry8nEceeYTU1NRGE4vs7GwKCgp45513CAkJsXnMnDkTgKysLJtzrr/++gZt67+HoxUWFvLMM88we/ZswsLCGrw+atQozGYzd911F3v37iUnJ6fFm+AdOHCgwd8laPzzHjdunHWYZ+XKlQwfPpzhw4cTGBjIypUrKSoqYvPmzYwbN856zu7du9m+fXuD99u3b99GP5vu3bs3uG9AQECT7ycjI4Nzzz0XPz8/vvzyS5ycnFr0vo82duxYRo4cyZIlS6zHsrOzycjIsD6Ki4sBnQA3lcCWl5fb/JDQUr179+aCCy5g2bJlDYYng4ODSUxMJDExkXPPPZeHH36Y9957jzVr1vDee++1+l7C8clMJNFlFBQUMH78eHx9fXnyySeJjY3F3d2djRs38sADD2A2mwFaNL+kvqZ+knvggQeYPHkyEyZMaDD502Lz5s2cc845TJw4kfvuu4+rr7662fkqrdGaL4kZM2bw/PPPs3DhQq644gr++9//ct555+Hn52dtc/7553P99dfz/PPP8/zzzzd6HcvnePXVVzf5U/3gwYNtnj/22GM2X+gAU6dObTLW5557DpPJxH333dfo3I3p06ezceNG5s2bxzvvvNPkdU7U2LFjeffdd9m3bx8rV65k3LhxGIbB2LFjWblyJZGRkZjNZpv3ZjabGTRoEC+++GKj14yOjrZ53lSyoerNxbIoLCzknHPOoaCgwHr/ExEdHc3OnTutz0eMGGFNlkHPs3r88ceJiIigpqaGrKwsQkNDra9XVlaSm5t73HFER0dTWVlJSUkJvr6+x2w7ceJEAH777TfuuOOO47qfcFySrIhOY/fu3Zx55pnW58XFxaSnpzNlyhRArzzJzc3l66+/tk52BBpMkI2IiADg8OHDzd4zLS2t0f+IFy5cyNq1axsMdxxt0KBBLFiwAA8PDxYsWMBNN93Eli1bcHd3b/KcHj16ANh8iVgkJycTHByMl5cXAD179myyHWCzsmfgwIGccsopfPrpp3Tr1o2DBw82uqnX/Pnzeeyxx9i7d681MZk0aZL19ZCQEHx8fKipqSExMfGY799i0KBBDdo29SV9+PBhXnnlFebOnYuPj0+jyYrJZOKFF15g69atpKSk8MYbb5CZmWkzpNWUHj16NDqxtLHP0ZKELF68mD///NM6Ufv000/nzTffJDIyEi8vLxISEqznxMbGsnnzZiZOnNhkj9vxKC8vZ+rUqezatYslS5YQHx9/wtfct28fISEh1ueffvqpTXLeq1cvQO97ArB+/XrrvzfLc7PZbH39eO7v7u6Ot7d3s20tK4gsvT2ic5FhINFpvPPOO1RVVVmfv/nmm1RXV3POOecAdV9+9X8irays5I033rC5zogRI/Dw8OB///uf9diWLVsoLy9n06ZN1u7uvLw8fvvtN5vEB6CmpoaHH36YK6+8stn/pIcNG4aXlxcmk4n33nuP/fv38+STTx7znIiICIYOHcpHH31EQUGB9fi2bdv45ZdfbL4spkyZwrp161izZo31WHl5OW+++Sbh4eE2X6IA11xzDb/88gsvv/wyQUFB1s/uaD169GDChAnWrvj6nJycuOSSS/jqq6/Ytm1bg3Ozs7OP+f6a88QTTxAWFsYtt9xyzHbz5s3j119/5dNPPyUxMZExY8a06PpTpkzh999/t9lcLDs722Y+j0XPnj2JioripZdeoqqqynqPcePGsXfvXr788ktOO+00m+W0l112GWlpabz77rsNrldWVnbM4a+m1NTUcPnll7N27VoWLFjAqFGjmmybnp5OcnKyzb+Vxv5MfvzxRzZs2MDZZ59tPTZmzBjrn3liYqI1WZkwYQKBgYE2y7NB/xv09PTk3HPPtR7LyckhOTnZOtzY1P03b97Mt99+y1lnnYXJ1PxX1XfffQfAkCFDmm0rOh7pWRGdRmVlJRMnTuSyyy5j586dvPHGG4wdO5bzzz8f0PMtAgICuPbaa7nzzjsxDIOPP/64QXe6Zc+RZ599FmdnZ4YNG8Zbb72FyWQiPT2dc889l/PPP5/33nuPiooK7r33XpvzU1NTcXV1bTDRtTkDBw7kgQce4Nlnn2X69OkNhkrqe/755znnnHMYNWoUN9xwA2VlZcybNw8/Pz+b/U7uv/9+Pv30U8455xzuvPNOgoOD+eSTT9ixYweffvppgz0prrzySu6//37+97//ceutt9pMWG6NZ599lmXLljFy5EhuvPFG4uPjycvLY+PGjSxZsuSEtkX/5Zdf+PTTT5uc0Al6btL999/P448/3mBH1Obcf//9fPzxx5x99tncddddeHl58c4779CjRw+2bNnSoP24ceP4v//7PwYNGkRAQABQl4Tu2rWLK6+80qb9NddcwxdffMEtt9zCsmXLGDNmDDU1NSQnJ/PFF1/w888/N1gC3Jy///3vfPvtt0ydOpW8vDw++eQTm9fr9yg99NBDfPTRR6SkpFh71kaPHs0pp5zC8OHD8fPzY+PGjbz//vtER0fz8MMPN3t/Dw8PnnrqKW6//XamTZvG5MmTWblyJZ988glPP/20zUTw1157jSeeeIJly5ZZhzwvv/xyPDw8GD16NKGhoezYsYN33nkHT09Pnn322Qb3S0tLs77HyspKNm/ezNtvv01wcLAMAXVWdl2LJMQxtHbp8ooVK9RNN92kAgIClLe3t7rqqqtslvYqpZdInnbaacrDw0NFRkaq+++/37psd9myZdZ2VVVV6u6771Y+Pj6qe/fuatGiRdaltA888IDy9vZWvXr1Ut9++63N9a+99loF2Cxnrh9jU0uXLcrLy1X//v3ViBEjVHV19THf95IlS9SYMWOUh4eH8vX1VVOnTlU7duxo0G7v3r3q0ksvVX5+fsrd3V2NGDFCLVy4sMnrTpkyRQFqzZo1x7x/fRy1dFkppTIzM9Xtt9+uoqOjlYuLiwoPD1cTJ05U77zzjrXN8SxdHjp0qHUZsFJ1S5ItS5fLy8vV4MGD1dixY20+w5YuXVZKqS1btqjx48crd3d3FRUVpZ566ik1f/78Bn+GSin1+uuvK0DdeuutNscTExMVoJYuXdrg+pWVleq5555TAwYMUG5ubiogIEAlJCSoJ554QhUWFlrbAer2229vcP7Rf3fGjx/f6HJey6M+y9/R+u/jH//4hxo6dKjy8/NTLi4uqnv37urWW29VGRkZzX5W9b3zzjuqX79+ytXVVcXGxqqXXnrJ5s9KKaXmzJnT4N/bK6+8ok499VQVGBionJ2dVUREhLr66qvV7t27G33v9d+byWSybjVQf4m36FwMpRqZpSVEB/Lhhx8yc+ZM/vzzz1b/RNoa3t7eXHrppU1Olu0sLrroIrZu3cqePXvsHYpDsfw9q98jIYQ4OWTOihDCKj09nR9++IFrrrnG3qEIIYSVzFkRQpCSksLq1at57733cHFx4eabb7Z3SEIIYSU9K0IIVqxYwTXXXENKSgofffSRtSicEEI4ArvPWXn99dd5/vnnycjIYMiQIcybN89mm+v6qqqqmDt3Lh999BFpaWn069eP5557zmZp3eOPP84TTzxhc16/fv2s+0oIIYQQomOxa8/K559/zuzZs5kzZw4bN25kyJAh1kqyjXnkkUd4++23mTdvHjt27OCWW27hoosualDRc8CAAaSnp1sfq1atOhlvRwghhBDtwK49KyNHjmTEiBG89tprgN6GOjo6mjvuuMO6E2R9kZGR/OMf/+D222+3Hrvkkkvw8PCwrrl//PHHWbhwIZs2bTop70EIIYQQ7ctuE2wrKyvZsGGDTUVNk8lEYmIia9eubfScioqKBtuQe3h4NOg52b17N5GRkbi7uzNq1Cjmzp3baDGw+tetqKiwPjebzeTl5REUFNSm22ELIYQQnZ1SiiNHjhAZGdmi3YdbelG7SEtLa3Tjqfvuu0+deuqpjZ5zxRVXqPj4eLVr1y5VU1OjfvnlF+Xh4aFcXV2tbX788Uf1xRdfqM2bN6tFixapUaNGqe7du6uioqImY7FsUiQPechDHvKQhzza5nHo0KG2SRiUHTeFO3z4MFFRUaxZs8amjsX999/PihUr+OOPPxqck52dzY033sh3332HYRjExsaSmJjI+++/32Tl24KCAnr06MGLL77IDTfc0Gibo3tWCgsL6d69O4cOHWq20qcQQggh6hQVFREdHU1BQYFN1fYTYbdhoODgYJycnMjMzLQ5npmZ2eSyyZCQEBYuXEh5ebm17PiDDz5oLabVGH9/f/r27XvM3Tjd3Nxwc3NrcNzX11eSFSGEEOI4tOU0CrutBnJ1dSUhIYGlS5daj5nNZpYuXXrMiqEA7u7uREVFUV1dzVdffcUFF1zQZNvi4mL27t1LREREm8UuhBBCiJPHrkuXZ8+ezbvvvstHH31EUlISt956KyUlJcycOROAGTNm2EzA/eOPP/j666/Zt28fK1eu5Oyzz8ZsNnP//fdb29x7772sWLGC/fv3s2bNGi666CKcnJy44oorTvr7E0IIIcSJs+t2+5dffjnZ2dk89thjZGRkMHToUBYtWkRYWBgABw8etJlJXF5eziOPPMK+ffvw9vZmypQpfPzxx/j7+1vbpKamcsUVV5Cbm0tISAhjx47l999/JyQk5GS/PSGEEEK0AbvvYOuIioqK8PPzo7CwUOasCCGEEK3QHt+hUhtICCGEEA5NkhUhhBBCODRJVoQQQgjh0CRZEUIIIYRDk2RFCCGEEA5NkhUhhBBCODRJVoQQQgjh0CRZEUIIIYRDk2RFCCGEEA5NkhUhhBBCODRJVoQQQgjh0CRZEUIIIYRDk2RFCCGEEA5NkhUhhBBCODRJVoQQQgjh0CRZEUIIIYRDk2RFCCGEEA5NkhUhRJegDixBfX+5vcMQQhwHZ3sHIERHoza8BIeWQszZGENn2b62+U1I+QGiJ2Ik3GOnCNuf2vI25O6AIwfAOxpjwryGbQpTYMubkL8b3Pyg13kYfS5t+poHlsBfLzf+4jmfYLj5N31u9hbY8z/I3wnVZeAeBAF9oOe5GMEDW/nuhBCORpIVIY6HRwikrkQNuhHDyQ0AVVMJqcv1aw5IKQXKjGFyapsL9pikk4PC/Q3vVVUKax6FkKEw5HYo2g9/vYpy8caIObvx63UbB2EJtsc2vgQ1lcdOVPb9AFvegugzYcQD4BUBVSWQswW2vgtnvnK871AI4SAkWRHiePjFQmk6HF6jvyRB/94jBDzDbZoqZYbdX8L+n6E8H7wjod90jKix+vXsLbD6YRj1BOz4CI6kQmB/GHE/FOyBre9BeS6EnwpD78Bwdtfn1VTB9vch9TeoLgX/PjDobxgBfY+67uOw42MoOgBDZ6H+egXGv4gR0Kcuxj3fwN6FcNZ8DKP50WFj8M36vKTCRpMVUpeDuRqG3YVhcgHfHrqnZc9CaCJZMZzcoDbxA1AVhZC9BU65s8k4VGmWTkhiz8cYdKPti349Ub3Ob3jO4bX6cyvLgeCBMPRODE/HTDCFEJrMWRHieHWfBAeX1D0/uFgfO9quBXDwVxhyG0x8A2IvhA3/RuVstW2X/F8YfAuc/jyUZcO6Z2HvNzD8PjhtDmT9Bfu+r2u//X04vBoS7oEzXtE9CmseQ1Uesb3u9g9hwHWQ+CZEjNS9HfXjtsaeiGGYUD9fj0r69Pg/F4C8JAgaqBMVi9BhUJyKqixu2TUOLtXJS9SYptscXgOqGpoYXjIMw/ZATQXs+gISZuvPuaoE1v+rZfEIIexGkhUhjlf0mZC7A1WapX/Cz02C6DNsmqiaKv3lOOwujLAEDK9wjB6J+tz9i2yvF38NRlA8hn8s9DgLcrfBkNsx/GP1vIvI0XpoA1DV5ZDyEwy4HiNsOIZvdzjlDnByhQO/2F437mqM0FMwvCIwXH0g5ixIXaFjA1TBHt3r0j1Rt/cKBzffE/tsygvA3d/2mGUopyK/Zdc4uBiix1uH2RpVnAbOnhjuAdZDKm016rtL6x71e35UNQy+BSMwDsO/Nwy7B/KSUPk7WxaTEMIuZBhIiONkuPmhwkboXgqlIHy4Pla/Uclh/dP86kdtj5urwb+X7QV9e9b93s0fnNwwvOoNKbkF6MmqACXp+os3KL4uHpMzKqAvHDlke13/3rbPI06DzW9C+hroNl73YAQPwvAK09cZ+0wrPoX2ofKS9PtI+HsLWh/VexI2DM58VQ+drXoIlLleUyc98dby1Cca5eKlh94C+rVN8EKINifJihAnosckPbkT9BDO0arL9a+j5ugVKvXVHyIB/UVa9wSMRv551v/ibSknd9vbmFxQ0RPg4BJU5GhIXQFHz/c4Ue7+unelvora524BNGv/L+DXS/d+HIt3JFSXoMrzrb0rhrMHeHugjDaaSCyEsDsZBhLiRIQNA3OV7ikJG9bwdZ9onZSUZmN4R9o+TmRSp1cEmJz18uFaylyte158ujd/fsxkyNoM+34Ec40eYmpLgXGQu03HZJH9F3h3w3D1PuapqroMDq/SiWBzIsfopG73ly2LS9VAwe66p0dS9bwVn24tO18IYRfSsyLECTAMJ9TEt6y/b/C6iyeq98Ww7T0USg/bVJXo+S0unhjdJx7ffZ3dUTFTYPv7KFcfvQpp91d6yKnHWc2f7xONCuwHOz6A7pNs5oWoVQ9D5CiMXlObPF8VH9a9RhX5YK5EFezTL/hG60m13cbrCcN/vYLqc6meE7P3W5seHHV4Dez4D0biW7YXT12pE6huZzb/PjxDUQNvgK3v6InF3RPBMwyqjsChZbWN6v1MZjjDlrdRg24Gk5MeDgvohyFDQEI4NElWhDhBhovnsRvEXa0nrO5aACUZ4OIF/rHQ97ITu/GA6wAFG/6tN0Lz7wOjn2y258KqxyS9aufoHoySDKgoOva5f72qJwBbLK9dXjxpPniFYbh4oUY/pTeFW343uPpCvyts91ipKoXi1IbXPviLTpZa+D6M2Kkon2jY+z9YN1cv43b10cu/Rz2B4RdT19jJTa8cWv+8ntMSNOCYS6OFEI7BUEqp5pt1LUVFRfj5+VFYWIiv7wmuihDCQankz+DwaowJr9k7FCFEJ9Ie36EyZ0WILkZVl6GK9uuyAL3Os3c4QgjRLBkGEqKr2fwWpK2AiFEtm8QqhBB2JsmKEF2MkXCP3vVWCCE6CBkGEkIIIYRDk2RFCCGEEA5NhoGEsBO14SWoKsE47RH7xqEUJH+qq0JXlUBQHAy5DcM7qulzqkoh6RNIXwsVhbp0wKCbrBWfW3NdlfEn7PxMV292coGgQdbPRBXug11fQt4OvZzaMxR6noMRe0G7fBZCCMckyYoQXd3ur2Dvd3oei2eYTkLWPIaa+CaGk2vj52yapzd6S/g7uAfqDdhWP4Ka+AaGR3CLr6vSVutrxc+AkCF6M7gjB+ruU7AH3Pz0fTxC9L4wm15DGaZjblonhOhcJFkRwgGpnK2w7X0oSgEXH+g+EeKuwTDpXXJV2irdG1Gcrjc68+8FIx/VO9tmb4HtH8CRg3rHVt/uMPw+DM/QhvdRCvZ+A/0ux4g4TR9LmA0/Xa17TbqNb3hOTQUcXq3vFzxQH4y7CpWxTleCjr+mRddV5hrY+o6uHB1Tb9dd37pyAcbRu/F6haPykuHwWpBkRYguQ5IVIRyMKsuBtY/rreMTZuuKwJvm6RpDcVehyvP0DqwDZurlx9VlkLsdUDoB+ONpXftnxP26ZlH+rrprl2TC4htgzDMYIYOhNFNvmR8y1NrGcPFCBfSDvORGkxXMNbqgotNRhRid3GrjoGXXLdyjd5E1DNSyO6E8H/x6wcCZGL4xTX9AVSXQ0l16hRCdgiQrQjialB/1kMfgWzAMA3yidYKy40NU/yugPE8X5IscXddbUrulvKo8AtUlED4CwytCv+YTXXdtkxN4dwPn2lpA5fn6V3d/2xjc/OuqJB/FcPFEBfaH5P9DeUfrc1N/00mId0TLr1uSoX9N/i8M/Bt4hcGe/8Gqh1GJb2O4+jS4t8pNgrSVuoq1EKLLkNVAQjiaI4cgsL9OVCyC4nQPSlkO+PXU8zt+vR21bi5q/yJUZTGA/oLvnqjnhqx9ArX3G53o1DI8gjES3zrxwn0Jf9e//nwtfHuRLlLY7XTAOOZpNiyVPvpdjhE1BsO/N5xytz6Wtqph86L98MdT0P8KjNBGKlwLITot6VkRooMxDCfU6H/qyaZZf8G+72HHx6jx/8bwCscYdjeq11TI2qB7IZI+QY1+CiOwf8OLuQfoX8sL9ERZi4oCnRQ1FYNXBIx7FlVdDtWlGO6BqD+fA6/wll/Xcrxez4/h5ILyCoeybJv7qaKDsPoRiDkbo9/0Zj8jIUTnIj0rQjgan2jIS8amxmhuEjh7QO1KG8MwMILiMeKugjNfAZOznrhay/CPxeh7GcbpL4BPd0hd0fi9PMPALQCyN1kPqapSyN+pqxY3w3B214lKZTFkboTaybQtuq5/bz0P50haXRtzNZRm6SXKlmNFB2D1wxA9ASN+RrMxCSE6H+lZEcKeqktQBftsj8WcrVfSbHkL1es8KE7T+5XEXohhmFB5OyF7M4Seopf15u+CykI9t6UkA/YvgoiR4B4ExalQkq5XE1E7eXf1I5BwD0ZAPwzDQMVeALs+R3lH1S0xdg/Uk3drqVUPQ+Qo63JhlblBv+Adpa+/7X3w6aaHoKBF1zVcPFEx50DypyjPYPAIhT1f6+tGjtX3KdoPq/4BocOg90Uoy1wYw4Th5tcOfyBCCEckyYoQ9pSzFZbfaXusx1kw6nGdACy7Qy9d7nEWWIY/XDwhd5tOaKpLdS/EwBswwobrL/PiVFj3K1QWgVsg9DxXJ0CgV/IUp0J1Rd39+lwCNeV6xVFVCQTFw+gnbfdYKcnQm7JZVJfC9o+gPEfHFzka4mdgmJxbd92B1+tJvxtehJoKCOgHY57GsKz2SVutE7HUZfph4REKk98/7o9dCNGxGMqmr1kAFBUV4efnR2FhIb6+vvYORwghhOgw2uM7VOasCCGEEMKhSbIihBBCCIcmyYoQQgghHJokK0IIIYRwaJKsCCGEEMKhSbIiRDtS2VtQC8+zbocvhBCi9WSfFSHaiFr5IPj1whh8U93BoDg4+2Nw8bJfYLVUTSVsel1XOz5yCMJOxTjtkZadm/En7PwMCvfrastBgxqcqw4sgb0L9SZ2zp4QNRZjyK36tSOpsPl1fd+qEr05XLczdJ2fenuzqD3fwP4foTQb3HwhcgzEX2vdm0WpGkj6L6Qu18US3QP1hnf9pltrKanyfNj+IWT/Vbu/ywAYfDOGd9QJfoJCCHuRZEWIdmSYXOrq5NibMoOTK/SaCofXtPy0tNV6Y7f4GbqAorkGjhywbbPnf7pi8oDrIbAfVJfrbfMtTM4QPQH8Y8HFGwpT9DUxQ/y1+hqHlsOOD+GUuyAwDkrSYOPL+vxBN+pfd30F+3+CYffoMgIFu+GvV3QyGHu+LlHwxz/1/UY+opOmvQth9SOoiW9iOLsf54cnhLAnSVaEaANqw0t6V9ncbah93+qDk+ZDaaauazPl/zBcvXXvw9Z3YfjfYdt8XUU5LAGGzYbDqyHpU6gu0V/sg/6GYTjp69dUQdJ/dI2fqhLw7QHx12GEDG5xjIazOwy9XV8vN0lfp7n3Za6Bre/AgOsxYs6qe8G3e12bymK9lf5pj2KEDK1rU68QouEVXlfkEMAzFJWzBXK31x3LS4LAOIzoM/RzrzBU1Om6nED9NuEjMcJH1LVJ/a2uTclhXX9owusYvj10fENug5+u0Z9dzORm37MQwvFIsiJEWxh8k+4J8OkBcVfrY26+Olk5Wk0F7P0Oht8P1WWw7hlY97TucRj1OJRm6GOBcdDtdH3Oljf1EMrw+8EjCA6vhbVzUBNesw5vqIXnwSl3Y/RIbLv3VbgHynPBMFDL7tRDL369YOBMDN8Y3Sb7L91rU5aLWnKLfk+BcboEgGdIo5dVxYchayNEjK47GBgHh5aj8ndiBPTTdY4y1+vErX6b/YtQxWkY3lGown2QtwMG3lD72VbpX+tt6W8YJpSTC+TukGRFiA5KkhUh2oDh4oUynMHJDaPesE+jtSxUNQy9DcMrQj+NHA2HlsE5n2A4e4Bvd1TwYMjZAt1OR5VmwcElcNYHGB5B+hp9LkZlbdDHa4dR8O6m6wa1pZIM/Wvyf2Hg38ArTA/3rHoYlfg2hquPbqMU7Fqgh2tcvCDpY1jzKGrCPD0UZnnrv90LBXvBXKXrFcVdZX3NiD4DVVkEvz2AQoGqgZhzMPpdVhdP30t1XaIlt6AMk06S4q/BiD5Tv+7TDTxCYPtHqKGzwNkN9nyje7Aq8tr2sxFCnDSSrAhxsjm5WRMVANwCwDNMJyrWY/5QUah/X3RAfykvudk2+TFXgWtd3Q0j8a22j9VSOqzf5RhRY/ShU+6Gn6+FtFXQ8xzdRlXD4JswQofpNsPv10Mv2Vv0MJfF8Ad0z0tRii7U6PU19LlUn5O9BXZ9AUNu1QUNSw7D1ndRyZ9h9L9Cn5+2Uk+uHX6v7sUq3KfbuAdhdJ+IYXJGjfwHbHwFfpwOhglChuoYpAqaEB2WJCtCnGxGI//sauem1DtQlyhUl+kv3TNe1r/WVz/BaQ/ugfpXn+i6yJxcUF7hUJZd26a2J8mnbh6L4eaHcvOta2M5bhkW8u2OUmbY9Bqq90V6bk7yJxA9AcMyVOMXg6qp0G36XY5hmGD7B9DnUoxu4+valGXpXp3uE/U9/HvDhHmoqhIwV+tYVswG/z5t+9kIIU4a2WdFiLZictE9IG3NP1Zft6IAwzvS9tHeK438e+v3dSTNekiZq/VKH89QfSAoXv9anFrXpvIIVBTVtWmMMoO5ul5SVgG1y4+trMlZ/Tamhm0a+dwNFy+dqBSnQf4eiBjZ3LsVQjgo6VkRoq14hkL+TlRJJji7g6tPm1zW8I5CdTsDNr6EGniDnuBaWQjZm8G3p3VljFpyC8TPwIgc3eS1VNFBnSBUHYHqMlTBPn0P/1769fydsOElGPNPDI9gDBdPVMw5kPwpyjMYPEJhz9f6YpFj6+ILPw22vIMaege4eMD2j/T8kWC9WkkdWqaXE/vG6OSnYDfs+AiixtXtsxJ+KuxdiPLrVTsMlK5XGYWfal0VRfipsPNzlEeI7skp3At7FkKPSXXvMW2VHh7zDIWi/bDlHYg4zTpEJYToeCRZEaKt9LkYNrwIv96mV/xMmt921x52N+z8vHa5c65eaRTQD8JOrWtTnApVpce+ztrHoaze/ifL79S/Xvi9/rW6Ql/HXFPXZuD1YHLS762mQt93zNMYrt51bRJm6yXZvz8OmCB4IIx6oi4RMZxg15d6HopSOpHodR7EXlh3jX7Tdc9K0ie179FPJydx19S1GXyzfn3zG3pOj3sgxJwD/afXtSnPg23vQXmBHqKKnmD7uhCiwzGUUjLt7ChFRUX4+flRWFiIr69v8ycIIYQQAmif71CZsyKEEEIIhybJihBCCCEcmiQrQgghhHBokqwIIYQQwqFJsiKEEEIIhybJihBCCCEcmiQrQgghhHBokqwIIYQQwqFJsiKEEEIIhybJihBCCCEcmiQrQogGjpRXsWD9IcqrappvLIQQ7UwKGQohGnj82x18tTGVQ/llzJ7U197hCCG6OOlZEULYKCqv4vsthwFYtC3dztEIIYQkK0KIo3y/OZ2KajMAuzKLOZBbYueIhBBdnSQrQggbX6w/BICTyQBg8Y5Me4YjhBCSrAgh6uzOPMKmQwU4mwxuGd8LkGRFCGF/kqwIIawWbEgF4Mz+oUwf0R2AP/fnkV9Sac+whBBdnCQrQggAqmrMfL1RJyuXDY8mOtCT/uE+mBX8mpxl5+iEEF2ZJCtCCACWJWeRU1xJsLcbZ/QLAeCs+DAAliTJUJAQwn7snqy8/vrrxMTE4O7uzsiRI1m3bl2TbauqqnjyySeJjY3F3d2dIUOGsGjRohO6phBCswwBXTwsChcn/V/DpPhwAFbsypYN4oQQdmPXZOXzzz9n9uzZzJkzh40bNzJkyBAmT55MVlbjXc6PPPIIb7/9NvPmzWPHjh3ccsstXHTRRfz111/HfU0hBGQdKbcO9UxL6GY9PjDKl3Bfd0ora1i7N9de4Qkhuji7JisvvvgiN954IzNnziQ+Pp633noLT09P3n///Ubbf/zxxzz88MNMmTKFXr16ceuttzJlyhT+/e9/H/c1hRCw8K80asyKU7r70yfMx3rcMAwS40MBWCxDQUIIO7FbslJZWcmGDRtITEysC8ZkIjExkbVr1zZ6TkVFBe7u7jbHPDw8WLVq1XFf03LdoqIim4cQXYVSigXr9RDQtIToBq9bhoKW7MjEbFYnNTYhhAA7Jis5OTnU1NQQFhZmczwsLIyMjIxGz5k8eTIvvvgiu3fvxmw2s3jxYr7++mvS09OP+5oAc+fOxc/Pz/qIjm74H7YQndWmQwXszirG3cXEeUMiGrx+Wq9AvN2cyTpSwZa0QjtEKITo6uw+wbY1XnnlFfr06UP//v1xdXVl1qxZzJw5E5PpxN7GQw89RGFhofVx6NChNopYCMdnmVh7zsAIfN1dGrzu5uzE+L56ddDiHU0n/UII0V7slqwEBwfj5OREZqbtOHhmZibh4eGNnhMSEsLChQspKSnhwIEDJCcn4+3tTa9evY77mgBubm74+vraPIToCsoqa/huky5aOG14tybbTbIsYd4hE9WFECef3ZIVV1dXEhISWLp0qfWY2Wxm6dKljBo16pjnuru7ExUVRXV1NV999RUXXHDBCV9TiK5o0fZ0jlRUEx3owWk9g5psd2a/UJxMBjszj3Awt/QkRiiEEHYeBpo9ezbvvvsuH330EUlJSdx6662UlJQwc+ZMAGbMmMFDDz1kbf/HH3/w9ddfs2/fPlauXMnZZ5+N2Wzm/vvvb/E1hRB1LBNrLx0Wjam2cGFj/DxdODUmEIBfZChICHGSOdvz5pdffjnZ2dk89thjZGRkMHToUBYtWmSdIHvw4EGb+Sjl5eU88sgj7Nu3D29vb6ZMmcLHH3+Mv79/i68phNAO5ZWyZm8uhgGXJEQ1235SfBhr9+WyJCmTv43rdRIiFEIIzVBKyVrEoxQVFeHn50dhYaHMXxGd1ouLd/Hq0t2M6xPMxzeMbLb9obxSxv1rGU4mgw2PJOLv6XoSohRCdDTt8R3aoVYDCSHahtms+Kp2FdClCU1PrK3PUtiwxqyksKEQ4qSSZEWILmjN3lzSCsrwdXdm8oCmV8odzbIqaPEO2c1WCHHySLIiRBf0xXq9l9AFQ6Nwd3Fq8XmWZEUKGwohTiZJVoToYgpLq1i0Xa/oOdbeKo0ZFOVHmK+bLmy4TwobCiFODklWhOhivt1ymMpqM/3DfRgU5deqcw3DIDFOhoKEECeXJCtCdDELaoeApg2PxjCa3lulKZahoKVJUthQCHFySLIiRBeSnFHEltRCnE0GFw6NPK5rjIoNwsvVicyiCrZKYUMhxEkgyYoQXYhlx9rEuDCCvN2O6xpuzk6M72cpbChDQUKI9ifJihBdRGW1mf/9lQbAZSNaN7H2aLKEWQhxMkmyIkQX8WtyFnkllYT6uHF6n5ATupYUNhRCnEySrAjRRVgm1l48rBvOTif2T9/f09Va2HBxkvSuCCHalyQrQnQBWUXlLN+VDbR+b5WmJFqHgqQKsxCifUmyIkQX8PVfadSYFQk9AogN8W6Ta55Vm6z8uT+fgtLKNrmmEEI0RpIVITo5pZR1e/3L2qhXBWwLGy7bKYUNhRDtR5IVITq5jQcL2JddgoeLE+cOPr69VZoiu9kKIU4GSVaE6OQsE2unDIrA2825Ta9tLWy4M5uKailsKIRoH5KsCNGJlVZW893mw0DbDgFZWAobllTWsHavFDYUQrQPSVaE6MR+2ppBSWUNPYI8ObVnYJtf32SSwoZCiPYnyYoQnZhlYu20hG7HVbSwJSxLmJdIYUMhRDuRZEWITupAbgl/pORhGHBJQtsPAVmMrlfYcNthKWwohGh7kqwI0Ul9uUEXLRzXJ4QIP492u48UNhRCtDdJVoTohGrMypqstMfE2qPJvBUhRHuSZEWITmjVnhzSC8vx93SxLi9uTxP668KGyRlHOJQnhQ2FEG1LkhUhOiHL3ioXDInEzdmp3e/n7+nKiJgAQHpXhBBtT5IVITqZgtJKftmuE4Zpw6NP2n0nxYcDkqwIIdqeJCtCdDLfbDpMZY2Z+AhfBkb5nbT7Tqqdt7Juf54UNhRCtClJVoToZBZsqN1b5SRMrK2ve5An/cJ0YcPlO7NP6r2FEJ2bJCtCdCI7DhexLa0IVycTFw6NOun3t0zmlaEgIURbkmRFiE7E0quSGB9KgJfrSb+/ZTfb5TuzpLChEKLNSLIiRCdRUV3Dwr/SgJM7sba+wVF+hPpIYUMhRNuSZEWITmJpUhb5pVWE+7pzep8Qu8RgMhk2tYKEEKItSLIiRCdh2Vvl4mFROJnap2hhS1jmrSzZkYVSUthQCHHiJFkRohPIKCxnxS69AsdeQ0AWo3oF4enqREZROVvTpLChEOLESbIiRCfw1cZUzApOjQmkZ7CXXWNxd3FifF89DLVEVgUJIdqAJCtCdHBK1RUtvPQk763SFMtQ0C+SrAgh2oAkK0J0cOsP5JOSU4KnqxPnDoqwdzgAnNlPChsKIdqOJCtCdHBf/Kkn1p43OAIvN2c7R6MFeLkyvIcUNhRCtA1JVoTowEoqqvlhazpg/4m1R5skS5iFEG1EkhUhOrAftqZTWllDz2Ava0+Go7AkK3+k5FFYWmXnaIQQHZkkK0J0YJa9VaYN74Zh2G9vlcb0CPKib5g3NWbFsp1Z9g5HCNGBSbIiRAe1L7uYP/fnYzLgkmGOsQroaNbChjIUJIQ4AZKsCNFBWZYrj+8bQpivu52jadyk+HAAVuzMlsKGQojjJsmKEB1QjVnx1UadrFzmYBNr67MUNiyuqOb3fXn2DkcI0UFJsiJEB/Tb7mwyiyoI8HRhYlyYvcNpkslkWONbvCPDztEIIToqSVaE6IAsE2svPCUKV2fH/md8lhQ2FEKcIMf+X04I0UBeSaV1o7VpCY47BGQxKrausOG2tCJ7hyOE6IAkWRGig/lmUxpVNYqBUb7ER/raO5xmubs4cXofXdhQhoKEEMdDkhUhOpgv1jv+xNqj1S1hlv1WhBCtJ8mKEB3ItrRCktKLcHUycf6QSHuH02IT+odiMiApvUgKGwohWk2SFSE6EMvE2rMGhOHv6WrnaFouwMuV4TGBgNQKEkK0niQrQnQQ5VU1LNx0GOhYQ0AWllVBUoVZCNFakqwI0UEsScqksKyKCD93xvQOtnc4rSaFDYUQx0uSFSE6CMvE2ksTuuFkcqyihS1Rv7Dh8l0y0VYI0XKSrAjRARwuKGPl7mxAJysdVWLtbra/yFCQEKIVJFkRogP4emMqSsHInoH0CPKydzjHzTIUtGJnNpXVZjtHI4ToKCRZEcLBmc2qQ+6t0pgh3fwJsRY2zLV3OEKIDkKSFSEc3Lr9eRzMK8XbzZlzBoXbO5wTYjIZJMaFArIqSAjRcpKsCOHgFtT2qpw3OAJPV2c7R3PiLENBS5IypbChEKJFJFkRwoEVV1Tz49Z0AKZ18CEgi9GxwXi6OpFeWM72w1LYUAjRPElWhHBgP2w5TFlVDbEhXgzr7m/vcNpE/cKGsipICNESkqwI4cAsE2unDY/GMDre3ipNSZTdbIUQrSDJihAOak9WMRsO5ONkMrj4lCh7h9Om6hc2TM2XwoZCiGOTZEUIB/XlBt2rckbfEEJ93e0cTdsKrF/YUHpXhBDNkGRFCAdUXWPmq411Q0Cd0aTa3WwXSxVmIUQzJFkRwgGt2JVN9pEKgrxcmdA/1N7htAtrYcN9eRSWSWFDIUTTJFkRwgFZ9la58JQoXJ075z/TmGAv+oR6U21WLN8phQ2FEE3rnP8LCtGB5RZXsKR2aKSjb6/fnEmyKkgI0QKSrAjhYP73VxrVZsWQbn70C/exdzjtKlEKGwohWkCSFSEciFLKugro0k7eqwIwtLaw4ZGKav5IkcKGQojGSbIihAPZmlZIcsYR3JxNnD8k0t7htDspbCiEaAlJVoRwIF+sPwTA2QPD8fNwsXM0J4e1sOEOKWwohGicJCtCOIjyqhq+3XQYgGkJnX8IyGJ0bDAeLk4clsKGQogmSLIihIP4eXsGReXVRPl7MDo2yN7hnDTuLk6c3jcYkKEgIUTjJFkRwkFY9la5NKEbJlPnKVrYEpPiwwFJVoQQjZNkRQgHkJpfyuq9OYBOVroaS2HDHVLYUAjRCElWhHAAX21IQykYHRtEdKCnvcM56QK9XBneQxc2XJoku9kKIWxJsiKEnZnNii836lVAnX3H2mOR3WyFEE2RZEUIO/s9JZdDeWX4uDkzeUC4vcOxG8tutr/vy5XChkIIG5KsCGFnlom1U4dG4uHqZOdo7KdnsBe9pbChEKIRkqwIYUdF5VX8tC0d6NpDQBbWDeJk3ooQoh5JVoSwo+83p1NeZaZPqDdDuvnZOxy7syQry5OzpLChEMJKkhUh7Miyvf5lw6MxjK61t0pjhnbzJ9hbChsKIWzZPVl5/fXXiYmJwd3dnZEjR7Ju3bpjtn/55Zfp168fHh4eREdHc88991BeXm59/fHHH8cwDJtH//792/ttCNFquzOPsOlQAU4mgwtPibJ3OA6hfmHDJbIqSAhRy67Jyueff87s2bOZM2cOGzduZMiQIUyePJmsrMbHq//73//y4IMPMmfOHJKSkpg/fz6ff/45Dz/8sE27AQMGkJ6ebn2sWrXqZLwdIVplwQY9sXZC/1BCfNzsHI3jqL+EWQobCiEAnO158xdffJEbb7yRmTNnAvDWW2/xww8/8P777/Pggw82aL9mzRrGjBnDlVdeCUBMTAxXXHEFf/zxh007Z2dnwsNbvgS0oqKCiooK6/OiIimmJtpXVY2ZrzfqZEUm1toa09u2sOHAKJnLI0RXZ7eelcrKSjZs2EBiYmJdMCYTiYmJrF27ttFzRo8ezYYNG6xDRfv27ePHH39kypQpNu12795NZGQkvXr14qqrruLgwYPHjGXu3Ln4+flZH9HR8uUh2tfyndnkFFcS7O3KGf1C7B2OQ3F3cWJcHylsKISoY7dkJScnh5qaGsLCwmyOh4WFkZGR0eg5V155JU8++SRjx47FxcWF2NhYzjjjDJthoJEjR/Lhhx+yaNEi3nzzTVJSUhg3bhxHjhxpMpaHHnqIwsJC6+PQoUNt8yaFaIJlYu3Fw7rh4mT3qWMOp24JsyQrQggHmGDbGsuXL+eZZ57hjTfeYOPGjXz99df88MMPPPXUU9Y255xzDtOmTWPw4MFMnjyZH3/8kYKCAr744osmr+vm5oavr6/NQ4j2kn2kgl+T9bysaV2waGFLWAobbj9cRFpBmb3DEULYmd2SleDgYJycnMjMtP3JKTMzs8n5Jo8++ijXXHMNf/vb3xg0aBAXXXQRzzzzDHPnzsVsbnxPBn9/f/r27cuePXva/D0IcTwW/pVGjVkxNNqfPmE+9g7HIQV5u5HQIwCQVUFCCDsmK66uriQkJLB06VLrMbPZzNKlSxk1alSj55SWlmIy2Ybs5KS3J29q1UBxcTF79+4lIiKijSIX4vgppWz2VhFNk6EgIYSFXYeBZs+ezbvvvstHH31EUlISt956KyUlJdbVQTNmzOChhx6ytp86dSpvvvkm//d//0dKSgqLFy/m0UcfZerUqdak5d5772XFihXs37+fNWvWcNFFF+Hk5MQVV1xhl/coRH2bDhWwO6sYdxcT5w2RBPpYJsXrHtbf9+VSVC6FDYXoyuy6dPnyyy8nOzubxx57jIyMDIYOHcqiRYusk24PHjxo05PyyCOPYBgGjzzyCGlpaYSEhDB16lSefvppa5vU1FSuuOIKcnNzCQkJYezYsfz++++EhMiKC2F/lr1VzhkYga+7i52jcWyWwoZ7sopZvjOb84dE2jskIYSdGEp2XWqgqKgIPz8/CgsLZbKtaDNllTWc+vQSjlRU898bRzI6NtjeITm8Z39K5q0Ve5k6JJJ5V5xi73CEEC3QHt+hHWo1kBAd2c/bMzhSUU10oAen9QyydzgdgrWw4U4pbChEVybJihAniWVi7aXDojGZpGhhS5wS7U+wtytHyqtZl5Jn73CEEHYiyYoQJ8GhvFLW7M3FMOCSBCla2FImk8HE/pZaQY1vFimE6PwkWRHiJPiydmLt2N7BdAvwtHM0HUvdEuYsKWwoRBclyYoQ7cxsVtZk5VLZsbbVxvbRhQ3TCsrYkS5FRoXoiiRZEaKdrdmbS1pBGb7uzkwe0PJq4EKTwoZCCElWhGhnCzboibXnD43E3cXJztF0TInxlnkrkqwI0RVJsiJEOyosreKnbXpiqGyvf/wm1itseFgKGwrR5UiyIkQ7+nbLYSqrzfQP92FQlJ+9w+mwbAobSq0gIbqcVicrixYtYtWqVdbnr7/+OkOHDuXKK68kPz+/TYMToqP70rK3SkI3DEP2VjkRiXEyFCREV9XqZOW+++6jqEjPyN+6dSt///vfmTJlCikpKcyePbvNAxSio0rOKGJzaiHOJoOLTpG9VU6UZQmzFDYUoutpdbKSkpJCfHw8AF999RXnnXcezzzzDK+//jo//fRTmwcoREe1YL1erpwYF0aQt5udo+n4eoV4ExviRVWNYsXObHuHI4Q4iVqdrLi6ulJaWgrAkiVLOOusswAIDAy09rgI0dVVVptZ+FcaANOGy94qbWVSvF76LUNBQnQtrU5Wxo4dy+zZs3nqqadYt24d5557LgC7du2iWzf5T1kIgF+Ts8gtqSTEx43xfUPsHU6nMSk+FIBlO7OoqpHChkJ0Fa1OVl577TWcnZ358ssvefPNN4mK0mPxP/30E2effXabByhER7SgdmLtJcO64ewki+7aytDoAClsKEQX5NzaE7p3787333/f4PhLL73UJgEJ0dFlFZWzfJeeUyFDQG3Lqbaw4efrD7F4RyZjegfbOyQhxEnQ6h/5Nm7cyNatW63Pv/nmGy688EIefvhhKisr2zQ4ITqir/9Ko8asSOgRQGyIt73D6XTq72YrhQ2F6BpanazcfPPN7Nq1C4B9+/Yxffp0PD09WbBgAffff3+bByhER6KUsg4BXSa9Ku1ibO9g3F1MpBWUkZR+xN7hCCFOglYnK7t27WLo0KEALFiwgNNPP53//ve/fPjhh3z11VdtHZ8QHcrGgwXszS7Bw8WJcwdH2jucTsnD1YlxffSkZVkVJETX0OpkRSmF2axn4S9ZsoQpU6YAEB0dTU5OTttGJ0QHY+lVmTIoAm+3Vk8JEy1k2SBucVKGnSMRQpwMrU5Whg8fzj//+U8+/vhjVqxYYV26nJKSQlhYWJsHKERHUVpZzfdb0gEZAmpvE/qHYhiwLU0KGwrRFbQ6WXn55ZfZuHEjs2bN4h//+Ae9e/cG4Msvv2T06NFtHqAQHcVPWzMorqimR5Anp/YMtHc4nVqwtxsJ3XVhw6VS2FCITq/V/dSDBw+2WQ1k8fzzz+Pk5NQmQQnREX1ROwQ0TYoWnhST4sNYfyCfX3Zkcs2oGHuHI4RoR8c9qL5hwwaSkpIAiI+PZ9iwYW0WlBAdzYHcEv5IycMw4OJhMgR0MiTGhzH3p2RrYUNfdxd7hySEaCetTlaysrK4/PLLWbFiBf7+/gAUFBRw5pln8n//93+EhMjW4qLr+XKDLlo4rk8Ikf4edo6ma4gN8aZXiBf7skv4bVc258nqKyE6rVbPWbnjjjsoLi5m+/bt5OXlkZeXx7Zt2ygqKuLOO+9sjxiFcGg1ZmVNVmRi7ck1qd4GcUKIzqvVycqiRYt44403iIuLsx6Lj4/n9ddf56effmrT4IToCFbvySG9sBw/DxcS42RF3Ml0Vm2ysixZChsK0Zm1Olkxm824uDQcG3ZxcbHuvyJEV2KZWHvh0EjcXWSS+ck0NDqAIC9XiqSwoRCdWquTlQkTJnDXXXdx+PBh67G0tDTuueceJk6c2KbBCeHoCkor+WW7HoKYNjzaztF0PU4mg4lxoYAMBQnRmbU6WXnttdcoKioiJiaG2NhYYmNj6dmzJ0VFRcybN689YhTCYX27+TCVNWbiInwZGOVn73C6pEnx4YAUNhSiM2v1aqDo6Gg2btzIkiVLSE5OBiAuLo7ExMQ2D04IR/eFFC20u6MLG8ZH+to7JCFEGzuufVYMw2DSpElMmjSpreMRosPYcbiIbWlFuDqZuHBolL3D6bI8XJ0Y2zuEJUmZLEnKlGRFiE6oRcnKq6++2uILyvJl0VUs2KB7VRLjQwnwcrVzNF3bWfFhLEnKZPGOTO6c2Mfe4Qgh2liLkpWXXnqpRRczDEOSFdElVFabWfhXGiATax3BhDhd2HBrWiHphWVE+MnGfEJ0Ji1KVlJSUto7DiE6lKVJmeSXVhHu687pfWTXZnsL9nZjWPcANhzIZ4nUChKi02n1aiAhRN3E2ouHReFkkqKFjsC6m21Slp0jEUK0NUlWhGiljMJyVuzKBmQIyJFYkpW1e3M4Ul5l52iEEG1JkhUhWunrv1IxKzg1JpCewV72DkfUig3xplewF1U1yppMCiE6B0lWhGgFpRQL1uuihZfK3ioOx9K7skR2sxWiU5FkRYhWWH8gn5ScEjxdnTh3UIS9wxFHsSQrv0phQyE6lePaFK6goIB169aRlZXVoHjhjBkz2iQwIRzRgtqJtecOisDL7bj++Yh2dEp3Xdgwt6SSP1PyGN072N4hCSHaQKv/t/3uu++46qqrKC4uxtfXF8OoWwlhGIYkK6LTKqmo5vst6QBcNkIm1joiJ5PBhP6hLNiQyi87MiVZEaKTaPUw0N///neuv/56iouLKSgoID8/3/rIy5MS7aLz+mFrOqWVNfQM9mJ4jwB7hyOaYJ23kiSFDYXoLFqdrKSlpXHnnXfi6enZHvEI4bC+tEysTehm06MoHMu4PiG4OZtIzS8jOeOIvcMRQrSBVicrkydPZv369e0RixAOa192Mev252Ey4JJhsgrIkXm4OjGujx7+WSyrgoToFFo9Z+Xcc8/lvvvuY8eOHQwaNAgXFxeb188///w2C04IR/HlBt2rMr5vCOF+7naORjRnUnwYS5KyWJIkhQ2F6AxanazceOONADz55JMNXjMMg5qamhOPSggHUmNWfLVRJyuyY23HMKF/GIaxlS2phWQUlkuCKUQH1+phILPZ3ORDEhXRGf22O5vMogoCPF2YGBdq73BEC4T46MKGAIuTZChIiI5ONoUTohmWvVUuPCUKN2cnO0cjWioxrrawocxbEaLDa9Ew0KuvvspNN92Eu7s7r7766jHb3nnnnW0SmBCOIK+k0vplNy1BhoA6kknxYTy3KNla2NDH3aX5k4QQDqlFycpLL73EVVddhbu7Oy+99FKT7QzDkGRFdCrfbEqjqkYxMMqX+Ehfe4cjWqF3qC5suC+nhN925XDuYCmPIERH1aJkJSUlpdHfC9HZWYoWXiYTazukxPgw3vltH4t3ZEiyIkQHJnNWhGjCtrRCdqQX4epk4vwhkfYORxwHKWwoROdwXJXYUlNT+fbbbzl48CCVlZU2r7344ottEpgQ9maZWHvWgDD8PV3tHI04HsPqFzbcn8foWKkVJERH1OpkZenSpZx//vn06tWL5ORkBg4cyP79+1FKMWzYsPaIUYiTrryqhoWbDgMyBNSR1S9suHhHpiQrQnRQrR4Geuihh7j33nvZunUr7u7ufPXVVxw6dIjx48czbdq09ohRiJNuSVImhWVVRPi5M0Yq93ZoifF1S5ilsKEQHVOrk5WkpCRmzJgBgLOzM2VlZXh7e/Pkk0/y3HPPtXmAQtjDF/WKFjqZpGhhRzauT7C1sOHOTClsKERH1OpkxcvLyzpPJSIigr1791pfy8nJabvIhLCTwwVlrNydDehkRXRsnq7OdYUNt8sGcUJ0RK1OVk477TRWrVoFwJQpU/j73//O008/zfXXX89pp53W5gEKcbJ9vTEVpWBkz0B6BHnZOxzRBiyrgmTrfSE6plZPsH3xxRcpLi4G4IknnqC4uJjPP/+cPn36yEog0eEppViwQfZW6WyksKEQHVurkpWamhpSU1MZPHgwoIeE3nrrrXYJTAh7WJeSx4HcUrzdnDlnULi9wxFtJMTHjVOi/dl4sIAlSZlcfVoPe4ckhGiFVg0DOTk5cdZZZ5Gfn99e8QhhV5aJtecNjsDT9bi2IRIOalK8Tj6lsKEQHU+r56wMHDiQffv2tUcsQthVcUU1P25NB2CaDAF1OpPiQwFYuzeX4opqO0cjhGiNVicr//znP7n33nv5/vvvSU9Pp6ioyOYhREf1w5bDlFXV0CvEi2Hd/e0djmhjsSHe9Az2orLGzG+7su0djhCiFVqcrDz55JOUlJQwZcoUNm/ezPnnn0+3bt0ICAggICAAf39/AgIC2jNWIdrVF/WKFhqG7K3S2RiGUbcqSIaChOhQWjwo/8QTT3DLLbewbNmy9oxHCLvYk1XMhgP5OJkMLj4lyt7hiHYyqbYKs6WwoYuT1HIVoiNocbJi2aZ6/Pjx7RaMEPbyZe1y5TP6hhDqK8taO6th3QMI9HIlr6SS9fvzGRUbZO+QhBAt0KofK6RrXHRG1TVmvtqokxWZWNu5WQobggwFCdGRtCpZ6du3L4GBgcd8CNHR/LY7m+wjFQR5uVq/yETnVbebbYYUNhSig2jVRhJPPPEEfn5+7RWLEHbxxZ+6V+XCU6JwdZY5DJ2dpbDhoTxd2LB/uK+9QxJCNKNVycr06dMJDZWfPEXnkVtcwZLaejGyvX7X4OnqzNjewSxNzmLJjkxJVoToAFr8Y6TMVxGd0cJNh6k2K4Z086NfuI+9wxEniSxhFqJjaXGyImO7orNRSrFg/SEALpVelS5lYlwYhgGbUwvJLCq3dzhCiGa0OFkxm80yBCQ6la1phSRnHMHN2cT5QyLtHY44iUJ83Bga7Q9gHQYUQjgumU0ouqwFtTvWTh4Qjp+Hi52jESebDAUJ0XFIsiK6pPKqGr7ZlAbIxNqu6qzaZGXNHilsKISjk2RFdEk/b8+gqLyaKH8PRssupl1SbIg3MUGeUthQiA5AkhXRJVm2178koRsmk6x064rqFzZcIkNBQjg0SVZEl5OaX8qqPTkATEvoZudohD1Nig8H4NedWVTXmO0cjRCiKZKsiC7nqw1pKAWjY4OIDvS0dzjCjhJ6BBDg6UJBaRV/7s+3dzhCiCZIsiK6FLNZ8eVGvbfKtOHSq9LV6cKGtUNBsoRZCIdl92Tl9ddfJyYmBnd3d0aOHMm6deuO2f7ll1+mX79+eHh4EB0dzT333EN5ue2mTq29pug6fk/J5VBeGT5uzpw9IMLe4QgHUH8Js2x+KYRjsmuy8vnnnzN79mzmzJnDxo0bGTJkCJMnTyYrK6vR9v/973958MEHmTNnDklJScyfP5/PP/+chx9++LivKboWy94qU4dG4uHqZOdohCM4vW8wrs4mDuaVsiuz2N7hCCEaYddk5cUXX+TGG29k5syZxMfH89Zbb+Hp6cn777/faPs1a9YwZswYrrzySmJiYjjrrLO44oorbHpOWntN0XUUlVfx07Z0QCbWijqWwoYAi3dk2DkaIURj7JasVFZWsmHDBhITE+uCMZlITExk7dq1jZ4zevRoNmzYYE1O9u3bx48//siUKVOO+5oAFRUVFBUV2TxE5/P95nTKq8z0CfW2brUuBNQbCkqSHlghHJGzvW6ck5NDTU0NYWFhNsfDwsJITk5u9Jwrr7ySnJwcxo4di1KK6upqbrnlFusw0PFcE2Du3Lk88cQTJ/iOhKNbsEFPrL1seLRUERc2JsaF6sKGhwrILConzNfd3iEJIeqx+wTb1li+fDnPPPMMb7zxBhs3buTrr7/mhx9+4Kmnnjqh6z700EMUFhZaH4cOHWqjiIWj2J15hL8OFuBkMrjwlKiTfn+V9itq6TUn/b6iZUJ93KWwoRAOzG49K8HBwTg5OZGZafsfQ2ZmJuHh4Y2e8+ijj3LNNdfwt7/9DYBBgwZRUlLCTTfdxD/+8Y/juiaAm5sbbm5uJ/iOTg61dR4cXg7dzsIYcLPtazvehUOLIPIMjEF32CfAk0AlzYeCZDhyELy7YYz+d8M2R/bDjvegaA+4+nKwdDgQxYT+oYT4NP5nrX6+pOHBwfdgRIw9djy5W+HAd1CwG2rKwC0Q/GIh+myMwAHH8Q6FPSTGhfHXwQKW7MjkqpE97B2OEKIeu/WsuLq6kpCQwNKlS63HzGYzS5cuZdSoUY2eU1paislkG7KTk17RoZQ6rmt2SO7BkLEKVVNhPaRqKiF9pX7NASmlUOaatrtg1ASIGNP4vapLYf1T4BECo/5FTe9rGK2WckVEcvNFCwfeDme8V/cIPfWYzdXBRbD+CXDxgSGzYeyrcMr94N8Pdn54nG9O2IOlsOHqvbmUSGFDIRyK3XpWAGbPns21117L8OHDOfXUU3n55ZcpKSlh5syZAMyYMYOoqCjmzp0LwNSpU3nxxRc55ZRTGDlyJHv27OHRRx9l6tSp1qSluWt2Cr49oTQTMv+AyNP1scw/dKLiGWrTVCkzpCyE1MVQUQCeERA7DSNcJ28qbxv8OQcSHoFdn0JJGvj3hcGzoWiv/sItz4OQBBh4G4aT7pVQ5irY+R/IWAXVZeAbC/1nYvj1tr3usH/Ans90L8iAm1Hb3oDTnrW2A1D7v9c9E6e/iWE0nz8bcTfo8/YUwZEDDRsc/g3M1TpekwvLDrqxOzWOm3rsoFu/kGNf3NkLwy2g2RgAVFk2JH8APc7F6H/U3y+fGFT3cxuek/kH7PoPlOdCQDwMuA3DwzETzK6md6gubLg/t5TfdmVzziDZh0cIR2HXZOXyyy8nOzubxx57jIyMDIYOHcqiRYusE2QPHjxo05PyyCOPYBgGjzzyCGlpaYSEhDB16lSefvrpFl+z04iaAGm/1iUraUv1sfxttu32fQ3pv0H8TTpRyd8BW19BufraDlHs+QLi/gZOrrD53/phcobBd0NNOfz1LzjwI/S6SLff+R/I/B0G3qF7MFIWwvqnUONew3D1qbvurk+g37XgGQbOXhA0GNKWQb1khbRfIepMDMOEWnGL/n3vy4//syncBYFxGCYXAL5Yf4gjed24tcdWMJeCk3fT5ya9h9r+JniEQfRZEDWh6cm4mb+DqoaeFzb6coPzaiph31cw6E4wnCHpXdjyIox85jjepGhrhmGQGBfGe6tSWLwjU5IVIRyIXZMVgFmzZjFr1qxGX1u+fLnNc2dnZ+bMmcOcOXOO+5qdRuTpsPtTVFntUsuCnXoYol6yosxVkPI1DJ+D4d9PH/QMR+Unw6FfoH6y0ucKjID++ryoibD7Uxj3OoannuujwkZB3jbodRGqulyfP3AWRsgw/fqAWyH3Vp001f/y7jMdI3hIXUzdJsL2d1D9r8MwuaCK9kHxQRj2oDU+XOolO8ejogA8dA9T9pEKliVnEePuXveaSxPJSu/pEDhIJ2w5m3UyUVMOPRr2kABQehicPW16YlTGWtj2Wl2bkc9g+NTOf1DVEPc3DP+++unAWbD6LlTBbgz/PifwhkVbmRSvkxVLYUNnpw61BkGITsvuyYo4PoarHyp4GKQtBxSEDMNw9cVms/DSdKipgPVP2h43V+uhpPp86k0odPMHJzdroqKP+UHhbv37sgz9xRvQry4ekzPKr7ceRqrPN9b2eeipeuJr5h8QMVb3sgQOxKhNLowRj7f0I2iRhX+lUW1W9A/3bbatETut7olvL1RNOez/pulkpTHBQ2HUC1CRB38+BqpeJV/DyaZHyfDuhnL2gpJUkGTFIVgKG+aXVrH+QD6n9Qqyd0hCCCRZ6di6TYSk9/Tv4/7W8PXq2ppJwx7WK1Tqqx0isTKO+qtgHL0VvQEcR90UJ9v9KgyTCypyPKT9igobqScF97++9dc9Fjd/qCxAKcUX6/Uy9AvjvaCk9rWW8u8L+75EmausQ0o2PCOguhRVkW/tXTGcPcDZA2WSrfw7ImcnExP6h/HVxlQW78iUZEUIByF9nB1Z8FDdS2Ku1r8/mne0TkrKszG8ImwfJzKp0yNcJzf5O62HlLkaCveAVwu2se+WCLlb4eDPoGogbOTxx9IYv76Ql8TmQ7nszirG3cXE2MA08IrEaGoIqDFFKeDs3XiiAhA2Sn8OKQtbdj1VA4V7656WpEF1Scs+M3HSTIrXvXxLkqSwoRCOQnpWOjDDcEKNfcX6+wavO3ugYs6H5A/1f7oBcVBdCvnJ4OyBEXXm8d3X2R0VPRl2/Qfl4g0ewfoLu6ZS9/Y0d753N5R/H9j1MXSbYF1hBKD+fBxCT8XoMaXJ81VJup5LUlEANZWoohT9gnc3nVhEjIO9CzBvfZ0+nrFcPdDA7fAi6Hdd3TUy/4Ddn2CMnaefZ/0JlYU60TG5QO5mPd8n5vym34dHCKrftZD8PqqqGCLP0BOJq4rh8IraRvV+HjCcIXk+qv/1uucq6T3w6yvzVRzMuD4huDqbOJBbyu6sYvqGneAcKiHECZNkpYMznD2P3aD3FeDqq794t2eBiyf49IJeF5/YjfteDSjY+qreCM03FoY/2vKei6iJelJw1FHJTWkGVB059rnb34T87XXP196rfz39TfAIxXDxonzIP1BL/813w7eDqw/0moYRfVbdOdUlUHK47rnhDAcXQekH+rlnuE5uutXVmWqM0WMKyjsK9n8Hm1/Qy7hdfPQQUsIjdZNrQU/c7XkhbHlZz2kJiIMBtx37vYqTzstNFzb8NTmLxTsyJVkRwgEYSvo5GygqKsLPz4/CwkJ8fZufmClaT+1dABlrMMa81C7XX/hXGnd/voluAR78dt+ZmExSC0i03H//OMjD/9vKkGh/vrm98c0HhRCNa4/vUJmzIk4qVV2GOnIQDv4E3Zse6jlRlom10xKiJVERrZYYp+etbD5UQFZRuZ2jEUJIsiJOrqT3YO19eo+XbhPa5RaH8kpZszcXw4BLEk5+0ULR8YX61i9smGXfYIQQkqyIk8sYdAfGWZ9jDPl7o5OC28KXG1IBGBMbTLeAZub0CNGESbW1ghbvyLBzJEIISVZEp2I2K2uyMm24LAkWx2+SFDYUwmFIsiI6lbX7ckkrKMPX3ZnJA8KbP0GIJvQJ9aZHkCeV1WZW7s62dzhCdGmydFlYqa3zoLoE45QH7RuHUrDn/yB1id4Xxr8fxN+E4RXZ9DkrboHybEYDKZbtY359BxV9Nkb8jXXtCnbC7v/Wlg4wgW8MJDxaV026aJ/e/6Vwj94jJew06Hed3plWdCmGYTCptrDhLzsyOXugFDYUwl6kZ0U4npSFcPBHGHAznDZXb9m/4SlUTWXT54x6jiOnvcXY369kxOrp7Ovxd308fJS1iSrYCRv+CUFD4LRnYdRz0P0c68ZtqjwP/nxC77Fy2rOQ8CgUH7ItTCi6lMTaoaBfk3VhQyGEfUjPimgRlbcddv4HjuzXVYujzoDeV2LU1sBRGWth7xd6UzcnV/DpCac8qHe7zdsGOz+GkkN651bvaBh8t7V4oc19lIID30OvSzFCT9XHBt0By2+ArHW6+GEjDFc/vt14gLQyd/qH+9BLJeuyAAH1KksnfwDdp2DU3xDPq95qoez1YHKCuBsxLAlM/M2wZjaqJB3DS36y7mqG9wjA39OFgtIqNhzIZ6TUChLCLqRnRTRLlefCxqd1xeDR/4b4myD1V9j3pX69Ih+2vARRE2DsKzDiST18gkKZa+Cv5yAwHka/CCPnQrdJ6MKIoMqyUD9fohMagLJMqCyAoMHW+xsuXuDXR+94ewwLavdWuWxYOKT/prfyN2rvU1Goh35c/VB/PIxadj1q3aOo/KS6C5irweRsTVQAMLnqXwvqtRNdhi5sqJPqxTsy7RyNEF2XJCuieYcWgXsQxP0Nw7sbRthI6H057P8WpcxQkW8tSGh4hGL49MDofrae51Fdqh8hwzE8w/X5UWdieIToaxtO4BUJptr6QBUF+tejqyO7+ukkpgk7M46wObUQZ5PBtO7pejv9yHq1j8pqv2j2fq630E94BHx7wZ+Poyzb7gcNhIoCVMpClLlK1/vZ/YltXKLLOcuyhFkKGwphNzIMJJpXnAZ+/ay9FAD499fFBMtzwacHBA6C1bNRwUP1nJDwURgu3hiuPqjIM/Wck6DBusckfAyGWwAAhnsQ1BYTPBGWXpWJcaF45/wIwadguAfWNVC18w26nYURVbsZnW8vVO4WSPsV+l6N4d0dNfAO2Pkh7P4UMEGPKeDqj6UnSHQ99Qsb7skqpo/UChLipJOeFXHCDMMJhs/RvRXe3fTk2FV3oEp1b4YxaBaMfEYnOBlrYOUsVMGuxi9m6VE5uiejsrA2aWiostrM//5KA2DGUE/I3dqwAGFtcoT3UXuveHeD8py69xI5DuPM+TD+XZjwIcReDpVFupqy6JK83JwZE6vnqvwiQ0FC2IUkK6J53lFQuNO2C7wgGZw89PAQepmnEdAfo/d0GP2CrmKc9Ye1ueHbC6PXxRgjnwHv7pC+svF7eYTppCRvq/WQqi7V8038+zV6yq/JWeSWVBLi48Zpblt0lenghKOuGwpugbaVlgFK0sE9pME1DTd/PYyVsRqcXHRvkeiyJsXrPXtk3ooQ9iHJirBVVYoqSrF50G2SHu5Jeg9VnIrKWgd7PoeYqRiGCVWwC7XvK1ThHlRZNmT+oXsjvLqhSjNRuz5BFezUk2lzNkFpunUVjirPRa26A1WwG9BJDz3Og71forL+RB05AFtf1T0jtauDANSfj6MO/AjAlxv0ENDFwyIwpS+DqDOsq5QsDMOAmAvg4I+ojLWoknTU7s+gJA26Tay77oEfUUX7UCWHUQd/0rWM+lylJ/mKLmtibWHDTVLYUAi7kDkrwlb+dlh7r+2xqIkw7B966fKav+uly90mQK9L9evOnpC3Qy85ri7TPRX9rsUIGYaqKNAJwablUHlEJx3dz4bos/S5qkb3dpgr6u7X80I9H2b7W3qirH//2o3bXOvalGZA1RGyispZtlPvLjqjTxHszdHxNsKIOQ9lroSdH0BVMfjEwPDHMDzr7XRbtEdPwq0u1wnVgJsxIs84gQ9UdAZhvu4MifZn86ECliZnccWp3e0dkhBdiqFkensDRUVF+Pn5UVhYiK+vr73DEcfw1oq9PPtTMgk9Avjq1tH2Dkd0Yq8v28PzP+9kQv9Q3r9uhL3DEcJhtcd3qAwDiQ5LKWVdBTQtQYoWivZlKWy4ak+OFDYU4iSTZEV0WBsPFrA3uwQPFyfOHSy7y4r21SfUm+6BlsKGOc2fIIRoM5KsiA7L0qsyZVAEPu4udo5GdHaGYVh7V2RVkBAnlyQrokMqrazm+y3pAEwbLkNA4uSYZC1smCmFDYU4iSRZ6eRU3jZde6eqxN6htKmftmZQXFFNjyBPRvYMbP4EIdqApbBhfm1hQyHEySFLlzsRte4x8InBiLu+7qB/PzjjPb282AGoI/thx3t6ibCrr66C3PPCY59TuAd2fQJFewED/Hrzx9YhgLOeWFt6GLX9bShJ1XWI3AIgYhzEXoZh0n/FVfFB2P1/ULQPyrOh30yMmPNs71NdBrs/05vZVRaBb0/ofz2GX+/G49r+NqT+0ui1AJS5Cn5/UFeqHvUChm/P1n9gwqE4O5mY0C+Ur/9KY0lSplRhFuIkkZ6VTs4wuWC4BdjW9bETVV0K658CjxAY9S/oOwP2fI469MsxzimDDU+BezCc9iyM/CelZlfuDVqAi8nMxcO66WKIUWdAwmMw9lXofz2kLtEb11nUVOot8/te3eS2/Wx/A3I3w6A7dYXooCGw/glddfrouDL/gMJdelfcpuz8T902/6LTqD9vRXZ+EOLkkJ6VTkJtnac3dMvfjjr4gz54+ptQlgV/zoEJ/8Fw8UKl/QrJH8Cgu2DnR7ouTsgw/QWdsUZ/wVeXQuR46H+drvtDbS/B7v9C+iq9UZt3d138L3Bgy4M8/BuYq2HgbRgmF/DujjqSAge+q9sk7mglaXoDt97TMTyCAfgyfxQz3P7kgn6uRPp7AB5Qf2M3j1BU3jbIT7IeMvx6Q20Pidr1ScPPr6YCMn+HUx7ECBygD/a+HJW9Hg79DH2urGtbu5svwx+FDc80GrbK3qgTn6H3Qc5fLf+MhMM7vW8Irk4m9kthQyFOGulZ6Sz6X6+HfLol6mGfM96z1u1poKZSFxscco8uPpi3Hf56DnI2QsI/dOJy6BfI+L3unB3vQcFOfc7oFyFsFGz4J6perR318yU6GWpK4S4IjNOJikXQUCg5jKoqbvwcryhw8YG0pShzFTVV5bhnLWd3iT9nDo1v9BRVkg45myCw8dcbP8msH6ajVhWZXCE/ua6ZMuvt/3tegOHd+C6mqqIAtr+pP0cnt5bHIDoELzdnRvfW/7YWJ8mqICFOBklWOgnDxUsXDzS56WEftwBrr0gDqhrib9LFBQMH6MSjIBkG3IbhHY0ROhwCB0LeNt28LBsO/wpD7sUIiMfwDMfoeYHeBj9tWd11vSLB+Rg1dCoKGg7BNFVl2fK+nD1gxJO6V2bxlRi/Xk2C1wHu3DmFifGRtm/rj4dRi6fDqlkQEAe9pzcdS2P38e+naxKV56FUDerwCijYBRX1JlKmLNTDTt3PbfQ6SinY9hpET25yrovo+GQJsxAnlwwDdUVObrb1cNz8wD1Ef2Fbj/lDZaH+ffFB3euw6g5sRujNVeBa1wVujJ3X5qGqmgo9lySgPwy5hxd/TiK+YjkfDV2Cm+k8oF5CNng21JTpCa07/wP7v9V1hlpq0J2w7XVYcSMYJvDpBRFjayf2gircCwd+gFHPNz0H6OCPuj5Sr4uO9y2LDiAxLox//G+bLmx4pJxQH3d7hyREpybJSlfUoMfFAFNjfxVq95GoLtdf3qP+RYPOOOdW/Cft5g+VBbbHLD0qlh6Wo6Wv1PNuRj5DYVk172zZjaoZT/KZn0HWnzqZsLyL2jkteEfr4Zrtb6Fipjbdw3QUwzMcTn0KVV0ONWUYbgGozf8GD/1TNPlJOoH77ea6pE2ZYedHqAPfY4x/C/K26t6YxdNtE7vf70dFnI4x6I4WxSIcW5ivO0O6+bE5tZClSVLYUIj2JslKZ2JyxppgtCXfnvpLubIQI6AV80CO5tcXdn+GMldblxSTuwW8IjFcvBs/p6YSMACDbzcfprLazIAIP0wmExxrJYZSuqKzUvr0VjCc3cHZXc+jydkEfa/RL0SOh6DBto03PAWRp0PUBP28/w3Qu24yLhV5us3g2eDft3WBCIc2KT6MzamFLNmRKcmKEO1M5qx0Jh4hULAbVZaFqizSvQttwPCKhIjTYes8VObvqNJMVMFu1L6vUdkbrO3Uqjv0kt6mRIzTCdX2N1DFB1Hpq+HgD9Bjat01Mv9ArarX+xA0WK8+SnqXNVs208czn1cGrtI9PUF6JZI6/BsqYzWqOBVVmoHKWA27P4XwMXX7rJirUEUpqKIUPWenIlc/L0mvu3fOX6jsv/T7y9msV1F5RVkTEcPVB8Onu80DwwlcAzC8onQbjxDb171q59V4hmM0NeFZdEiT4vVQ6qo9OZRWSmFDIdqT9Kx0JjEXwNZ5sOouMFfqpcttZeDtsO/L2uXOeXquil9fCEmoa1NyWCcWTTBcvFDDH9Uri9ber1f59JqGUX/ZcnWJvo7lHO9uqFMeojTpM56LWoY5Cry8+kD/RzEse5gYTnriq+U892Dofg70qLdRW0U+rL237vn+b/UjYACc+mTtvUth16dQngsu3hB2GvS5sq4XSIh6+obpwoYH80r5bVcOZw8Mb/4kIcRxMZTsatRAUVERfn5+FBYW4uvra+9wBPDEd9v5YPV+pgwK542rEpo/QYiT4MnvdvD+6hQuTejGC9OG2DscIRxCe3yHyjCQcHiV1WYW/pUGwLTh0XaORog6dYUNs6gxy899QrQXSVaEw1ualEl+aRVhvm6c3ifE3uEIYTUiJgA/DxfySiqlsKEQ7UiSFeHwvlh/CIBLhnXDyWT/GkdCWDg7mZjQPxSAxTsy7ByNEJ2XJCvCoWUWlbNiVzYgQ0DCMUlhQyHanyQrwqF9tTEVs9Ld7T2Dj7GVvxB2Ur+w4d7sJmpcCSFOiCQrwmEppViwPhWQXhXhuLzrFTb8RWoFCdEuJFkRDmvDgXxSckrwdHXi3EER9g5HiCYlxumhoCWSrAjRLiRZEQ7LMrH23EEReLnJxmzCcVnmrfx1qIDsIxV2jkaIzkeSFeGQSiqq+X6L3gr/shEyBCQcm6WwoVJ6qb0Qom1JsiIc0o9b0ymtrKFnsBfDewTYOxwhmlV/VZAQom1JsiIckmVi7aUJ3TAM2VtFOL7E2mRFChsK0fYkWREOJyWnhHX78zAZeiM4ITqCfmE+RAd6UFFtZuXuHHuHI0SnIsmKcDhr9ur/6E/vG0K4n7udoxGiZQzDYFKcrrwsQ0FCtC1ZYiEczlUjezA6Npjyqhp7hyJEqyTGh/L+6hRrYUMpDyFE25CeFeGQegZ7ERfRNqXFhThZTo0JtBY23HhQChvWpzJ+Q626yd5hiA5KelaEEB2KSn4bMldCxASMvtfbvrb7Qzi8BMLGYfS/+aTHZils+L+/0li8I5MRMYHtch+15z9QuAtKUsEzEmP4Mw3bFB+E3R/CkRRw9YHIszC6n9f0NauOQNIbUHIIqorB1ReCEqDnNAxnz2PHk78DUn+EI3uhuhzcAsCnJ0ROwvDvf6JvVwjpWRFCdEBuQZD1O6qm0npImSsha41+zY6aKmyolEKpNhzaDB8Poac1+pKqLoUtz4F7MCQ8Bb2ugANfow7/eowLmiA4AQbOhlNfgH43Qf422P3BMcNQaYthy1xw8Ya4WXDq8zDgbvDtA3s/Of73J0Q90rMihOh4vGOgPBNy/oSwMfpY9npwCwb3EJumSpnh0PeQvgwqC8AjAnpciBFyqn69YAdsfgYG3Q8pn0PpYf1FG3c7HNkP+z6FijwIOgX6/g3DyU2fZ66CfZ9B1u9QXaZ7EmKv4vS+PXB1MhFq3ge/vYcaeB/sX6B7LPregNr5Lgx7AsOnV12MqYsg9ScY+RKG0fzPkEbvGfq8/UVQfLBhg6w1oKqh300YJmfw6oYqPqDvETmh8Wu6eEFkYt0B92BUZCKk/tBkHKo8RyckUZMxel9t+6J3d1TU5Ibn5KzXn1t5Hvj315+pu30TTOH4pGdFCNExhY+HjN/qnmesgPDTG7Y7+B1kroI+M2H4c9DtbEh6E1WQZNtu/9fQ+1oYOgcqcmHHPEhbBP1vg4H3Qt5WSPulrv2+zyD7T+h3MyT8EzzCYOu/8DKVMyq23pdvyufQ83IY8S8IGgYBA2zjBv08/HQMw4T6/W7U/q9O7LMp2gN+/XWiYhEwGMrSUVUlLbqEqsjXyaDfMYZxcv4EVQNNDC812CPJXAEHv4F+t8Apj0F1KSS91qJ4RNcmyYoQomMKHQOFu1DlOfon/KJddb0stZS5Cg5+C31vxAgcjOERihF+OoSNhvSjhkR6Xorh1xfDJ0YnQoXJ0Gcmhk+MnncRcioU7NDXrSmHw0uh1xUYQUMwvKKg7w1gcoWM5dahIABiLsEIHIThEYbh4g3hZ0DWWh0boI6k6F4XS6LlEQouPif22VQW6Dkn9bn61b12DGrHa6iV18Pvd4CzB/T7W9ONSzPAyQPD1b/u/Ox1qJU31D2KD9W7eA30vhbDrw+GT0/ofzMU7UYV7W3V2xNdjwwDCSE6JMPVFxU0tLaXQkHgUAwXH1T9RmWZ+qf5Lc/aHlfVeiipPq/udb939QOTG4ZHqO2xI7VfqmVZ+ovXr29dPCZnlE8vKD1MYlwi39V2nuQZUdgMcgQPhz0fQc56CB2lJwv7x2HUDl8ZQx4+jk+jDfW+GmIuhtJ0SPkC9n6qe6WadFTvSeBgGP40VOTD5qcBc72mTlBv+MvwjEQ5e0JpGvjGtunbEJ2LJCtCiI4r/HTY8x/9+97XNny9plz/OuhevUKlPsPF9rnJqf6L+ov1aEo1PNZYWH7uxIZ4AbBibyEXB4XXXdnkjAobCxm/oYJHQOYa6H1Ni67bYq7+UFlke6yysO61YzBc/XUbz0iUizdsegrV/UKMoz8/0ENfNaWoygJr74rh5A4e4ajGPj8hjpMMAwkhOq7AIWCu1o/AwQ1f94zSSUlFLoZHuO3jRCZ1eoSC4ayXD9dS5mo4sk/fExjeQy9bXrYzu+H54WfolTaHl4AyQ/CI44+lMb69oTBZx2SRvxU8IvRE2payJGeqiVpHIafqpO7g9y28Xo1eSm15WnpYz1up/cyEaIr0rAghOizDMKFGPGf9fYPXnT1Q0VNgzyd6VZBfP/3lWLQbnNz1/JXjua+TOypyIuz7DOXipVchHfoezJU6EQESYgLgEKzdm0tpZTWernX/3RpeUSjf3rDv/yB8PIaTq/U1tfkZCB6OEXVWk/dXZRlQU6F7S8yVeqUPgGeUnlQbOhr2/w92vYeKPk/vx5L2C8ReVXeNnD9h3xcYpz6vn+dugqpCPUzj5K7P2fcZ+Pa1DlE1+Bzcg1GxV8Gej1HVxRB2OniE6H1aMlfXtqr352I4wZ7/oHpfo3+/+yPw6Y0hQ0CiGZKsCCE6tOY2LCPmUj1h9eB3UD4fnL3Auwd0v+DEbtzrckBB8lt6IzSfnjDofmvPRfcATzgEFdVmVu3O4awB4bbnh5+hk6ajE6ayLKg6cux773xPTwC22PAP/evIl8A9BMPZEzX4Ab0p3IZH9R4oPS7EqL9suboMytLrnptcIX057PkUVJXeryZ4OHSfesxQjKizUJ6Reln0jlehpgycvXXvzqD7Mbyj693DDaLP05vPVeTr5PFYE3iFqGUo1cJB2C6kqKgIPz8/CgsL8fWVLd+FEMfnie+288Hq/UxL6Mbz04bYvKYO/A+y12EMn2un6IRoH+3xHSpzVoQQop1YljBbChuCXvasSg5B2mI4xlCPEKKOJCtCCNFORsQE4uvuTG5JJX9ZChvu/kgPzfjH6f1chBDNkmRFCCHaiUttYUPQtYIAjP43Y5z+IUb8HS3aWl8IIcmKEEK0q0nxemKtJVkRQrSeJCtCCNGOxvcLwdXJxL6cEvZkFds7HCE6JFm6LIToklTy21BdijHwnna9j7ebM6fFBvHbrmyWJGXSO9TbNg6lYP9XkLFM7wHj21fXJPIMb+KKoH6/GypyGr4QmYjR5zrdZtd8yN8Olfl63xTfPtBrOoZnpH494zfY+U7jNxj1Ooarn/6MMlc2fN0zCqN2fxshTgZJVoQQop1Nig/jt13ZLN6RyS3jj9oA7dD3esO2/jeDewjs/xK2Poca8RyGybXxCw57EpuaOyWpsOVZvaOshXdPXezRPUhv0nbga9jyHGrkS3quTMhpDXf9TX4bzFUYlqKHva+p3U+mlqqB9f+wvY8QJ4EkK0IIcRRVkKR3by0+CC5eEDYOek7DqK13o7LX6S//sky90Zl3Dxh4j97ZtmCH3pm2JE3v0uoVxVmxN/AosPFgPtlHKgjxcdPXUQrSFkGPCzCCE/Sx/rfAmtshZ4MudNgI46iKyurgd+AeCn5xdW3qbwDnHoKKmQYbHobybPAI07vm1t85t7JIV5Xud2PdNZw9gbpN91TOeqgukVVM4qSTZEUIIepRFXmw9QUIHwf9b4HSw7BrPphcIOYSVEU+JL0OvabrHV6ry627ySpVA9tehogzIO52XbPoyF5CfdwZFOVHXl4awRtvQA15GMM/XicOlYUQMNB6f8PZE+Ubq3e3bSJZsYnXXK23tu92DoZhNN6mplxXp3YP0TvTNiZzlU68go/Ra5K+AgIGYLgHNxuXEG1JkhUhhKjv8BJwC4Te1+ovf89InaCkfI7qcRFUFujhkOARdV/atVvKq6piqCmFoFMwPPSGcHjpIn2T4sP49Ld00qsCiDDpnhUqC/SvLkft8unqW1cluTk56/Vcl0bqHKm0xbqXx1wBHhEw+EFdO6gxGcshbJRNnSKba1XkQ95miLutZXEJ0YZkNZAQQtRXehh8e9v2Uvj1hZpyqMjTQz7+A2D9g6jtr6LSl6GqSgAwXLz1kNGWf6G2/huVukh/yaOTlcwKTyasmEK5e0zbxZuxAgKHYLgFNHwtbAwkPA1DHgHPcNgxD2WubNBMFe7W77u2CGOjMleCs6fuTRLiJJNkRQghWsEwTDD4QRh0v+41SfsF/rwPVZalX+9/M5wyB/z6QPYf+rWiPfQP96FbgAflVWZW7s7WF3P1179WFdnepLIILJNcj0GV50D+Nj3s1Fiszp4YnuEY/v0h/i4oTdc9MUfLWA7ePTB8ejZ+H6V0UhQ2tumeGSHakSQrQghRn2ckFO3BpsZr4S69/NctEADDMDD8+mLEXKJ7LgwnmyTA8InB6H4+xilzwLMbZK3BMAwS4/TQ0JKk2g3i3EN0UpK/3Xquqi6For16qXFzMlboIaOgoS14Y0o/zNW2R2vKdVJ1rEmzhUl6MnGETKwV9iEpshCi66ouRRUfsD0WMQFSf4Y9/0FFTdK9EQe+rp3AakIV7dHJReAgPdfkyF6oOgKeUbp3JX0ZBA0DtwB9blkGhI8F4Lx+blzt9D1P7h5HjXkwTiYDFXU2HFyI8gjTK3r2fwlu/lC7OghAbX4Ggodj1Ct8qJRZT5oNG2ddpWR9rSwLsn+HgEHg4qOHrw59ByZXCLSt/kzW73oOTtiYpj+n9BXgE4vhFX1cH7MQJ0qSFSFE11WYBBv+YXssfDwMulcvXV6/TC9dDh8PPS7Urzt56NU/aT9DdZnexyT2SoygIajKQj33I3Ol3tvE1R+iJukECBjSzQfnjCNUVJbz18F8hscEQvR5UFMBu97XE2X9+sKg+233WCnL0glRffnboSK38R4RkwsU7oTURXqpsasf+PWHUx6r20PFImOFnizs7NXoR6SqSyHnT73nihB2Yiibvk4BUFRUhJ+fH4WFhfj6+jZ/ghBCtNBd//cX32w6zM3je/HQOXHNnyBEB9Me36EyZ0UIIU6iSfF63ooUNhSi5SRZEUKIk2h83xBcnAz2ZZewN1sKGwrREg6RrLz++uvExMTg7u7OyJEjWbduXZNtzzjjDD0T/6jHueeea21z3XXXNXj97LPPPhlvRQghjsnH3YVRsXozOeldEaJl7J6sfP7558yePZs5c+awceNGhgwZwuTJk8nKymq0/ddff016err1sW3bNpycnJg2bZpNu7PPPtum3WeffXYy3o4QQjRrUlwoAEskWRGiReyerLz44ovceOONzJw5k/j4eN566y08PT15//33G20fGBhIeHi49bF48WI8PT0bJCtubm427QICGtndsVZFRQVFRUU2DyFEx6cKdqBWXI2qLrF3KDYSa+etbDiYT05xhZ2jEcLx2XXpcmVlJRs2bOChhx6yHjOZTCQmJrJ27doWXWP+/PlMnz4dLy/bZXfLly8nNDSUgIAAJkyYwD//+U+Cghov4DV37lyeeOKJ438jQgi7U5v+qXdhrb/E1rcvjHoNnDybPvEkUQU79FLiI3sJry5n6RnevLqrL78mZXHZiOb3L1FVR2D9w1CZD2PetllqrDJXw6Ef9J4uzh56L5VeV2C4+OjXN/3TWmzRRuAQjEH36TbJb+sl1/UFDMIY/EC9GIphz38gdyNggpAR0PsaDCf3ujbFB2H3h3AkBVx9IPIsjO7ntfyDEqIRdk1WcnJyqKmpISwszOZ4WFgYycmN/MM6yrp169i2bRvz58+3OX722Wdz8cUX07NnT/bu3cvDDz/MOeecw9q1a3FycmpwnYceeojZs2dbnxcVFREdLZsfCdHRGSbnui3t7a1wN3hF631VXP04tPYX/j34F97YHwItSFbY+R54d4e8fJvDqnAXJL8FsVdD0Ck6mdn1ga4UPeBu3WjA3aDq7VxbVawTn5CRtvcIGAz9b6p7brjYvp70hi6+OPhBvZHcznf0feJu17FUl8KW5yBgAPS9HkoOwc53Uc6eGJETWvQxCdGYDr0p3Pz58xk0aBCnnmpb0nz69OnW3w8aNIjBgwcTGxvL8uXLmThxYoPruLm54ebm1u7xCiHah0p+W/ccFCaj0n7WB0e+BOXZsPkZa0+EyvgN9nwCcbfC3k/1zq6BQ6D/LXrL+f1f66rJYWMh9mpdBwhQ5ipIWQBZa/XGbV7doNflGP7xLY7R6HGBzfPQ/hewYvVWIqu3UVZ5CR6uDX+Qsr6/w0v05m49LtKVj+sr2g3uIRjdJuvnHqGoyAlw8Lu6e7t4214v63dwcoUQ2/87MblgNJHcqZI0yN8Cw57E8Omlj/WeAVtfQPW6UhdSzFqjk6J+N+lE0aub3iE49SeQZEWcALvOWQkODsbJyYnMTNtJZpmZmYSHhx/z3JKSEv7v//6PG264odn79OrVi+DgYPbs2XNC8QohHFTva3QtnYgz9bDPqNfArfFhX8wVevfZuFm6GGFBEmx/WScBg+6D/rfC4V8hu96qxN0f6aQg7nYY/oz+kt/yPKo0w9pErbhaJ0MtFBfhQ7B7NXnlrqzak9NkO1WSBgf+pxOq+pWgLXz7QEUuKncTSim9i272umPXC8pYDqGjbIZvAChIQq25DbXuXtSuD/TQk0XRHnD2tCYqAAQMBAw4sqeujV9/22KHAYOhLN1amVqI42HXZMXV1ZWEhASWLl1qPWY2m1m6dCmjRo065rkLFiygoqKCq6++utn7pKamkpubS0RExAnHLIRwPIazpy4maHLFcPXXD6OJ/95UDfSZqYsN+vfXiUfhLuh3I4ZXFEbQKeAfBwU7dPPyHF2DJ/5ODP/+GB5hGNHn6m3xM1bUXdcjQs8XaansP4j3yWVBWi8W78hotIkyV0HS63r+iXtw4+/dry/E3QZJr8HK62Dt7TqO3tc2fs2ivVCSCuFn2L4QOBj63wyDH4Je03Upgq3P6xpEoId/XGx3IzUMJ3DxhsrCujauR+1Yatnev7Kg0XiEaAm7DwPNnj2ba6+9luHDh3Pqqafy8ssvU1JSwsyZMwGYMWMGUVFRzJ071+a8+fPnc+GFFzaYNFtcXMwTTzzBJZdcQnh4OHv37uX++++nd+/eTJ48+aS9LyGEgzK5YXjUmyfn6gfuwba9DK5+UFW7KrDkEGCGdfdiU5tEVesv6lrGqc+3OASVvwN2vktK4OXsLlbkJWVRY1Y4mY7qOdn3OXhGYoSNbfpaJWmw52NduyhgsE4K9n0Guz+Afjc2PCFjOXhFY/jG2hw2Quv9gOgdjfLqDutm66QtYGCL35sQ7cHuycrll19OdnY2jz32GBkZGQwdOpRFixZZJ90ePHgQk8n2J6SdO3eyatUqfvnllwbXc3JyYsuWLXz00UcUFBQQGRnJWWedxVNPPSXzUoQQugem2WMGWMqm1VQAJkh4Co7urTl6GKUFVEESbPs3xF5Fz7Az8HVfTG5JJZsO5ZPQI9C2ccEOKDmEWmEZkqqNafWtqB4XYMRcAge/Bd++GNGWFTfdUU5usOkpVMylei6J5eyacl1lOeaSZuM0PEJRLj5QlqmTFVf/ugTOcj1VU1uwsbb3xNUfKo/a+sHS6+IoE51Fh2T3ZAVg1qxZzJo1q9HXli9f3uBYv379aKr+ooeHBz///HNbhieE6AhMzmAZsmhL3j0AM1QW6WGjE6AKdsDWf0Ov6RiRE3ABzuwfyjebDvPLjsyGycqAu8BcWff8yD7Y+S4MfRQ89MZymCsbJlFNjfBnrwNzNYSNaT7Wity6ytEAvr2huhR1JAXDp6c+lr8DUODTu65NygKUubpu3kr+VvCIwHBpvKqzEC1h903hhBCiTbiHwJG9qPJsVNWRurkWJ8jwjIDQ0bDzbVT2n6iyLFTRXtTBb1G5f1nbqXX3oXL+bPI6Kr82UYk6C0JGoCoLUJUFnNNP74WyZEcmKudP1Lr76u7tEYbhFW194B6iX/CKxLD0ZgSdAjnrUYeX6NgKd8He/4BPrE2vCgDpyyE4wbr/ijW2mnLU3v+iivbozy9/G2x7CTzC9FwWwPCK0sNMu97T779wF+z5CEJPq7tP6GgwnHWbklS96ijtF+h2znF88kLUcYieFSGEOGHdpkDy2/DnA7q3YeRLbXftfjfBwW9g33/1cmcXH92LEHhKXZuydKgua/oamSv1SqRD3+lHrUSffrg4JbA3u4Ts/EpCytJbFZoRfroe3klbDHv/C86e4B+vJ8nWo0oPQ9EuGPRAI1cx6bk5mav0EmnXAAgcBDGXYpjq7bUSd5tOULbMBYzaTeFm1MXi7Ika/IDeFG7Do3pOT48LZY8VccIM1dR4ShdWVFSEn58fhYWF+Pr6Nn+CEEKcgGvm/8HK3Tk8dE5/bh4f2/wJQjiw9vgOlWEgIYSws7NqawVJFWYhGifJihBC2NnEuLrChrlS2FCIBiRZEUIIO4v092BglC9KwdLkLHuHI4TDkWRFCCEcwKQ4XWJEhoKEaEiSFSGEcACJ8XrflJW7symvqrFzNEI4FklWhBDCAcRH+BLl70F5lZlVu5subChEVyTJihBCOADDMJgkq4KEaJQkK0II4SAsycrS5ExqzLIFlhAWkqwIIYSDOLVnID7uzuQUV7LpUIG9wxHCYUiyIoQQDsLFycSZ/fREWxkKEqKOJCtCCOFA6uatZNg5EiEchyQrQgjhQMb3C8HFyWBvdgn7sovtHY4QDkGSFSGEcCC+7i6c1isIH3dnUnJK7B2OEA7B2d4BCCGEsPXCtCEEeLri6iw/TwoBkqwIIYTDCfN1t3cIQjgUSduFEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dAkWRFCCCGEQ5NkRQghhBAOTZIVIYQQQjg0SVaEEEII4dCc7R1AR1ZTU0NVVZW9wxCiU3BxccHJycneYQghHJAkK8dBKUVGRgYFBQX2DkWITsXf35/w8HAMw7B3KEIIByLJynGwJCqhoaF4enrKf6xCnCClFKWlpWRlZQEQERFh54iEEI5EkpVWqqmpsSYqQUFB9g5HiE7Dw8MDgKysLEJDQ2VISAhhJRNsW8kyR8XT09POkQjR+Vj+XclcMCFEfZKsHCcZ+hGi7cm/KyFEYyRZEUIIIYRDk2RFCCGEEA5NkhUhOoEzzjiDu+++u02udd1113HhhRe2ybWEEKItSLIi7Gbz5s1cccUVREdH4+HhQVxcHK+88kqz58XExGAYhs3j2Wefbfa85cuXM2zYMNzc3OjduzcffvjhMdvv37+/wX0Mw+D333+3tnn88cdtXvPz82PcuHGsWLGi2XiEEEK0jCxdFnazYcMGQkND+eSTT4iOjmbNmjXcdNNNODk5MWvWrGOe++STT3LjjTdan/v4+ByzfUpKCueeey633HILn376KUuXLuVvf/sbERERTJ48+ZjnLlmyhAEDBlifH71kfcCAASxZsgSAvLw8XnjhBc477zxSU1Px8/M75rU7I6UUNTU1ODvLfy9CiLYhPSttQClFaWX1SX8opVoVZ0lJCTNmzMDb25uIiAj+/e9/W4cPXnvtNQYOHGhtu3DhQgzD4K233rIeS0xM5JFHHrE+/+abbxg2bBju7u706tWLJ554gurqauvrhmHw3nvvcdFFF+Hp6UmfPn349ttvra9ff/31vPLKK4wfP55evXpx9dVXM3PmTL7++utm34uPjw/h4eHWh5eX1zHbv/XWW/Ts2ZN///vfxMXFMWvWLC699FJeeumlZu8VFBRkcy8XFxeb152dna2vxcfH8+STT1JcXMyuXbuavTbAwYMHueCCC/D29sbX15fLLruMzMxM6+uPP/44Q4cO5eOPPyYmJgY/Pz+mT5/OkSNHGr3ek08+afNnaTF06FAeffTRFsVUX0VFBXfeeSehoaG4u7szduxY/vzzT+vry5cvxzAMfvrpJxISEnBzc2PVqlXs3buXCy64gLCwMLy9vRkxYoQ1qRNCiNaQH33aQFlVDfGP/XzS77vjycl4urb8j/C+++5jxYoVfPPNN4SGhvLwww+zceNGhg4dyvjx47nzzjvJzs4mJCSEFStWEBwczPLly7nllluoqqpi7dq1PPjggwCsXLmSGTNm8OqrrzJu3Dj27t3LTTfdBMCcOXOs93ziiSf417/+xfPPP8+8efO46qqrOHDgAIGBgY3GWFhY2ORr9T377LM89dRTdO/enSuvvJJ77rnnmD/Jr127lsTERJtjkydPbtE8j/PPP5/y8nL6/n97dx4XVfX/D/w1DMyArCKyKIgIiIqyKMIDLEFFcYmkPq4fBdzJLBcQxM/nm2smmrmUfNCUwKUEN6i0NCMgIRRERtaoyIUKUIsdBIXz+8MH9+dlHwSGgffz8ZjHwzn33HPf7znd5nDumXuHD0dAQABef/31FuvW1NQgLCwMWlpasLCwaLPt+vp6bqASHx+PZ8+eYc2aNZg/fz7i4uK4enl5eYiOjsalS5dQXFyMefPmISgoCLt27WrS5rJly7B9+3akpKRg/PjxAIC0tDSkp6e3ayDYWEBAAC5cuIATJ07A2NgYe/fuhZubG3777TdeXwUGBmLfvn0YNmwY+vfvj/z8fMycORO7du2CWCzGyZMn4e7ujtzcXAwZMkTqOAghfRfNrPQRFRUVCA0Nxb59+zBlyhSMGTMGJ06c4GZCRo8eDW1tbW6tRVxcHPz8/Lj3ycnJePr0KZycnAA8H4QEBgbC29sbw4YNw9SpU7Fz504cPXqUd9wlS5Zg4cKFMDMzwwcffICKigokJyc3G+NPP/2EyMhIbtDTkrVr1yIiIgKxsbHw8fHBBx98gICAgFb3KSwshJ6eHq9MT08PZWVlqK6ubnYfNTU1fPTRRzh37hwuX76MV155BR4eHrzZIQDIyMiAmpoa1NTUoKKign379uHMmTPQ0NBoNSYAiImJQUZGBr744guMGzcODg4OOHnyJOLj43mzF/X19QgPD8fo0aPx6quvwtPTEzExMc22aWhoCDc3N4SFhXFlYWFh3AyWNCorKxESEoIPP/wQM2bMwKhRo3Ds2DGoqKggNDSUV3fHjh2YOnUqTE1Noa2tDWtra/j4+GD06NEwNzfHzp07YWpq2uTzI4SQttDMSidQURIie0fr6x666rjtlZeXh9raWjg4OHBl2tra3F//AoEAEydORFxcHFxdXZGdnY23334be/fuxc8//4z4+HiMHz+eu8PonTt3kJiYyPvLvq6uDk+ePEFVVRVXz8rKituuqqoKDQ0N7vkvL8rMzMTs2bOxdetWTJs2rdVcfH19uX9bWVlBJBLBx8cHu3fvhlgshpqaGrd98eLFvEtZ0tDR0eEda/z48fjrr7/w4Ycf8mZXLCwsuC/g8vJyREZGYu7cuYiNjYWdnV2rx8jJyYGRkRGMjIy4slGjRkFLSws5OTnczMjQoUN563IMDAya/RwbrFy5EsuWLcP+/fuhoKCAL774ol2XvBrLy8vD06dPMWHCBK5MSUkJ9vb2yMnJ4dVtnGtFRQW2bduGy5cvo6CgAM+ePUN1dTUePHggdRyEkL6NBiudQCAQSHU5pqdycXHBp59+iuvXr8PW1hYaGhrcACY+Ph7Ozs5c3YqKCmzfvh1vvvlmk3aUlZW5fzde3yEQCFBfX88ry87OxpQpU7Bq1Srempj2cnBwwLNnz3Dv3j1YWFhAIpFw2xpmN/T19XnrQACgqKgIGhoa3DNp2nusa9eu8cpEIhHMzMy497a2toiOjsbBgwdx+vRpqfNpTns+xxe5u7tDLBYjKioKIpEIT58+xZw5czollpY0Xje0ceNGXLt2Dfv27YOZmRlUVFQwZ84c1NbWdmkchJDeR/6/YUm7mJqaQklJCTdv3uTWCxQXF+OXX37hBiHOzs5Yv349zp07BxcXFwDPBzDff/89EhMT4efnx7U3duxY5Obm8r6kOyIrKwuTJ0+Gt7d3s+sv2kMikUBBQQG6uroA0GxMjo6O+Oabb3hl165dg6Ojo9THas8TgYVCYYuXl140cuRI5OfnIz8/n5tdyc7ORklJCUaNGiVVbC9SVFSEt7c3wsLCIBKJsGDBAqkGZQ1MTU0hEomQmJgIY2NjAM+f25OSktLmep/ExEQsWbIEb7zxBoDnA9x79+5JHQMhhNBgpY9QU1PD8uXL4e/vjwEDBkBXVxf//e9/oaDw/5ctWVlZoX///vjiiy9w6dIlAM8HKxs3boRAIOBdCtiyZQtee+01DBkyBHPmzIGCggLu3LmDzMxMvP/+++2KKTMzE5MnT4abmxt8fX1RWFgI4PkX/cCBAwE8Xyvj5eWFmJgYDB48GElJSbh58yYmTZoEdXV1JCUlYcOGDVi8eDH69+/f4rHeeustHD58GAEBAVi2bBl++OEHnD17FpcvX+bqHD58GFFRUdxakBMnTkAkEsHW1hYAcPHiRXz22Wc4fvw4r+1nz55xsTdcBsrOzsamTZva/AxcXV0xZswYLFq0CAcPHsSzZ8/w9ttvw9nZuc1LSG1ZsWIFRo4cCeD5wKEjVFVVsXr1avj7+0NbWxtDhgzB3r17UVVVheXLl7e6r7m5OS5evAh3d3cIBAK89957rc4GEUJIS2iw0od8+OGHqKiogLu7O9TV1eHn54fS0lJuu0AgwKuvvsotJgWeD2A0NDRgYWHBm+Z3c3PDpUuXsGPHDuzZswdKSkoYMWIEVqxY0e54zp8/j0ePHuH06dO8yyXGxsbcX+BVVVXIzc3lnsIrFosRERGBbdu2oaamBiYmJtiwYQNvbUlzTExMcPnyZWzYsAGHDh2CoaEhjh8/zrvHyuPHj5GXl8fbb+fOnbh//z4UFRUxYsQIREZGNrmckpWVxc229OvXD6ampggJCYGXl1ebn4FAIMCXX36Jd999FxMnToSCggKmT5+OTz75pM1922Jubg4nJyf8888/vLVK0goKCkJ9fT08PT1RXl4OOzs7XL16tdXBIQDs378fy5Ytg5OTE3R0dLBp0yaUlZV1OA5CSN8lYNLerKMPKCsrg6amJkpLS5v8ouPJkye4e/cuTExMeGsz5JWLiwtsbGxw8OBBWYdCOhljDObm5nj77bfbHMz1FL3t/CKkL2rtO7SjaGaFkF7o0aNHiIiIQGFhIZYuXSrrcAgh5KXQYIWQLvT555/Dx8en2W3GxsbIysrqkuPq6upCR0cHn376aZPLNS/+tLuxb7/9Fq+++mqXxEQIIR1Fg5U+7sW7pJLO9/rrr7e4XqTxz5E7U2tXd1/8aXdjgwcP7oJoCCHk5dBghZAupK6u3uZDFrvby/7cnBBCuhvdbr+DaF0yIZ2PzitCSHNosCKlhqn7qqoqGUdCSO/TcF515SUyQoj8octAUhIKhdDS0uKey9KvXz8IBAIZR0WIfGOMoaqqCg8fPoSWlhaEwvY/94oQ0vvRYKUD9PX1AaDVB8kRQqSnpaXFnV+EENKABisdIBAIYGBgAF1dXe7OqoSQl6OkpEQzKoSQZtFg5SUIhUL6nyshhBDSxXrEAtvg4GAMHToUysrKcHBwQHJycot1XVxcIBAImrxmzZrF1WGMYcuWLTAwMICKigpcXV3x66+/dkcqhBBCCOlkMh+sREZGwtfXF1u3bsXt27dhbW0NNze3FteDXLx4EQUFBdwrMzMTQqEQc+fO5ers3bsXH3/8MY4cOYKbN29CVVUVbm5uePLkSXelRQghhJBOIvMHGTo4OGD8+PE4fPgwAKC+vh5GRkZ49913ERgY2Ob+Bw8exJYtW1BQUABVVVUwxjBo0CD4+flh48aNAIDS0lLo6ekhPDwcCxYsaLPNrngIEyGEENIX9LoHGdbW1iI1NRWbN2/myhQUFODq6oqkpKR2tREaGooFCxZAVVUVAHD37l0UFhbC1dWVq6OpqQkHBwckJSU1O1ipqalBTU0N9760tBQA6HH2hBBCiJQavjs7cy5EpoOVx48fo66uDnp6erxyPT09/Pzzz23un5ycjMzMTISGhnJlhYWFXBuN22zY1tju3buxffv2JuVGRkZtxkAIIYSQpv7++29oamp2Slty/Wug0NBQjBkzBvb29i/VzubNm+Hr68u9LykpgbGxMR48eNBpH3RPVFZWBiMjI+Tn5/fqy12UZ+/TV3KlPHuXvpJnaWkphgwZAm1t7U5rU6aDFR0dHQiFQhQVFfHKi4qK2rwxVGVlJSIiIrBjxw5eecN+RUVFMDAw4LVpY2PTbFtisRhisbhJuaamZq/+D6qBhoYG5dmL9JU8gb6TK+XZu/SVPBUUOu83PDL9NZBIJMK4ceMQExPDldXX1yMmJgaOjo6t7nvu3DnU1NRg8eLFvHITExPo6+vz2iwrK8PNmzfbbJMQQgghPY/MLwP5+vrC29sbdnZ2sLe3x8GDB1FZWYmlS5cCALy8vDB48GDs3r2bt19oaCg8PDwwYMAAXrlAIMD69evx/vvvw9zcHCYmJnjvvfcwaNAgeHh4dFdahBBCCOkkMh+szJ8/H48ePcKWLVtQWFgIGxsbXLlyhVsg++DBgyZTSbm5uUhISMB3333XbJsBAQGorKzEqlWrUFJSgldeeQVXrlyBsrJyu2ISi8XYunVrs5eGehPKs3fpK3kCfSdXyrN3oTw7Tub3WSGEEEIIaY3M72BLCCGEENIaGqwQQgghpEejwQohhBBCejQarBBCCCGkR+uzg5Xg4GAMHToUysrKcHBwQHJycqv1z507hxEjRkBZWRljxozBN998002Rvhxp8gwPD4dAIOC92vsLKln68ccf4e7ujkGDBkEgECA6OrrNfeLi4jB27FiIxWKYmZkhPDy8y+N8WdLmGRcX16Q/BQJBi4+d6Cl2796N8ePHQ11dHbq6uvDw8EBubm6b+8nbOdqRPOXxHA0JCYGVlRV3IzRHR0d8++23re4jb30JSJ+nPPZlc4KCgrhbhrTmZfu0Tw5WIiMj4evri61bt+L27duwtraGm5sbHj582Gz9n376CQsXLsTy5cuRlpYGDw8PeHh4IDMzs5sjl460eQLP76xYUFDAve7fv9+NEXdMZWUlrK2tERwc3K76d+/exaxZszBp0iRIJBKsX78eK1aswNWrV7s40pcjbZ4NcnNzeX2qq6vbRRF2jvj4eKxZswY3btzAtWvX8PTpU0ybNg2VlZUt7iOP52hH8gTk7xw1NDREUFAQUlNTcevWLUyePBmzZ89GVlZWs/XlsS8B6fME5K8vG0tJScHRo0dhZWXVar1O6VPWB9nb27M1a9Zw7+vq6tigQYPY7t27m60/b948NmvWLF6Zg4MD8/Hx6dI4X5a0eYaFhTFNTc1uiq5rAGBRUVGt1gkICGCWlpa8svnz5zM3N7cujKxztSfP2NhYBoAVFxd3S0xd5eHDhwwAi4+Pb7GOvJ6jL2pPnr3hHGWMsf79+7Pjx483u6039GWD1vKU974sLy9n5ubm7Nq1a8zZ2ZmtW7euxbqd0ad9bmaltrYWqampcHV15coUFBTg6uqKpKSkZvdJSkri1QcANze3Fuv3BB3JEwAqKipgbGwMIyOjNv8qkFfy2J8vw8bGBgYGBpg6dSoSExNlHY7USktLAaDVh6L1hj5tT56AfJ+jdXV1iIiIQGVlZYuPP+kNfdmePAH57ss1a9Zg1qxZTfqqOZ3Rp31usPL48WPU1dVxd8htoKen1+K1/MLCQqnq9wQdydPCwgKfffYZvvzyS5w+fRr19fVwcnLCH3/80R0hd5uW+rOsrAzV1dUyiqrzGRgY4MiRI7hw4QIuXLgAIyMjuLi44Pbt27IOrd3q6+uxfv16TJgwAaNHj26xnjyeoy9qb57yeo5mZGRATU0NYrEYb731FqKiojBq1Khm68pzX0qTp7z2JQBERETg9u3bTR6D05LO6FOZ326f9ByOjo68vwKcnJwwcuRIHD16FDt37pRhZKQjLCwsYGFhwb13cnJCXl4eDhw4gFOnTskwsvZbs2YNMjMzkZCQIOtQulR785TXc9TCwgISiQSlpaU4f/48vL29ER8f3+IXubySJk957cv8/HysW7cO165d69YFwX1usKKjowOhUIiioiJeeVFREfT19ZvdR19fX6r6PUFH8mxMSUkJtra2+O2337oiRJlpqT81NDSgoqIio6i6h729vdx88b/zzju4dOkSfvzxRxgaGrZaVx7P0QbS5NmYvJyjIpEIZmZmAIBx48YhJSUFhw4dwtGjR5vUlee+lCbPxuSlL1NTU/Hw4UOMHTuWK6urq8OPP/6Iw4cPo6amBkKhkLdPZ/Rpn7sMJBKJMG7cOMTExHBl9fX1iImJafHaoqOjI68+AFy7dq3Va5Gy1pE8G6urq0NGRgYMDAy6KkyZkMf+7CwSiaTH9ydjDO+88w6ioqLwww8/wMTEpM195LFPO5JnY/J6jtbX16OmpqbZbfLYly1pLc/G5KUvp0yZgoyMDEgkEu5lZ2eHRYsWQSKRNBmoAJ3Upx1bByzfIiIimFgsZuHh4Sw7O5utWrWKaWlpscLCQsYYY56eniwwMJCrn5iYyBQVFdm+fftYTk4O27p1K1NSUmIZGRmySqFdpM1z+/bt7OrVqywvL4+lpqayBQsWMGVlZZaVlSWrFNqlvLycpaWlsbS0NAaA7d+/n6WlpbH79+8zxhgLDAxknp6eXP3ff/+d9evXj/n7+7OcnBwWHBzMhEIhu3LliqxSaBdp8zxw4ACLjo5mv/76K8vIyGDr1q1jCgoK7Pvvv5dVCu2yevVqpqmpyeLi4lhBQQH3qqqq4ur0hnO0I3nK4zkaGBjI4uPj2d27d1l6ejoLDAxkAoGAfffdd4yx3tGXjEmfpzz2ZUsa/xqoK/q0Tw5WGGPsk08+YUOGDGEikYjZ29uzGzducNucnZ2Zt7c3r/7Zs2fZ8OHDmUgkYpaWluzy5cvdHHHHSJPn+vXrubp6enps5syZ7Pbt2zKIWjoNP9Ft/GrIzdvbmzk7OzfZx8bGholEIjZs2DAWFhbW7XFLS9o89+zZw0xNTZmysjLT1tZmLi4u7IcffpBN8FJoLkcAvD7qDedoR/KUx3N02bJlzNjYmIlEIjZw4EA2ZcoU7gucsd7Rl4xJn6c89mVLGg9WuqJPBYwx1v55GEIIIYSQ7tXn1qwQQgghRL7QYIUQQgghPRoNVgghhBDSo9FghRBCCCE9Gg1WCCGEENKj0WCFEEIIIT0aDVYIIYQQ0qPRYIUQ0i2ePn0q6xAIIXKKBiuEkC4RFxeHOXPmwNTUFJqamjA2NkZfuwelp6cnPvjgA1mH0awrV67AxsYG9fX1sg6FkDbRYIWQbrJkyRIIBALuNWDAAEyfPh3p6emyDq3Tff7553B3d4ednR2ioqKQmpqKtLQ0CAQCWYfWbe7cuYNvvvkGa9eulXUozZo+fTqUlJTw+eefyzoUQtpEt9snpJssWbIERUVFCAsLAwAUFhbi//7v/5Ceno4HDx7IOLrOU1FRASMjI5w9exZTp06VdTgys2LFCigqKuLIkSOyDqVFwcHBCA8PR0pKiqxDIaRVNLNCSDcSi8XQ19eHvr4+bGxsEBgYiPz8fDx69AgAcO/ePQgEAkRERMDJyQnKysoYPXo04uPjee1kZmZixowZUFNTg56eHjw9PfH48WNuu4uLCwQCAS5evMjbz9bWFgKBAHFxcVzZpUuXYG1tDRUVFW7Wx8PDo9U8QkJCYGpqCpFIBAsLC5w6dYrbdv36daioqCAqKgqDBg1Cv3794OrqiqysLABAZWUlNDQ0cP78eV6b0dHRUFVVRXl5OcLDw6GlpcXb7uLigvXr13Pva2pqsHHjRgwePBiqqqpwcHDg5dVcGw2fr0QiAfD8UpVAIEBJSQlXx9PTEwKBANHR0VxZUlISHB0doaamxn1GNjY2LX4+dXV1OH/+PNzd3Vs8NgBs27aN105KSgqmTp0KHR0daGpqwtnZGbdv3+a1XVJSAh8fH+jp6XH/fVy6dKnFnBtIJBIIBALcu3ePK3N3d8etW7eQl5fXYi6E9AQ0WCFERioqKnD69GmYmZlhwIABvG3+/v7w8/NDWloaHB0d4e7ujr///hvA8y+ryZMnw9bWFrdu3cKVK1dQVFSEefPm8doYPHgwPv30U+59cnIyNyhqUFJSgvnz58PFxQXZ2dkoKCho0k5jUVFRWLduHfz8/JCZmQkfHx8sXboUsbGxAIBHjx6hoKAAcXFxiIiIwM2bN6Guro7p06ejuroaqqqqWLBgATfD1CAsLAxz5syBurp6uz6/d955B0lJSYiIiEB6ejrmzp2L6dOn49dff23X/s1JTU3FV1991aR8zpw5MDIyQlpaGgoKCuDn59dqO+np6SgtLYWdnZ1Uxy8vL4e3tzcSEhJw48YNmJubY+bMmSgvLwcA1NfXY8aMGUhMTMTp06eRnZ2NoKAgCIVCqY7TYMiQIdDT08P169c7tD8h3eblHgxNCGkvb29vJhQKmaqqKlNVVWUAmIGBAUtNTeXq3L17lwFgQUFBXNnTp0+ZoaEh27NnD2OMsZ07d7Jp06bx2s7Pz2cAWG5uLmPs+SPaV69ezXR1ddm9e/cYY4wtX76cvffeewwAi42NZYwxdvPmTQaA/fnnn7w4Z8+e3WIeTk5ObOXKlbyyuXPnspkzZzLGGAsLC2MAWGJiIre9rKyMaWlpsWPHjnHHFQqF7K+//mKMMVZUVMQUFRVZXFwcY4yxiIgIJhaLecd48TH09+/fZ0KhkBc3Y4xNmTKFbd68mYtDU1OTt73h801LS2OMMRYbG8sAsOLiYsYYYxMnTmQ7d+5kAFhUVBQXW+N8tm7dyqytrVv8jKKiophQKGT19fVcWWFhIQPAfvrpp3a3U1dXx9TV1dnXX3/NGGPs6tWrTEFBgevnxprLuUFaWhoDwO7evcsrt7W1Zdu2bWsxBkJ6AppZIaQbTZo0CRKJBBKJBMnJyXBzc8OMGTNw//59Xj1HR0fu34qKirCzs0NOTg6A5ws3Y2Njoaamxr1GjBgBALzpfJFIBE9PTxw/fhxlZWWIioqCl5cX7zhGRkZQVFTEmTNn2v2rkJycHEyYMIFXNmHCBC6+hpgdHBy49+rq6rC2tkZ2djYAwN7eHpaWljhx4gQA4PTp0zA2NsbEiRMBAJaWlqipqcGFCxeajSEjIwN1dXUYPnw473OIj4/nfQalpaW87ZaWli3mFR0djd9//73JrIm2tjY0NTVx9uzZdv/8urq6GmKxmLegWFdXFwMHDkRkZGSLn3VRURFWrlwJc3NzaGpqQkNDAxUVFdyaJolEAkNDQwwfPrzFYzfkrKGhAXNzc2zcuLHVuFVUVFBVVdWuvAiRFUVZB0BIX6KqqgozMzPu/fHjx6GpqYljx47h/fffb1cbFRUVcHd3x549e5psMzAw4L1ftWoVJk+eDD09PUybNg06OjpN6oeEhGDTpk3YvHkzRCIRampqMGvWrA5k91z//v1b3Pbil/eKFSsQHByMwMBAhIWFYenSpdz20aNHY9OmTZg7dy6UlZWhoKCA6upqbn1HRUUFhEIhUlNTm1wCUVNT4/6trq7OW/Px559/wsXFpUlcT58+RUBAAHbt2gUVFRXeNkVFRZw6dQqrV6/G4cOHoaysjNraWowaNarFPHV0dFBVVYXa2lqIRCIu9yNHjsDLywshISFQUlJq0o63tzf+/vtvHDp0CMbGxhCLxXB0dERtbS0ANImtOQ05M8aQnZ0Nb29v6Ovrw9XVtdn6//zzDwYOHNhmu4TIEs2sECJDAoGA+yJ+0Y0bN7h/P3v2DKmpqRg5ciQAYOzYscjKysLQoUNhZmbGe6mqqvLaGT58OMzNzfGf//wHK1eubDYGb29vjBgxAqtWrYJEIsHrr7/easwjR45EYmIirywxMZH70h0xYgSePXuGmzdvctvLy8tx584d3hfz4sWLcf/+fXz88cfcl+qLgoKCUFJSgvT0dEgkEt76D1tbW9TV1eHhw4dNPgN9fX2unoKCAm+bsbFxszmFhIRATU0Nnp6ezW53d3eHk5MT3N3dIZFI8NZbb7X6GTUMqhpmkhq8+eab+Oeff5CTk9NsO4mJiVi7di1mzpwJS0tLiMVi3sJpKysr/PHHH/jll19aPHZDzubm5pg9ezamTp3KW9T7oidPniAvLw+2trat5kOIrNHMCiHdqKamBoWFhQCA4uJiHD58mJspeVFwcDDMzc0xcuRIHDhwAMXFxVi2bBkAYM2aNTh27BgWLlyIgIAAaGtr47fffkNERASOHz/eZKZhz549SEhIwKRJk1BaWtokJj8/PwgEAhw4cABKSkpQV1fn/TqmMX9/f8ybNw+2trZwdXXF119/jYsXL+L7778HAFhYWGDGjBlYsWIFjh49Ci0tLWzZsgVqamr497//zbXTv39/vPnmm/D398e0adNgaGjY5FgaGhrQ0NAAwJ9VGD58OBYtWgQvLy989NFHsLW1xaNHjxATEwMrKyupZ4b27t2Lr7/+usX7wOzfvx8SiQQpKSnQ1NSEtrZ2q+0NHDgQY8eORUJCQpNfDYlEIgwbNgwAmrRjbm6OU6dOwc7ODmVlZfD39+fl7ezsjIkTJ+Jf//oX9u/fDzMzM/z8888QCASYPn06V+/JkyfczEpCQgLWrVvXbJw3btzgZm8I6cloZoWQbnTlyhUYGBjAwMAADg4OSElJwblz55pcmggKCkJQUBCsra2RkJCAr776iruEM2jQICQmJqKurg7Tpk3DmDFjsH79emhpaUFBoekpbW9vD19f32a/iM+cOYOzZ8/i7NmzUFJSalcOHh4eOHToEPbt2wdLS0scPXoUYWFhvBxOnjwJW1tbuLu7w8HBARUVFbh69WqTyxjLly9HbW0tNxCTRlhYGLy8vODn5wcLCwt4eHggJSUFQ4YMkbqtSZMmYdKkSc1uu379OrZv344LFy5AU1Oz3W2uWLFC6huuhYaGori4GGPHjoWnpyfWrl0LXV1dXp0LFy5g/PjxWLhwIUaNGoWAgADU1dVx20tLS6GiogJVVVW89tpreOONN+Dr69vs8c6cOYNFixahX79+UsVJSHejm8IR0oPcu3cPJiYmSEtLa/U+Hr3FqVOnsGHDBvz111/c2o7eorq6GhYWFoiMjOyRMxePHz+GhYUFbt26BRMTE1mHQ0ir6DIQIaTbVVVVoaCgAEFBQfDx8el1AxXg+WWrkydP8tac9CT37t3D//73PxqoELlAMyuE9CB9ZWZl27Zt2LVrFyZOnIgvv/yS9wseQghpjAYrhBBCCOnRaIEtIYQQQno0GqwQQgghpEejwQohhBBCejQarBBCCCGkR6PBCiGEEEJ6NBqsEEIIIaRHo8EKIYQQQno0GqwQQgghpEf7fw1cn3l9APSfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Qwen 2.5-0.5B - Instruct only LoRA\n"
      ],
      "metadata": {
        "id": "PsW9UJDcMSnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем модель и токенайзер"
      ],
      "metadata": {
        "id": "k-p9r5XeOJzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "5f75e1dad81d4f98a8fc23176ac9b1e9",
            "b6b30cf9b0ed418fa0ae79fed85f5f9d",
            "32cebbb8cafb4894afab3e9f61803d0c",
            "2bbb98f945144d57949ec31600ae1a63",
            "38e26098934b4529a08820c0f62284da",
            "6661e7227e1a416eb865b0fdbf723eea",
            "09fbe4bf5d474f3ba37ef998b15f1a9d",
            "5a61f090a007472dabb6a067cecf2888",
            "7fc83aedecd64cfe996f78d8904e2d24",
            "0bf39fcb86a9403a9dd4ce5df36b6731",
            "9dc8d078388c45aa82d05a6744f3ecfd",
            "bde5263313f14dd7974af3b37900d0af",
            "14e9055c58b040deb84332e340f7d0c8",
            "d5e4b40d1d99419684ccc0e61e7c4769",
            "4839db4c6f614c18b493fa1a9fa5bcfc",
            "aae026abe2a44d4f9c3e4d306f596e53",
            "14a8da54f6b54cec854157ea01479411",
            "a6a8a5e2e8d84898ac7c7978499d6ac6",
            "9018f8f24a9347afbbc897a66bf64a1a",
            "c9f8c0f30cfb48ce912bb754928e6bf3",
            "4f078cc5232248648ed8b9f4304cd6b0",
            "c32e10b7c81244baab288538c6789bf4",
            "f7347b45a850453fae5ad43878167c3b",
            "04c3af5b0d6a46e68cf42fc4f13ba237",
            "a362b0d0d2aa4b2cbf43273831561767",
            "9a9671342e5b4b03a02cb53de7d41680",
            "5df80f65b6b1411b9e76ce71f4b9c390",
            "0d9b1b1b6dec44c2904b957566911fb4",
            "8b69afc1897c4a4ca7bf42eed4e08387",
            "ae7e668fea2e4d719b8f16ee9a5a8f5b",
            "f23cab6e74ef43a0a0a661c8fcb060e5",
            "c92c446290a947dbb8fdad40e64cbc00",
            "ead0d76f67864f60a8f63429098e0b84",
            "491bfd5686454787b54c19ce4c879e10",
            "dd7c6916bb654badbb8be09874c64dd1",
            "9a8f40316d5c4d86833e55b8897b8ba6",
            "ea37a563467e4625b1f876e01a5e5ae9",
            "8d16c5e406e941cca58bbb998ee1d3d4",
            "aa301a14340b492a90a8fae8606881e8",
            "88c69a72d5bd4431b2b8dbbc830a06c2",
            "d9148f3c2062475aa711d4dd6eae03ea",
            "d4a249795ad244b6b5aef6191009fd92",
            "547a37ea310c4818a48e47a5ec8a2408",
            "723d2561419e43ad83d72d3bf45bb4d0",
            "194599d89f354f138d5a7160b5ceff56",
            "b6b62da3fb6a40c18d43ef55dff498bf",
            "ecf21e7c6eed4462ac7b9a8dc586595b",
            "adfdf8e5f05f495ebcf9608199387c3a",
            "bc593a848b9b46bc80db226b6df023f8",
            "f1cd90258d0f47a9b2bc5b0c1bdf1bd0",
            "bf233d1c37a1473db8d65fb9b37dcb96",
            "5abca94b4c5d401793acece8430ad217",
            "9a3184e6d0e64e5697e7478efaeb186d",
            "dd3d09aa0529426a9c537d9626578cec",
            "e1139a4e994e497cac3950d7af860221",
            "95320aaebea44139863b8d69b67f825a",
            "2d3f009656214b3db27ba74eb863cf32",
            "3679731329f44ad7bf637b5d31f4be6a",
            "62cda8c7dd9142c6b96c473ac6058635",
            "2ed62e930b434604b3b70052a3fa281a",
            "81917d44f2ee4574a883680a02dbebdb",
            "0cb48070cb394598ae8ce2a4c99bd25e",
            "c10c89f762844869a88a830083c56e4c",
            "d334a22e446e4163b7f636d14074cc3f",
            "ed0bdaf5925b470090b360f6b251de64",
            "d9b7b5499ef74fa3bc8d93ecf2dd0c17",
            "c2e816e24cee4ff38506fbdf561c6590",
            "ab6a9bdbb46446de9079d842a504a1f3",
            "c9e0950a53584ce1951c6494a7320453",
            "fbed3d31eed2479d99a210079d7bfed6",
            "551bf3ec955842aeaf1639d655443014",
            "934bb4b2d4b0413ab483e0b9e01136a0",
            "df4728374af74700a8ff70831fe2dca4",
            "b4094d731df84cffacbc7cd6efdcbde9",
            "3358f72568ea45ca872bd2b52f2341e8",
            "4afc073e2de545e884cf65c36b775f9b",
            "d31eab4229834d8f831903d179ae6e7f"
          ]
        },
        "id": "BkxZLiV9XeCF",
        "outputId": "b79af0a0-22aa-4ff2-acfc-943960c0d22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f75e1dad81d4f98a8fc23176ac9b1e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bde5263313f14dd7974af3b37900d0af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7347b45a850453fae5ad43878167c3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491bfd5686454787b54c19ce4c879e10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "194599d89f354f138d5a7160b5ceff56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95320aaebea44139863b8d69b67f825a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2e816e24cee4ff38506fbdf561c6590"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Внедряем адаптеры LoRA"
      ],
      "metadata": {
        "id": "zcMye1tEOOMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()  # Проверяем, сколько параметров обучается"
      ],
      "metadata": {
        "id": "GelzaAHcOCS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c9ff1b-3319-47e1-e79a-6c041d17dc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,081,344 || all params: 495,114,112 || trainable%: 0.2184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь займемся обработкой датасета ultrachat_200k. Во-первых необходимо уменьшить размер"
      ],
      "metadata": {
        "id": "iiUldhT4Oex6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_chat(example):\n",
        "    messages = example[\"messages\"]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    return {\"text\": text}\n",
        "\n",
        "train_dataset = datasets['uchat_train'].map(format_chat, remove_columns=[\"messages\"])\n",
        "test_dataset = datasets['uchat_test'].map(format_chat, remove_columns=[\"messages\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "889f4b26d3674035bd2c07415a2458f1",
            "630a4949057e41b6a21ec980bd8f6a8a",
            "c4fef17f02974fbcbfa74c59d01693ea",
            "f08fb3b79db5473f91d4d3ef805f94db",
            "3afa7fbdeb744332a480b0d4dc935007",
            "1d8f769d56e64800940de8712aed0f6d",
            "6b5cc69e12754297b53a19464c59ed45",
            "2efcc9b9245c4e8b888593eefd276936",
            "2c48b0fff3c5469e9e1747373d8432ec",
            "381099b81c22414ba23b8215fa9dc3c5",
            "960e4bb6dec54e88a2ad10004ac94886",
            "6ae447e0e2d341b889b671bf0a79fbb1",
            "c40f9fd254a9496e9a7db2fd038fef45",
            "35001240c8b549c1bd61ed2dea1b18c8",
            "6a576816b3e24270955cafcf7ca41d00",
            "daf6008760884f9cb44f10bbb624f676",
            "fcd5ed3a214f4a8b847e21eb4960f5f2",
            "4589eb432cd04b4eb6c0ffa6a5c28b82",
            "9dd1726b5fe24309b338f31844941dab",
            "dc1d62a81a8e4edd90e074d90854ea77",
            "e3bf4a5253704adeb8e4229dacb5dcea",
            "3b5a0cd46195462daab434f7d8e0ff8a"
          ]
        },
        "id": "vd1kHsmJPBMK",
        "outputId": "3c44f03c-02f1-4be4-a9af-bace90d07c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "889f4b26d3674035bd2c07415a2458f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/231 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ae447e0e2d341b889b671bf0a79fbb1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_response = tokenizer.encode('<|im_start|>assistant\\n')\n",
        "collator = DataCollatorForCompletionOnlyLM(\n",
        "    # явно указываем начало assistant-реплики, до нее включительно будет стоять -100 для подсчет Cross-Entropy\n",
        "    response_template=tokenized_response,\n",
        "    tokenizer=tokenizer,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "x_h5CjOjV0lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = SFTConfig(\n",
        "    output_dir=\"./qwen2_0.5B_instruct_sft\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=100,\n",
        "    save_steps=1000,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=300,\n",
        "    bf16=True,\n",
        "    optim=\"adamw_torch\",\n",
        "    report_to=\"tensorboard\",\n",
        "    dataset_text_field=\"text\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model.to(device),\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=collator,\n",
        "    peft_config=lora_config\n",
        ")"
      ],
      "metadata": {
        "id": "K7fbN0cHQbYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "9e-7m05GVYSp",
        "outputId": "f28d8252-344c-4600-b41a-b62ec2bc979c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1560 2:11:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.300800</td>\n",
              "      <td>1.283360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.256400</td>\n",
              "      <td>1.282033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.229100</td>\n",
              "      <td>1.281065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.273300</td>\n",
              "      <td>1.280703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.247000</td>\n",
              "      <td>1.280840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1560, training_loss=1.2710570897811497, metrics={'train_runtime': 7902.7638, 'train_samples_per_second': 0.789, 'train_steps_per_second': 0.197, 'total_flos': 1.3244808366163968e+16, 'train_loss': 1.2710570897811497})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пиковое значение использования GPU составляет 13.9 Gb"
      ],
      "metadata": {
        "id": "E4gNpuTLNoFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(\n",
        "    model=model,\n",
        "    model_id='./qwen2_0.5B_instruct_sft/checkpoint-1560',\n",
        "    peft_config=lora_config,\n",
        "    is_trainable=True\n",
        ")"
      ],
      "metadata": {
        "id": "KTSIHhoUMuwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "9077938685e147cbbad64cafab93501c",
            "65208b490bf44bffbc6417438b74343e",
            "aa1c5ab1624549bc8bc14abce6eda316",
            "976927f381134d4086756d5d1be5c49b",
            "8780e6c909354acabee6baaf2e56191d",
            "95b9d784e6e94c7c8f0dfbbb27980ab9",
            "9b44c117200b4f3a84607e5cc0593631",
            "9030305a422c4069ba4a3875ea0f7db3",
            "934a68a81ddc4601a962f4184ff39929",
            "f25932f71fa440adb3e949f00da79efd",
            "41de536d75744495ac1a8f8d2a0ce8a6",
            "fd308fe2c44b4795b5c2b753da93fc37",
            "23ac16c61b3f469881407bba72a45cdf",
            "350b2a08239f4e5780cc4d43e6b0960f",
            "1ba49290a4f149339ef061fcc0a7992f",
            "92d5b3fd7a66482d9184a75d0de69c23",
            "7dce531ed97447ed818dd53c7d93e020",
            "c59af4da09204ddb8c4973a40d43247d",
            "de9f1800d9754cdc8d24d763b8bbbd98",
            "26d0f02c364144248c113408a9f49135",
            "49a7bcdfedf943a9ba0f6c88e897d7d6",
            "15cfa5bd0d5548d9ba6f51a2022cebf1",
            "a07eff9134bf47dea8dca28ff8419c1e",
            "6c286393695c40f7a69068f254d7c4c9",
            "05e2e9c868c64ae3acad8e34a7cb9dac",
            "60ccd06e4cd2470a9176778312a5b968",
            "030623b1199b47e79b8dbc6b47c6d1ca",
            "d13770f1781b4bb188924ca57c0f8227",
            "de1f23f0a47745deae0da1150b7b6db6",
            "3dc6b44fef2b498090db87ade9546077",
            "941370c5b34b4d40b1fa5a468485d779",
            "ffb465e6c44048cdb378c1da6973a6e1",
            "766be20ab09d47dd8fe953866ac8dadd"
          ]
        },
        "outputId": "67f52afa-8238-4bb9-eeda-6afa06bba512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9077938685e147cbbad64cafab93501c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd308fe2c44b4795b5c2b753da93fc37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a07eff9134bf47dea8dca28ff8419c1e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(train_time, train_loss, label='train')\n",
        "plt.plot(train_time, val_loss, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "FrNM9_tbpNsx",
        "outputId": "d5f4db7d-1f43-418f-a197-4450cdf2ac52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib\n",
        "train_loss = [1.300800, 1.256400, 1.229100, 1.273300, 1.247000]\n",
        "val_loss = [1.283360, 1.282033, 1.281065, 1.280703, 1.280840]\n",
        "train_time = np.cumsum(np.ones(5) * 7902.7638 / 5 / 3600)\n",
        "memory_usage = np.ones(5) * 13.9\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.title('График обучения qwen2.5-0.5B')\n",
        "plt.xlabel('Время обучения (часы)')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.plot(train_time, train_loss, label='train')\n",
        "plt.plot(train_time, val_loss, label='val')\n",
        "\n",
        "theory_time = np.array([0, 2, 6, 8, 12]) + train_time[-1]\n",
        "theory_loss = np.array([0, 0, -0.07, -0.07, -0.1]) + train_loss[-1]\n",
        "plt.plot(theory_time, theory_loss, color='g', label='preds')\n",
        "\n",
        "plt.annotate('SFT', (train_time[-1], train_loss[-1]), textcoords=\"offset points\", xytext=(0,-10), ha='center')\n",
        "plt.annotate('iter0\\n generate_data', (theory_time[1], theory_loss[1]), textcoords=\"offset points\", xytext=(0,10), ha='center',)\n",
        "plt.annotate('iter1', (theory_time[2], theory_loss[2]), textcoords=\"offset points\", xytext=(0,-10), ha='center',)\n",
        "plt.annotate('iter1\\n generate_data', (theory_time[3], theory_loss[3]), textcoords=\"offset points\", xytext=(0,10), ha='center',)\n",
        "plt.annotate('iter2', (theory_time[4], theory_loss[4]), textcoords=\"offset points\", xytext=(0,-10), ha='center',)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "1NMFPqX9oKl1",
        "outputId": "f7f61302-f2c1-4fcd-e7f1-403939cd2560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SPIN"
      ],
      "metadata": {
        "id": "KYgrvJpkXVsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/uclaml/SPIN.git\n",
        "! python -m pip install SPIN/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvT9QcXUc_co",
        "outputId": "00d4a8e8-d056-45d3-9b8a-b25485d848bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SPIN'...\n",
            "remote: Enumerating objects: 603, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 603 (delta 140), reused 127 (delta 122), pack-reused 438 (from 1)\u001b[K\n",
            "Receiving objects: 100% (603/603), 3.58 MiB | 12.95 MiB/s, done.\n",
            "Resolving deltas: 100% (358/358), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем датасет ultrachat_200k в удобный шаблон для Instruct модели, также вставив место для сгененированного ответа"
      ],
      "metadata": {
        "id": "spwApzbPFExF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python SPIN/spin/reformat.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjilPkfmMgJk",
        "outputId": "70fe93fb-92a8-4559-8d53-b4cb190a0ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading readme: 100% 3.90k/3.90k [00:00<00:00, 20.3MB/s]\n",
            "Downloading data files:   0% 0/4 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/244M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/244M [00:00<00:07, 30.9MB/s]\u001b[A\n",
            "Downloading data:  13% 31.5M/244M [00:00<00:02, 83.4MB/s]\u001b[A\n",
            "Downloading data:  30% 73.4M/244M [00:00<00:01, 171MB/s] \u001b[A\n",
            "Downloading data:  43% 105M/244M [00:00<00:00, 193MB/s] \u001b[A\n",
            "Downloading data:  56% 136M/244M [00:00<00:00, 214MB/s]\u001b[A\n",
            "Downloading data:  69% 168M/244M [00:00<00:00, 230MB/s]\u001b[A\n",
            "Downloading data:  82% 199M/244M [00:01<00:00, 235MB/s]\u001b[A\n",
            "Downloading data: 100% 244M/244M [00:01<00:00, 178MB/s]\n",
            "\n",
            "Downloading data:   0% 0.00/244M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/244M [00:00<00:06, 35.1MB/s]\u001b[A\n",
            "Downloading data:  17% 41.9M/244M [00:00<00:01, 116MB/s] \u001b[A\n",
            "Downloading data:  26% 62.9M/244M [00:00<00:01, 134MB/s]\u001b[A\n",
            "Downloading data:  34% 83.9M/244M [00:00<00:01, 156MB/s]\u001b[A\n",
            "Downloading data:  43% 105M/244M [00:00<00:00, 169MB/s] \u001b[A\n",
            "Downloading data:  56% 136M/244M [00:00<00:00, 196MB/s]\u001b[A\n",
            "Downloading data:  64% 157M/244M [00:00<00:00, 196MB/s]\u001b[A\n",
            "Downloading data:  77% 189M/244M [00:01<00:00, 213MB/s]\u001b[A\n",
            "Downloading data: 100% 244M/244M [00:01<00:00, 168MB/s]\n",
            "\n",
            "Downloading data:   0% 0.00/244M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/244M [00:00<00:06, 33.5MB/s]\u001b[A\n",
            "Downloading data:  17% 41.9M/244M [00:00<00:01, 114MB/s] \u001b[A\n",
            "Downloading data:  30% 73.4M/244M [00:00<00:01, 170MB/s]\u001b[A\n",
            "Downloading data:  43% 105M/244M [00:00<00:00, 200MB/s] \u001b[A\n",
            "Downloading data:  56% 136M/244M [00:00<00:00, 211MB/s]\u001b[A\n",
            "Downloading data:  69% 168M/244M [00:00<00:00, 235MB/s]\u001b[A\n",
            "Downloading data:  82% 199M/244M [00:01<00:00, 254MB/s]\u001b[A\n",
            "Downloading data: 100% 244M/244M [00:01<00:00, 193MB/s]\n",
            "Downloading data files:  25% 1/4 [00:04<00:12,  4.09s/it]\n",
            "Downloading data:   0% 0.00/81.2M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  13% 10.5M/81.2M [00:00<00:02, 32.9MB/s]\u001b[A\n",
            "Downloading data:  52% 41.9M/81.2M [00:00<00:00, 117MB/s] \u001b[A\n",
            "Downloading data: 100% 81.2M/81.2M [00:00<00:00, 126MB/s]\n",
            "Downloading data files:  50% 2/4 [00:04<00:04,  2.06s/it]\n",
            "Downloading data:   0% 0.00/244M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/244M [00:00<00:06, 36.1MB/s]\u001b[A\n",
            "Downloading data:  22% 52.4M/244M [00:00<00:01, 143MB/s] \u001b[A\n",
            "Downloading data:  34% 83.9M/244M [00:00<00:00, 181MB/s]\u001b[A\n",
            "Downloading data:  47% 115M/244M [00:00<00:00, 197MB/s] \u001b[A\n",
            "Downloading data:  60% 147M/244M [00:00<00:00, 219MB/s]\u001b[A\n",
            "Downloading data:  73% 178M/244M [00:00<00:00, 233MB/s]\u001b[A\n",
            "Downloading data:  86% 210M/244M [00:01<00:00, 220MB/s]\u001b[A\n",
            "Downloading data: 100% 244M/244M [00:01<00:00, 174MB/s]\n",
            "\n",
            "Downloading data:   0% 0.00/243M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/243M [00:00<00:08, 29.0MB/s]\u001b[A\n",
            "Downloading data:  13% 31.5M/243M [00:00<00:02, 79.7MB/s]\u001b[A\n",
            "Downloading data:  30% 73.4M/243M [00:00<00:01, 168MB/s] \u001b[A\n",
            "Downloading data:  43% 105M/243M [00:00<00:00, 198MB/s] \u001b[A\n",
            "Downloading data:  56% 136M/243M [00:00<00:00, 222MB/s]\u001b[A\n",
            "Downloading data:  69% 168M/243M [00:00<00:00, 238MB/s]\u001b[A\n",
            "Downloading data:  82% 199M/243M [00:01<00:00, 257MB/s]\u001b[A\n",
            "Downloading data: 100% 243M/243M [00:01<00:00, 189MB/s]\n",
            "\n",
            "Downloading data:   0% 0.00/243M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   4% 10.5M/243M [00:00<00:08, 27.6MB/s]\u001b[A\n",
            "Downloading data:  17% 41.9M/243M [00:00<00:01, 104MB/s] \u001b[A\n",
            "Downloading data:  26% 62.9M/243M [00:00<00:01, 133MB/s]\u001b[A\n",
            "Downloading data:  34% 83.9M/243M [00:00<00:01, 132MB/s]\u001b[A\n",
            "Downloading data:  43% 105M/243M [00:00<00:00, 150MB/s] \u001b[A\n",
            "Downloading data:  52% 126M/243M [00:00<00:00, 165MB/s]\u001b[A\n",
            "Downloading data:  69% 168M/243M [00:01<00:00, 207MB/s]\u001b[A\n",
            "Downloading data:  82% 199M/243M [00:01<00:00, 181MB/s]\u001b[A\n",
            "Downloading data: 100% 243M/243M [00:01<00:00, 144MB/s]\n",
            "Downloading data files:  75% 3/4 [00:09<00:03,  3.12s/it]\n",
            "Downloading data:   0% 0.00/80.4M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  13% 10.5M/80.4M [00:00<00:01, 36.5MB/s]\u001b[A\n",
            "Downloading data:  52% 41.9M/80.4M [00:00<00:00, 122MB/s] \u001b[A\n",
            "Downloading data: 100% 80.4M/80.4M [00:00<00:00, 141MB/s]\n",
            "Downloading data files: 100% 4/4 [00:09<00:00,  2.42s/it]\n",
            "Extracting data files: 100% 4/4 [00:00<00:00, 1131.46it/s]\n",
            "Generating train_sft split: 100% 207865/207865 [00:05<00:00, 38459.63 examples/s]\n",
            "Generating test_sft split: 100% 23110/23110 [00:00<00:00, 41475.09 examples/s]\n",
            "Generating train_gen split: 100% 256032/256032 [00:04<00:00, 52883.09 examples/s]\n",
            "Generating test_gen split: 100% 28304/28304 [00:00<00:00, 53504.58 examples/s]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 15141.89it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1947.22it/s]\n",
            "Generating train split: 207865 examples [00:08, 23839.88 examples/s]\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 14979.66it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 2011.66it/s]\n",
            "Generating train split: 23110 examples [00:00, 34818.87 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Qwen 2.5-0.5B iter1"
      ],
      "metadata": {
        "id": "vDZ011rxKHUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем ответы на элементы датасета для тренировочной выборки"
      ],
      "metadata": {
        "id": "s9wM-Gg8FRDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import gather_object\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "import argparse\n",
        "import torch, time, json, os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "from accelerate.utils import InitProcessGroupKwargs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=36000))\n",
        "accelerator = Accelerator(kwargs_handlers=[kwargs])\n",
        "\n",
        "def parse_arguments():\n",
        "    \"\"\"Parse command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', type=str, default='UCLA-AGI/zephyr-7b-sft-full-SPIN-iter0')\n",
        "    parser.add_argument('--data_frac', type=int, default=0)\n",
        "    parser.add_argument('--frac_len', type=int, default=0)\n",
        "    parser.add_argument('--output_dir', type=str, default='generated/iter1')\n",
        "    parser.add_argument('--batch_size', type=int, default=16)\n",
        "    parser.add_argument('--input_dir', type=str, default='UCLA-AGI/SPIN_iter0')\n",
        "    parser.add_argument('--split', type=str, default='train')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def prepare_prompts(prompts, tokenizer, batch_size=4):\n",
        "    \"\"\"Prepare prompts for tokenization.\"\"\"\n",
        "    batches=[prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)]\n",
        "    batches_tok=[]\n",
        "    tokenizer.padding_side=\"left\"\n",
        "    for prompt_batch in batches:\n",
        "        batches_tok.append(\n",
        "            tokenizer(\n",
        "                prompt_batch,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='longest',\n",
        "                truncation=False,\n",
        "                pad_to_multiple_of=8,\n",
        "                add_special_tokens=False).to(\"cuda\")\n",
        "            )\n",
        "    tokenizer.padding_side=\"right\"\n",
        "    return batches_tok\n",
        "\n",
        "def main():\n",
        "    model_path = 'qwen2_0.5B_instruct_model_sft'\n",
        "    data_frac = 0\n",
        "    frac_len = 0\n",
        "    batch_size = 4\n",
        "    output_dir = 'test'\n",
        "    split = 'train'\n",
        "\n",
        "    # load a base model and tokenizer\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map={\"\": accelerator.process_index},\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # load data\n",
        "    data = load_dataset('reformatted', split=split + '[:1%]')\n",
        "    data = data.shuffle(seed=42)\n",
        "    if frac_len > 0:\n",
        "        sub_len = frac_len\n",
        "        if sub_len*(data_frac+1) > len(data):\n",
        "            data = data[sub_len*data_frac:]['real']\n",
        "        else:\n",
        "            data = data[sub_len*data_frac:sub_len*(data_frac+1)]['real']\n",
        "    else:\n",
        "        data = data[:]['real']\n",
        "\n",
        "    prompts_all = [\"### Instruction: \" + data[idx][0]['content'] + \"\\n\\n### Response: \" for idx in range(len(data))]\n",
        "    prompts_old = [data[idx][0]['content'] for idx in range(len(data))]\n",
        "    corrects_all = [data[idx][1]['content'] for idx in range(len(data))]\n",
        "\n",
        "    # sync GPUs and start the timer\n",
        "    accelerator.wait_for_everyone()\n",
        "    start=time.time()\n",
        "\n",
        "    # divide the prompt list onto the available GPUs\n",
        "    with accelerator.split_between_processes(prompts_all) as prompts:\n",
        "        results = []\n",
        "        prompt_batches=prepare_prompts(prompts, tokenizer, batch_size=batch_size)\n",
        "\n",
        "        for prompts_tokenized in tqdm(prompt_batches):\n",
        "            # set max_new_tokens smaller for faster inference\n",
        "            outputs_tokenized=model.generate(**prompts_tokenized, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "            # remove prompt from gen. tokens\n",
        "            outputs_tokenized=[ tok_out[len(tok_in):]\n",
        "                for tok_in, tok_out in zip(prompts_tokenized[\"input_ids\"], outputs_tokenized) ]\n",
        "            # decode gen. tokens\n",
        "            outputs=tokenizer.batch_decode(outputs_tokenized)\n",
        "            results.extend(outputs)\n",
        "\n",
        "    # collect results from all the GPUs and remove paddings\n",
        "    results_gathered=gather_object(results)\n",
        "    results = [r.replace(\"</s>\",\"\").lstrip() for r in results_gathered]\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        timediff=time.time()-start\n",
        "        print(f\"time elapsed: {timediff}\")\n",
        "\n",
        "        # collecting data\n",
        "        for idx in range(len(corrects_all)):\n",
        "            d = {\"real\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": corrects_all[idx]}], \"generated\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": results[idx]}]}\n",
        "            if split == 'test':\n",
        "                filename = f\"{output_dir}/loser_{data_frac}_test.jsonl\"\n",
        "            else:\n",
        "                filename = f\"{output_dir}/loser_{data_frac}.jsonl\"\n",
        "            with open(filename, 'a') as f:\n",
        "                json.dump(d, f)\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "jBzuFDrJOW_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "0162f31b-0e49-4161-e69b-2c9800fbe8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.aria.configuration_aria because of the following error (look up to see its traceback):\nNo module named 'transformers.models.aria.configuration_aria'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.aria.configuration_aria'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0b2ea71012fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0b2ea71012fa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# load a base model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_index\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         )\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;31m# Set the adapter kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"adapter_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             )\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    786\u001b[0m             )\n\u001b[1;32m    787\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         ]\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping_items\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    782\u001b[0m         mapping_items = [\n\u001b[1;32m    783\u001b[0m             (\n\u001b[0;32m--> 784\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0;31m# object at the top level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0mtransformers_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.aria.configuration_aria because of the following error (look up to see its traceback):\nNo module named 'transformers.models.aria.configuration_aria'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь для валидационной выборки"
      ],
      "metadata": {
        "id": "eOUdqc6FFf4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import gather_object\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "import argparse\n",
        "import torch, time, json, os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "from accelerate.utils import InitProcessGroupKwargs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=36000))\n",
        "accelerator = Accelerator(kwargs_handlers=[kwargs])\n",
        "\n",
        "def parse_arguments():\n",
        "    \"\"\"Parse command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', type=str, default='UCLA-AGI/zephyr-7b-sft-full-SPIN-iter0')\n",
        "    parser.add_argument('--data_frac', type=int, default=0)\n",
        "    parser.add_argument('--frac_len', type=int, default=0)\n",
        "    parser.add_argument('--output_dir', type=str, default='generated/iter1')\n",
        "    parser.add_argument('--batch_size', type=int, default=16)\n",
        "    parser.add_argument('--input_dir', type=str, default='UCLA-AGI/SPIN_iter0')\n",
        "    parser.add_argument('--split', type=str, default='train')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def prepare_prompts(prompts, tokenizer, batch_size=4):\n",
        "    \"\"\"Prepare prompts for tokenization.\"\"\"\n",
        "    batches=[prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)]\n",
        "    batches_tok=[]\n",
        "    tokenizer.padding_side=\"left\"\n",
        "    for prompt_batch in batches:\n",
        "        batches_tok.append(\n",
        "            tokenizer(\n",
        "                prompt_batch,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='longest',\n",
        "                truncation=False,\n",
        "                pad_to_multiple_of=8,\n",
        "                add_special_tokens=False).to(\"cuda\")\n",
        "            )\n",
        "    tokenizer.padding_side=\"right\"\n",
        "    return batches_tok\n",
        "\n",
        "def main():\n",
        "    model_path = 'qwen2_0.5B_instruct_model_sft'\n",
        "    data_frac = 0\n",
        "    frac_len = 0\n",
        "    batch_size = 4\n",
        "    output_dir = 'qwen_generated/iter0'\n",
        "    split = 'test'\n",
        "\n",
        "    # load a base model and tokenizer\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map={\"\": accelerator.process_index},\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # load data\n",
        "    data = load_dataset('reformatted', split=split + '[:1%]')\n",
        "    data = data.shuffle(seed=42)\n",
        "    if frac_len > 0:\n",
        "        sub_len = frac_len\n",
        "        if sub_len*(data_frac+1) > len(data):\n",
        "            data = data[sub_len*data_frac:]['real']\n",
        "        else:\n",
        "            data = data[sub_len*data_frac:sub_len*(data_frac+1)]['real']\n",
        "    else:\n",
        "        data = data[:]['real']\n",
        "\n",
        "    prompts_all = [\"### Instruction: \" + data[idx][0]['content'] + \"\\n\\n### Response: \" for idx in range(len(data))]\n",
        "    prompts_old = [data[idx][0]['content'] for idx in range(len(data))]\n",
        "    corrects_all = [data[idx][1]['content'] for idx in range(len(data))]\n",
        "\n",
        "    # sync GPUs and start the timer\n",
        "    accelerator.wait_for_everyone()\n",
        "    start=time.time()\n",
        "\n",
        "    # divide the prompt list onto the available GPUs\n",
        "    with accelerator.split_between_processes(prompts_all) as prompts:\n",
        "        results = []\n",
        "        prompt_batches=prepare_prompts(prompts, tokenizer, batch_size=batch_size)\n",
        "\n",
        "        for prompts_tokenized in tqdm(prompt_batches):\n",
        "            # set max_new_tokens smaller for faster inference\n",
        "            outputs_tokenized=model.generate(**prompts_tokenized, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "            # remove prompt from gen. tokens\n",
        "            outputs_tokenized=[ tok_out[len(tok_in):]\n",
        "                for tok_in, tok_out in zip(prompts_tokenized[\"input_ids\"], outputs_tokenized) ]\n",
        "            # decode gen. tokens\n",
        "            outputs=tokenizer.batch_decode(outputs_tokenized)\n",
        "            results.extend(outputs)\n",
        "\n",
        "    # collect results from all the GPUs and remove paddings\n",
        "    results_gathered=gather_object(results)\n",
        "    results = [r.replace(\"</s>\",\"\").lstrip() for r in results_gathered]\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        timediff=time.time()-start\n",
        "        print(f\"time elapsed: {timediff}\")\n",
        "\n",
        "        # collecting data\n",
        "        for idx in range(len(corrects_all)):\n",
        "            d = {\"real\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": corrects_all[idx]}], \"generated\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": results[idx]}]}\n",
        "            if split == 'test':\n",
        "                filename = f\"{output_dir}/loser_{data_frac}_test.jsonl\"\n",
        "            else:\n",
        "                filename = f\"{output_dir}/loser_{data_frac}.jsonl\"\n",
        "            with open(filename, 'a') as f:\n",
        "                json.dump(d, f)\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrCCZCl7pnLB",
        "outputId": "e0fd6d5d-92ba-4e90-8734-a243bdf81060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [13:27<00:00, 13.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time elapsed: 808.0595595836639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь соберем разрозненные части сгенерированного датасета в `.parquet`."
      ],
      "metadata": {
        "id": "xy4ACUNohyi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir qwen_datasets/iter0\n",
        "! python3 SPIN/spin/convert_data.py --num_fracs=3 --input_dir=qwen_generated/iter0 --output_dir=qwen_datasets/iter0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9niko34h56-",
        "outputId": "2259e3dd-58b8-460f-c8a5-b91b08b5e220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2079\n",
            "231\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 9532.51it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1230.36it/s]\n",
            "Generating train split: 2079 examples [00:00, 14534.38 examples/s]\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 14169.95it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1673.04it/s]\n",
            "Generating train split: 231 examples [00:00, 21048.97 examples/s]\n",
            "2079\n",
            "231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приступим ко второму этапу метода SPIN - обучение модели.\n",
        "Необходима более старая версия numpy"
      ],
      "metadata": {
        "id": "XB97S934YFtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install numpy==1.26.4\n",
        "! python3 SPIN/spin/run_spin.py config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dylACdcU3XB",
        "outputId": "465db713-8d25-46a7-bab3-f7cdb49e16e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "policy_generated_logps: tensor([-456.5797], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-601.7887], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.6421], device='cuda:0')\n",
            "logits: tensor([15.2387], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0301], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4938], device='cuda:0')\n",
            " 90% 5624/6237 [1:37:55<07:58,  1.28it/s]losses: tensor([0.0213], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-264.7897], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.7273], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-271.2528], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.7829], device='cuda:0')\n",
            "logits: tensor([38.4075], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6463], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1944], device='cuda:0')\n",
            " 90% 5625/6237 [1:37:56<10:16,  1.01s/it]losses: tensor([0.0458], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-824.9891], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-325.8984], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-841.5660], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-311.8777], device='cuda:0')\n",
            "logits: tensor([30.5977], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6577], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4021], device='cuda:0')\n",
            " 90% 5626/6237 [1:37:58<11:27,  1.12s/it]losses: tensor([0.3416], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-644.0555], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-352.8125], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-638.2000], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-337.9713], device='cuda:0')\n",
            "logits: tensor([8.9857], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5856], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4841], device='cuda:0')\n",
            " 90% 5627/6237 [1:37:59<11:49,  1.16s/it]losses: tensor([0.1055], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-125.0819], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.9684], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-136.0696], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.9962], device='cuda:0')\n",
            "logits: tensor([21.9599], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0988], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0972], device='cuda:0')\n",
            " 90% 5628/6237 [1:38:01<12:53,  1.27s/it]losses: tensor([0.0262], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-226.5206], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.2785], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-236.9732], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.4377], device='cuda:0')\n",
            "logits: tensor([36.2934], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0453], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5841], device='cuda:0')\n",
            " 90% 5629/6237 [1:38:01<11:43,  1.16s/it]losses: tensor([0.0632], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-401.7934], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.1708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-413.9679], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.0529], device='cuda:0')\n",
            "logits: tensor([27.2924], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2175], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5118], device='cuda:0')\n",
            "{'loss': 0.1042, 'learning_rate': 5.513985391056476e-08, 'rewards/real': 1.0884608030319214, 'rewards/generated': -1.5934927463531494, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6819534301757812, 'logps/generated': -407.51275634765625, 'logps/real': -412.1171875, 'logits/generated': -1.4441807270050049, 'logits/real': -1.452715277671814, 'epoch': 2.71}\n",
            " 90% 5630/6237 [1:38:02<10:17,  1.02s/it]losses: tensor([0.1389], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1021.5580], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.4537], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1022.3295], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.1859], device='cuda:0')\n",
            "logits: tensor([19.0392], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0771], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8268], device='cuda:0')\n",
            " 90% 5631/6237 [1:38:03<11:00,  1.09s/it]losses: tensor([0.0942], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-390.8478], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.0691], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-399.6425], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-319.7192], device='cuda:0')\n",
            "logits: tensor([23.1446], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8795], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4350], device='cuda:0')\n",
            " 90% 5632/6237 [1:38:04<10:16,  1.02s/it]losses: tensor([0.4293], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-573.8334], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-288.8454], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-579.8600], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-288.6385], device='cuda:0')\n",
            "logits: tensor([6.2335], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6027], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0207], device='cuda:0')\n",
            " 90% 5633/6237 [1:38:06<11:47,  1.17s/it]losses: tensor([0.0139], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-811.7419], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.2000], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-821.0822], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.8703], device='cuda:0')\n",
            "logits: tensor([42.6699], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9340], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3330], device='cuda:0')\n",
            " 90% 5634/6237 [1:38:07<11:24,  1.14s/it]losses: tensor([0.0873], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-411.9755], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.9948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-417.4619], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.5363], device='cuda:0')\n",
            "logits: tensor([23.9449], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5486], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8459], device='cuda:0')\n",
            " 90% 5635/6237 [1:38:07<09:42,  1.03it/s]losses: tensor([0.0913], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-789.7028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-374.2542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-802.5190], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.5908], device='cuda:0')\n",
            "logits: tensor([23.4797], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2816], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0663], device='cuda:0')\n",
            " 90% 5636/6237 [1:38:09<10:32,  1.05s/it]losses: tensor([0.4039], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-298.1284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.5682], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-301.2765], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-375.7364], device='cuda:0')\n",
            "logits: tensor([6.9799], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3148], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3832], device='cuda:0')\n",
            " 90% 5637/6237 [1:38:09<09:00,  1.11it/s]losses: tensor([0.0169], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-280.4012], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.8145], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-288.5342], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.2481], device='cuda:0')\n",
            "logits: tensor([40.6994], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8133], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2566], device='cuda:0')\n",
            " 90% 5638/6237 [1:38:10<07:55,  1.26it/s]losses: tensor([0.0549], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-291.2498], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.7517], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-297.3274], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-458.0793], device='cuda:0')\n",
            "logits: tensor([28.7500], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6078], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2672], device='cuda:0')\n",
            " 90% 5639/6237 [1:38:11<10:05,  1.01s/it]losses: tensor([0.2360], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-873.2792], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.9880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-864.1357], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.6063], device='cuda:0')\n",
            "logits: tensor([13.2382], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9143], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2382], device='cuda:0')\n",
            "{'loss': 0.1567, 'learning_rate': 5.424906467129877e-08, 'rewards/real': 0.5145081281661987, 'rewards/generated': -1.7672843933105469, 'rewards/accuracies': 1.0, 'rewards/margins': 2.281792163848877, 'logps/generated': -402.3939514160156, 'logps/real': -574.2717895507812, 'logits/generated': -1.7480475902557373, 'logits/real': -1.721213936805725, 'epoch': 2.71}\n",
            " 90% 5640/6237 [1:38:12<10:31,  1.06s/it]losses: tensor([0.1529], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-307.7195], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-355.8099], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-315.9646], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-346.0520], device='cuda:0')\n",
            "logits: tensor([18.0029], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8245], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9758], device='cuda:0')\n",
            " 90% 5641/6237 [1:38:13<09:00,  1.10it/s]losses: tensor([0.1025], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-588.9246], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-375.7677], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-598.5596], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.1410], device='cuda:0')\n",
            "logits: tensor([22.2618], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9635], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2627], device='cuda:0')\n",
            " 90% 5642/6237 [1:38:14<08:57,  1.11it/s]losses: tensor([0.1330], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-738.2860], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.0052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-740.0255], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.2396], device='cuda:0')\n",
            "logits: tensor([19.5051], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1740], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7766], device='cuda:0')\n",
            " 90% 5643/6237 [1:38:15<08:33,  1.16it/s]losses: tensor([0.1963], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-520.4496], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-494.7254], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-525.9610], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-484.9518], device='cuda:0')\n",
            "logits: tensor([15.2850], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5511], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9774], device='cuda:0')\n",
            " 90% 5644/6237 [1:38:16<10:27,  1.06s/it]losses: tensor([0.0684], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-610.4615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.9093], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-615.7042], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.6675], device='cuda:0')\n",
            "logits: tensor([26.4843], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5243], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1242], device='cuda:0')\n",
            " 91% 5645/6237 [1:38:17<09:16,  1.06it/s]losses: tensor([0.0888], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1330.8567], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-425.3124], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1328.6215], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.3084], device='cuda:0')\n",
            "logits: tensor([23.7688], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2235], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6004], device='cuda:0')\n",
            " 91% 5646/6237 [1:38:19<11:39,  1.18s/it]losses: tensor([0.1579], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-135.4835], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-349.3845], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-144.7620], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-341.0045], device='cuda:0')\n",
            "logits: tensor([17.6585], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9279], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8380], device='cuda:0')\n",
            " 91% 5647/6237 [1:38:19<09:39,  1.02it/s]losses: tensor([0.0877], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-261.6106], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-364.3443], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-274.5769], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.4131], device='cuda:0')\n",
            "logits: tensor([23.8976], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2966], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0931], device='cuda:0')\n",
            " 91% 5648/6237 [1:38:20<09:55,  1.01s/it]losses: tensor([0.4415], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-724.0149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-309.6648], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-727.6609], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-307.4250], device='cuda:0')\n",
            "logits: tensor([5.8859], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3646], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2240], device='cuda:0')\n",
            " 91% 5649/6237 [1:38:21<10:15,  1.05s/it]losses: tensor([0.0427], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-354.2225], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.6984], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-367.1938], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.3528], device='cuda:0')\n",
            "logits: tensor([31.3170], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2971], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8346], device='cuda:0')\n",
            "{'loss': 0.1472, 'learning_rate': 5.335827543203278e-08, 'rewards/real': 0.6700069904327393, 'rewards/generated': -1.3706622123718262, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0406694412231445, 'logps/generated': -390.7621765136719, 'logps/real': -557.2029418945312, 'logits/generated': -1.6992981433868408, 'logits/real': -1.4247788190841675, 'epoch': 2.72}\n",
            " 91% 5650/6237 [1:38:22<09:45,  1.00it/s]losses: tensor([0.0513], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-895.1239], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.2490], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-905.6719], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.3458], device='cuda:0')\n",
            "logits: tensor([29.4512], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0548], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8903], device='cuda:0')\n",
            " 91% 5651/6237 [1:38:23<09:13,  1.06it/s]losses: tensor([0.0450], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1115.7534], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.1042], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1125.2532], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.8131], device='cuda:0')\n",
            "logits: tensor([30.7909], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9500], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1291], device='cuda:0')\n",
            " 91% 5652/6237 [1:38:25<10:57,  1.12s/it]losses: tensor([0.2618], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-927.1680], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-359.2618], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-929.3298], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.3580], device='cuda:0')\n",
            "logits: tensor([12.0657], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2162], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9904], device='cuda:0')\n",
            " 91% 5653/6237 [1:38:26<11:52,  1.22s/it]losses: tensor([0.0756], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-780.0530], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.7552], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-778.6987], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.9515], device='cuda:0')\n",
            "logits: tensor([25.4493], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1354], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6804], device='cuda:0')\n",
            " 91% 5654/6237 [1:38:27<11:38,  1.20s/it]losses: tensor([0.1394], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-873.6754], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-478.4800], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-877.0892], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.8987], device='cuda:0')\n",
            "logits: tensor([18.9952], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3414], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5581], device='cuda:0')\n",
            " 91% 5655/6237 [1:38:28<11:32,  1.19s/it]losses: tensor([0.0410], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-263.5784], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-533.4257], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-278.1956], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-516.3013], device='cuda:0')\n",
            "logits: tensor([31.7417], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4617], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7124], device='cuda:0')\n",
            " 91% 5656/6237 [1:38:29<09:35,  1.01it/s]losses: tensor([0.0309], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-227.7290], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-469.3188], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-235.5380], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.5202], device='cuda:0')\n",
            "logits: tensor([34.6076], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7809], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6799], device='cuda:0')\n",
            " 91% 5657/6237 [1:38:29<08:16,  1.17it/s]losses: tensor([0.0413], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-242.1572], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.3410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.7413], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.2738], device='cuda:0')\n",
            "logits: tensor([31.6513], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6584], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5067], device='cuda:0')\n",
            " 91% 5658/6237 [1:38:31<09:49,  1.02s/it]losses: tensor([0.1594], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-360.8052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.5802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-370.9345], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.1558], device='cuda:0')\n",
            "logits: tensor([17.5537], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0129], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7424], device='cuda:0')\n",
            " 91% 5659/6237 [1:38:32<09:10,  1.05it/s]losses: tensor([0.1312], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1222.5986], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.6672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1229.1736], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.5957], device='cuda:0')\n",
            "logits: tensor([19.6465], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6575], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3072], device='cuda:0')\n",
            "{'loss': 0.0977, 'learning_rate': 5.2467486192766784e-08, 'rewards/real': 0.7998369932174683, 'rewards/generated': -1.7196929454803467, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5195300579071045, 'logps/generated': -424.81829833984375, 'logps/real': -690.8641967773438, 'logits/generated': -1.5364426374435425, 'logits/real': -1.5004525184631348, 'epoch': 2.72}\n",
            " 91% 5660/6237 [1:38:33<11:38,  1.21s/it]losses: tensor([0.0918], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-268.6946], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-453.7258], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-275.3040], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-436.9208], device='cuda:0')\n",
            "logits: tensor([23.4143], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6609], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6805], device='cuda:0')\n",
            " 91% 5661/6237 [1:38:35<12:39,  1.32s/it]losses: tensor([0.0625], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-224.3428], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.9624], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-231.1481], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.3571], device='cuda:0')\n",
            "logits: tensor([27.4107], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6805], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0605], device='cuda:0')\n",
            " 91% 5662/6237 [1:38:36<12:56,  1.35s/it]losses: tensor([0.1082], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-534.4772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.4642], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-541.0007], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.2957], device='cuda:0')\n",
            "logits: tensor([21.6920], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6523], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5169], device='cuda:0')\n",
            " 91% 5663/6237 [1:38:37<11:00,  1.15s/it]losses: tensor([0.1328], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-339.0941], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-398.7120], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-351.2426], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.3459], device='cuda:0')\n",
            "logits: tensor([19.5146], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2148], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7366], device='cuda:0')\n",
            " 91% 5664/6237 [1:38:38<09:09,  1.04it/s]losses: tensor([0.1529], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-213.1873], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.8954], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-224.0052], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.7045], device='cuda:0')\n",
            "logits: tensor([18.0088], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0818], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7191], device='cuda:0')\n",
            " 91% 5665/6237 [1:38:38<08:07,  1.17it/s]losses: tensor([0.1834], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-241.4720], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-245.3857], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-253.0334], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-240.9183], device='cuda:0')\n",
            "logits: tensor([16.0288], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1561], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4467], device='cuda:0')\n",
            " 91% 5666/6237 [1:38:39<08:32,  1.11it/s]losses: tensor([0.2443], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-295.1072], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.9659], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-293.5554], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-371.5648], device='cuda:0')\n",
            "logits: tensor([12.8493], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1552], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4401], device='cuda:0')\n",
            " 91% 5667/6237 [1:38:40<07:46,  1.22it/s]losses: tensor([0.5697], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-437.7922], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-270.0477], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-440.3084], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-269.9212], device='cuda:0')\n",
            "logits: tensor([2.6427], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2516], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0126], device='cuda:0')\n",
            " 91% 5668/6237 [1:38:41<08:16,  1.15it/s]losses: tensor([0.0125], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-593.9657], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-414.5575], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-609.6263], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.4358], device='cuda:0')\n",
            "logits: tensor([43.7823], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5661], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8122], device='cuda:0')\n",
            " 91% 5669/6237 [1:38:42<08:09,  1.16it/s]losses: tensor([0.1682], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1221.7961], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-474.3808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1224.8328], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.4436], device='cuda:0')\n",
            "logits: tensor([16.9738], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3037], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3937], device='cuda:0')\n",
            "{'loss': 0.1726, 'learning_rate': 5.15766969535008e-08, 'rewards/real': 0.7412762641906738, 'rewards/generated': -1.281898021697998, 'rewards/accuracies': 1.0, 'rewards/margins': 2.023174285888672, 'logps/generated': -390.0097351074219, 'logps/real': -436.992919921875, 'logits/generated': -1.8591333627700806, 'logits/real': -1.849361777305603, 'epoch': 2.73}\n",
            " 91% 5670/6237 [1:38:43<09:02,  1.04it/s]losses: tensor([0.0970], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-112.1814], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.4646], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-129.7674], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.2069], device='cuda:0')\n",
            "logits: tensor([22.8438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7586], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5258], device='cuda:0')\n",
            " 91% 5671/6237 [1:38:44<10:44,  1.14s/it]losses: tensor([0.0969], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-992.0797], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.4333], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-999.7620], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-350.2644], device='cuda:0')\n",
            "logits: tensor([22.8512], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7682], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5169], device='cuda:0')\n",
            " 91% 5672/6237 [1:38:46<10:53,  1.16s/it]losses: tensor([0.0606], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-515.9999], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.3870], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-511.9162], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.5688], device='cuda:0')\n",
            "logits: tensor([27.7345], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4084], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1818], device='cuda:0')\n",
            " 91% 5673/6237 [1:38:46<09:31,  1.01s/it]losses: tensor([0.1913], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-198.1481], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-248.5035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-209.9660], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-244.7514], device='cuda:0')\n",
            "logits: tensor([15.5700], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1818], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3752], device='cuda:0')\n",
            " 91% 5674/6237 [1:38:47<08:08,  1.15it/s]losses: tensor([0.1557], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-345.8723], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.1033], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-352.0143], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-351.4336], device='cuda:0')\n",
            "logits: tensor([17.8117], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6142], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1670], device='cuda:0')\n",
            " 91% 5675/6237 [1:38:48<07:53,  1.19it/s]losses: tensor([0.5115], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-266.3808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-252.0593], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-270.2892], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-251.9306], device='cuda:0')\n",
            "logits: tensor([4.0371], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3908], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0129], device='cuda:0')\n",
            " 91% 5676/6237 [1:38:48<07:38,  1.22it/s]losses: tensor([0.0314], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-622.3720], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.5859], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-629.4203], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.1911], device='cuda:0')\n",
            "logits: tensor([34.4431], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7048], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7395], device='cuda:0')\n",
            " 91% 5677/6237 [1:38:49<07:57,  1.17it/s]losses: tensor([0.1487], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-517.0199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-340.9790], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-537.2933], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-342.9491], device='cuda:0')\n",
            "logits: tensor([18.3033], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0273], device='cuda:0')\n",
            "generated_rewards: tensor([0.1970], device='cuda:0')\n",
            " 91% 5678/6237 [1:38:50<08:24,  1.11it/s]losses: tensor([0.0233], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-132.3283], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.0207], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-141.5794], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.7827], device='cuda:0')\n",
            "logits: tensor([37.4892], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9251], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8238], device='cuda:0')\n",
            " 91% 5679/6237 [1:38:51<08:44,  1.06it/s]losses: tensor([0.1323], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-186.1961], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.4586], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-192.3898], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.0927], device='cuda:0')\n",
            "logits: tensor([19.5597], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6194], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3366], device='cuda:0')\n",
            "{'loss': 0.1449, 'learning_rate': 5.068590771423481e-08, 'rewards/real': 0.8581957817077637, 'rewards/generated': -1.3482401371002197, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2064356803894043, 'logps/generated': -377.29949951171875, 'logps/real': -388.85784912109375, 'logits/generated': -1.3959850072860718, 'logits/real': -1.3704670667648315, 'epoch': 2.73}\n",
            " 91% 5680/6237 [1:38:52<07:32,  1.23it/s]losses: tensor([0.0279], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1143.3149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.1528], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1147.5320], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.7146], device='cuda:0')\n",
            "logits: tensor([35.6553], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4217], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1438], device='cuda:0')\n",
            " 91% 5681/6237 [1:38:53<09:41,  1.05s/it]losses: tensor([0.1109], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-279.8343], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.4013], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-285.0681], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.2056], device='cuda:0')\n",
            "logits: tensor([21.4295], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5234], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6196], device='cuda:0')\n",
            " 91% 5682/6237 [1:38:55<10:02,  1.09s/it]losses: tensor([0.0981], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1524.2588], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.9667], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1534.2034], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.1834], device='cuda:0')\n",
            "logits: tensor([22.7279], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9945], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2783], device='cuda:0')\n",
            " 91% 5683/6237 [1:38:56<11:41,  1.27s/it]losses: tensor([0.1073], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-518.5234], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.3879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-532.3748], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-425.4615], device='cuda:0')\n",
            "logits: tensor([21.7777], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3851], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7926], device='cuda:0')\n",
            " 91% 5684/6237 [1:38:57<10:12,  1.11s/it]losses: tensor([0.0459], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-124.1373], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.8177], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-138.5934], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.6988], device='cuda:0')\n",
            "logits: tensor([30.5750], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4456], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6119], device='cuda:0')\n",
            " 91% 5685/6237 [1:38:58<09:43,  1.06s/it]losses: tensor([0.1802], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-939.6233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-358.0083], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-946.6410], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-348.8013], device='cuda:0')\n",
            "logits: tensor([16.2247], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7018], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9207], device='cuda:0')\n",
            " 91% 5686/6237 [1:38:59<10:52,  1.18s/it]losses: tensor([0.0853], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-197.8538], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.2065], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-207.3116], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.4832], device='cuda:0')\n",
            "logits: tensor([24.1812], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9458], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4723], device='cuda:0')\n",
            " 91% 5687/6237 [1:39:00<09:09,  1.00it/s]losses: tensor([0.3258], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-642.3441], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1111.1381], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-649.1744], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1108.4280], device='cuda:0')\n",
            "logits: tensor([9.5404], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6830], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2710], device='cuda:0')\n",
            " 91% 5688/6237 [1:39:02<10:36,  1.16s/it]losses: tensor([0.2106], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-619.0005], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-300.0933], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-631.5951], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-298.1798], device='cuda:0')\n",
            "logits: tensor([14.5080], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2595], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1913], device='cuda:0')\n",
            " 91% 5689/6237 [1:39:03<10:49,  1.18s/it]losses: tensor([0.1024], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-158.5254], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.0151], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-172.4457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.6666], device='cuda:0')\n",
            "logits: tensor([22.2689], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3920], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8349], device='cuda:0')\n",
            "{'loss': 0.1294, 'learning_rate': 4.9795118474968816e-08, 'rewards/real': 0.9752370119094849, 'rewards/generated': -1.2136476039886475, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1888842582702637, 'logps/generated': -480.3187561035156, 'logps/real': -614.7415771484375, 'logits/generated': -1.6610771417617798, 'logits/real': -1.445204734802246, 'epoch': 2.74}\n",
            " 91% 5690/6237 [1:39:05<12:37,  1.38s/it]losses: tensor([0.0668], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-146.1166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.2527], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-162.0081], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.4251], device='cuda:0')\n",
            "logits: tensor([26.7191], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5892], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0828], device='cuda:0')\n",
            " 91% 5691/6237 [1:39:07<13:49,  1.52s/it]losses: tensor([0.1180], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.0308], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.9333], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-757.6843], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.8113], device='cuda:0')\n",
            "logits: tensor([20.7756], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2654], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8122], device='cuda:0')\n",
            " 91% 5692/6237 [1:39:07<11:46,  1.30s/it]losses: tensor([0.1484], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-969.0361], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.8637], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-973.1252], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.6244], device='cuda:0')\n",
            "logits: tensor([18.3284], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4089], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4239], device='cuda:0')\n",
            " 91% 5693/6237 [1:39:09<11:52,  1.31s/it]losses: tensor([0.3394], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-213.0233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-225.0744], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-221.8032], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-224.7930], device='cuda:0')\n",
            "logits: tensor([9.0614], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8780], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0281], device='cuda:0')\n",
            " 91% 5694/6237 [1:39:09<09:52,  1.09s/it]losses: tensor([0.2614], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-301.3965], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-372.3372], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-306.0640], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.9215], device='cuda:0')\n",
            "logits: tensor([12.0831], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4667], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7416], device='cuda:0')\n",
            " 91% 5695/6237 [1:39:10<08:18,  1.09it/s]losses: tensor([0.0487], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-222.4519], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-515.4084], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-226.2569], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-489.2345], device='cuda:0')\n",
            "logits: tensor([29.9789], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3805], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6174], device='cuda:0')\n",
            " 91% 5696/6237 [1:39:11<09:56,  1.10s/it]losses: tensor([0.2343], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-208.2818], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.3364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-212.8828], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.6191], device='cuda:0')\n",
            "logits: tensor([13.3182], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4601], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8717], device='cuda:0')\n",
            " 91% 5697/6237 [1:39:13<10:46,  1.20s/it]losses: tensor([0.3370], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-449.9615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-308.8292], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-454.9349], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-304.6570], device='cuda:0')\n",
            "logits: tensor([9.1457], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4973], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4172], device='cuda:0')\n",
            " 91% 5698/6237 [1:39:14<10:16,  1.14s/it]losses: tensor([0.0655], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-881.4661], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.2292], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-889.7875], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.6209], device='cuda:0')\n",
            "logits: tensor([26.9297], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8321], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8608], device='cuda:0')\n",
            " 91% 5699/6237 [1:39:15<10:09,  1.13s/it]losses: tensor([0.2284], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-479.5023], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.2353], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-484.6281], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.7559], device='cuda:0')\n",
            "logits: tensor([13.6052], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5126], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8479], device='cuda:0')\n",
            "{'loss': 0.1848, 'learning_rate': 4.8904329235702834e-08, 'rewards/real': 0.6290816068649292, 'rewards/generated': -1.1703717708587646, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7994534969329834, 'logps/generated': -398.25, 'logps/real': -462.62664794921875, 'logits/generated': -1.6529937982559204, 'logits/real': -1.676079511642456, 'epoch': 2.74}\n",
            " 91% 5700/6237 [1:39:15<08:53,  1.01it/s]losses: tensor([0.0319], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-275.4262], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-361.0141], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-284.8673], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-336.1530], device='cuda:0')\n",
            "logits: tensor([34.3022], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9441], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4861], device='cuda:0')\n",
            " 91% 5701/6237 [1:39:16<07:55,  1.13it/s]losses: tensor([0.0617], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-538.0005], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.2661], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-540.8242], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-309.5428], device='cuda:0')\n",
            "logits: tensor([27.5470], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2824], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4723], device='cuda:0')\n",
            " 91% 5702/6237 [1:39:17<07:39,  1.16it/s]losses: tensor([0.0375], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-236.8678], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.4148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-249.9235], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.8345], device='cuda:0')\n",
            "logits: tensor([32.6360], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3056], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9580], device='cuda:0')\n",
            " 91% 5703/6237 [1:39:17<06:46,  1.31it/s]losses: tensor([0.0971], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-551.5782], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.9583], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-557.1480], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.6965], device='cuda:0')\n",
            "logits: tensor([22.8316], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5570], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7262], device='cuda:0')\n",
            " 91% 5704/6237 [1:39:18<06:45,  1.31it/s]losses: tensor([0.0291], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-541.1680], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.0128], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-544.2584], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.8685], device='cuda:0')\n",
            "logits: tensor([35.2347], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3090], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2144], device='cuda:0')\n",
            " 91% 5705/6237 [1:39:19<06:58,  1.27it/s]losses: tensor([0.4767], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-183.2964], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-274.3393], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-193.4322], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-279.5449], device='cuda:0')\n",
            "logits: tensor([4.9302], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0136], device='cuda:0')\n",
            "generated_rewards: tensor([0.5206], device='cuda:0')\n",
            " 91% 5706/6237 [1:39:20<06:58,  1.27it/s]losses: tensor([0.1580], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-299.9622], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.9666], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-310.8760], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.2276], device='cuda:0')\n",
            "logits: tensor([17.6527], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0914], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6739], device='cuda:0')\n",
            " 92% 5707/6237 [1:39:21<07:44,  1.14it/s]losses: tensor([0.1243], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-722.8258], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.7252], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-728.5535], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.2269], device='cuda:0')\n",
            "logits: tensor([20.2260], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5728], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4498], device='cuda:0')\n",
            " 92% 5708/6237 [1:39:22<07:21,  1.20it/s]losses: tensor([0.2029], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-393.8294], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-392.3109], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-396.6259], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.1870], device='cuda:0')\n",
            "logits: tensor([14.9204], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2796], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2124], device='cuda:0')\n",
            " 92% 5709/6237 [1:39:22<06:52,  1.28it/s]losses: tensor([0.0972], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1136.9965], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-524.1505], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1139.6179], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-503.9540], device='cuda:0')\n",
            "logits: tensor([22.8179], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2621], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0196], device='cuda:0')\n",
            "{'loss': 0.1316, 'learning_rate': 4.8013539996436845e-08, 'rewards/real': 0.6617589592933655, 'rewards/generated': -1.6692289113998413, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3309876918792725, 'logps/generated': -394.3158264160156, 'logps/real': -487.99505615234375, 'logits/generated': -1.685614824295044, 'logits/real': -1.718545913696289, 'epoch': 2.75}\n",
            " 92% 5710/6237 [1:39:24<08:12,  1.07it/s]losses: tensor([0.0316], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-151.3235], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.8950], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-162.1446], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.3365], device='cuda:0')\n",
            "logits: tensor([34.3796], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0821], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3559], device='cuda:0')\n",
            " 92% 5711/6237 [1:39:25<10:01,  1.14s/it]losses: tensor([0.0247], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-393.7364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.4109], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-403.4983], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.2939], device='cuda:0')\n",
            "logits: tensor([36.8789], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9762], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7117], device='cuda:0')\n",
            " 92% 5712/6237 [1:39:26<08:22,  1.05it/s]losses: tensor([0.1175], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-825.5618], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-360.4658], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-832.7653], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-346.8458], device='cuda:0')\n",
            "logits: tensor([20.8235], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7204], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3620], device='cuda:0')\n",
            " 92% 5713/6237 [1:39:27<09:06,  1.04s/it]losses: tensor([0.0349], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-262.6217], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.7561], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-274.6436], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-361.4062], device='cuda:0')\n",
            "logits: tensor([33.3717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2022], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1350], device='cuda:0')\n",
            " 92% 5714/6237 [1:39:28<08:02,  1.08it/s]losses: tensor([0.1143], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-455.9049], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.3728], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-456.5890], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.9451], device='cuda:0')\n",
            "logits: tensor([21.1118], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0684], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0428], device='cuda:0')\n",
            " 92% 5715/6237 [1:39:28<07:29,  1.16it/s]losses: tensor([0.1148], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-342.0955], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.0448], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-353.6357], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.5179], device='cuda:0')\n",
            "logits: tensor([21.0672], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1540], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9527], device='cuda:0')\n",
            " 92% 5716/6237 [1:39:29<07:39,  1.13it/s]losses: tensor([18.8662], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-144.8770], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-3357.0693], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-156.5107], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-3557.3647], device='cuda:0')\n",
            "logits: tensor([-188.6616], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1634], device='cuda:0')\n",
            "generated_rewards: tensor([20.0295], device='cuda:0')\n",
            " 92% 5717/6237 [1:39:30<07:31,  1.15it/s]losses: tensor([0.0424], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-371.8474], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.9034], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-378.9097], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.5710], device='cuda:0')\n",
            "logits: tensor([31.3948], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7062], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4332], device='cuda:0')\n",
            " 92% 5718/6237 [1:39:31<06:56,  1.25it/s]losses: tensor([0.2247], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-666.4707], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.7946], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-666.6499], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.1882], device='cuda:0')\n",
            "logits: tensor([13.7856], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0179], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3606], device='cuda:0')\n",
            " 92% 5719/6237 [1:39:32<07:54,  1.09it/s]losses: tensor([0.5129], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-937.1808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-326.0923], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-938.4569], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-323.3658], device='cuda:0')\n",
            "logits: tensor([4.0026], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1276], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2727], device='cuda:0')\n",
            "{'loss': 2.0084, 'learning_rate': 4.7211829681097454e-08, 'rewards/real': 0.721839189529419, 'rewards/generated': 0.44029903411865234, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 0.281540185213089, 'logps/generated': -706.8804931640625, 'logps/real': -455.1619567871094, 'logits/generated': -1.4477189779281616, 'logits/real': -1.9147472381591797, 'epoch': 2.75}\n",
            " 92% 5720/6237 [1:39:33<08:17,  1.04it/s]losses: tensor([0.1528], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-902.1802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.4418], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-903.0774], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.3254], device='cuda:0')\n",
            "logits: tensor([18.0135], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0897], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7116], device='cuda:0')\n",
            " 92% 5721/6237 [1:39:34<08:45,  1.02s/it]losses: tensor([0.1656], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-799.1731], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.2785], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-806.7734], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-337.7363], device='cuda:0')\n",
            "logits: tensor([17.1426], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7600], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9542], device='cuda:0')\n",
            " 92% 5722/6237 [1:39:35<09:08,  1.07s/it]losses: tensor([0.1198], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-760.2584], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.5591], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-764.2374], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.9258], device='cuda:0')\n",
            "logits: tensor([20.6123], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3979], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6633], device='cuda:0')\n",
            " 92% 5723/6237 [1:39:36<08:36,  1.00s/it]losses: tensor([0.1934], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-773.7109], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.7130], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-774.2561], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.8101], device='cuda:0')\n",
            "logits: tensor([15.4481], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0545], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4903], device='cuda:0')\n",
            " 92% 5724/6237 [1:39:37<09:13,  1.08s/it]losses: tensor([0.2166], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1036.5594], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.8753], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1037.3424], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.4622], device='cuda:0')\n",
            "logits: tensor([14.1960], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0783], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3413], device='cuda:0')\n",
            " 92% 5725/6237 [1:39:39<10:25,  1.22s/it]losses: tensor([0.0173], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-136.8599], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-490.0726], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-149.5145], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.2705], device='cuda:0')\n",
            "logits: tensor([40.4566], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2655], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7802], device='cuda:0')\n",
            " 92% 5726/6237 [1:39:40<10:19,  1.21s/it]losses: tensor([0.0620], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-742.7371], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-402.0549], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-753.5588], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.3901], device='cuda:0')\n",
            "logits: tensor([27.4866], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0822], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6665], device='cuda:0')\n",
            " 92% 5727/6237 [1:39:41<09:05,  1.07s/it]losses: tensor([0.1766], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-606.6931], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-335.9553], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-615.2603], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-328.0807], device='cuda:0')\n",
            "logits: tensor([16.4419], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8567], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7875], device='cuda:0')\n",
            " 92% 5728/6237 [1:39:42<08:46,  1.03s/it]losses: tensor([0.4561], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-198.9329], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-544.1898], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-206.8847], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-546.6584], device='cuda:0')\n",
            "logits: tensor([5.4832], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7952], device='cuda:0')\n",
            "generated_rewards: tensor([0.2469], device='cuda:0')\n",
            " 92% 5729/6237 [1:39:43<10:03,  1.19s/it]losses: tensor([0.0479], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.3822], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.4839], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-764.1987], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.1478], device='cuda:0')\n",
            "logits: tensor([30.1527], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8817], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1336], device='cuda:0')\n",
            "{'loss': 0.1608, 'learning_rate': 4.632104044183146e-08, 'rewards/real': 0.6261662244796753, 'rewards/generated': -1.4281682968139648, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0543344020843506, 'logps/generated': -426.46240234375, 'logps/real': -671.2486572265625, 'logits/generated': -2.129439353942871, 'logits/real': -2.070647954940796, 'epoch': 2.76}\n",
            " 92% 5730/6237 [1:39:45<10:01,  1.19s/it]losses: tensor([0.0651], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1007.5311], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-511.2542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1011.7872], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-488.5182], device='cuda:0')\n",
            "logits: tensor([26.9921], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4256], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2736], device='cuda:0')\n",
            " 92% 5731/6237 [1:39:46<09:47,  1.16s/it]losses: tensor([0.1127], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-535.7710], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.1346], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-543.7568], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.8584], device='cuda:0')\n",
            "logits: tensor([21.2620], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7986], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3276], device='cuda:0')\n",
            " 92% 5732/6237 [1:39:47<08:59,  1.07s/it]losses: tensor([0.0288], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.4870], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-484.9364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-302.1686], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-463.2836], device='cuda:0')\n",
            "logits: tensor([35.3344], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3682], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1653], device='cuda:0')\n",
            " 92% 5733/6237 [1:39:48<10:09,  1.21s/it]losses: tensor([0.1474], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-438.1602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.3716], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-449.0123], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-354.8237], device='cuda:0')\n",
            "logits: tensor([18.3999], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0852], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7548], device='cuda:0')\n",
            " 92% 5734/6237 [1:39:49<08:52,  1.06s/it]losses: tensor([0.0552], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-369.2710], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.5107], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-388.5062], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-464.0598], device='cuda:0')\n",
            "logits: tensor([28.6862], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.9235], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9451], device='cuda:0')\n",
            " 92% 5735/6237 [1:39:50<10:01,  1.20s/it]losses: tensor([0.0951], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-326.9436], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.5846], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-339.3195], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.9099], device='cuda:0')\n",
            "logits: tensor([23.0506], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2376], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0675], device='cuda:0')\n",
            " 92% 5736/6237 [1:39:51<08:17,  1.01it/s]losses: tensor([0.0193], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-106.0013], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.7991], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-119.8593], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.2635], device='cuda:0')\n",
            "logits: tensor([39.3936], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3858], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5536], device='cuda:0')\n",
            " 92% 5737/6237 [1:39:52<08:26,  1.01s/it]losses: tensor([0.0296], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-191.7549], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-517.4103], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-200.2079], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-490.8217], device='cuda:0')\n",
            "logits: tensor([35.0415], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8453], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6589], device='cuda:0')\n",
            " 92% 5738/6237 [1:39:53<09:06,  1.09s/it]losses: tensor([0.1446], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-444.9446], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-313.9613], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-452.7552], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-303.1681], device='cuda:0')\n",
            "logits: tensor([18.6039], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7811], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0793], device='cuda:0')\n",
            " 92% 5739/6237 [1:39:54<08:27,  1.02s/it]losses: tensor([0.1619], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-324.7116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.7485], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-332.7278], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.3753], device='cuda:0')\n",
            "logits: tensor([17.3894], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8016], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9373], device='cuda:0')\n",
            "{'loss': 0.086, 'learning_rate': 4.5430251202565475e-08, 'rewards/real': 1.065245270729065, 'rewards/generated': -1.5762895345687866, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6415345668792725, 'logps/generated': -439.97113037109375, 'logps/real': -403.3576354980469, 'logits/generated': -1.569075345993042, 'logits/real': -1.4985300302505493, 'epoch': 2.76}\n",
            " 92% 5740/6237 [1:39:55<09:21,  1.13s/it]losses: tensor([0.0417], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-255.2372], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.3346], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-273.3500], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.8802], device='cuda:0')\n",
            "logits: tensor([31.5673], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8113], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3454], device='cuda:0')\n",
            " 92% 5741/6237 [1:39:57<10:47,  1.31s/it]losses: tensor([0.0702], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-601.3112], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-369.5266], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-611.0571], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.0628], device='cuda:0')\n",
            "logits: tensor([26.2097], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9746], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6464], device='cuda:0')\n",
            " 92% 5742/6237 [1:39:58<10:40,  1.29s/it]losses: tensor([0.2893], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-671.7877], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-344.8434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-676.6166], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-338.7504], device='cuda:0')\n",
            "logits: tensor([10.9219], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4829], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6093], device='cuda:0')\n",
            " 92% 5743/6237 [1:40:00<10:30,  1.28s/it]losses: tensor([0.0385], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-192.4894], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.3895], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-203.8645], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.3911], device='cuda:0')\n",
            "logits: tensor([32.3734], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1375], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0998], device='cuda:0')\n",
            " 92% 5744/6237 [1:40:01<10:07,  1.23s/it]losses: tensor([0.2202], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-169.8944], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-270.7191], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-182.0869], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-268.8992], device='cuda:0')\n",
            "logits: tensor([14.0125], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2193], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1820], device='cuda:0')\n",
            " 92% 5745/6237 [1:40:01<08:34,  1.05s/it]losses: tensor([0.1712], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-381.1879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-320.2506], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-396.6224], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-318.9070], device='cuda:0')\n",
            "logits: tensor([16.7780], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5434], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1344], device='cuda:0')\n",
            " 92% 5746/6237 [1:40:02<08:14,  1.01s/it]losses: tensor([0.0139], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-329.8013], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.8043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-341.9896], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.3066], device='cuda:0')\n",
            "logits: tensor([42.6860], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2188], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0498], device='cuda:0')\n",
            " 92% 5747/6237 [1:40:03<07:56,  1.03it/s]losses: tensor([0.1270], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-849.0967], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-353.5970], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-851.7982], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-336.3049], device='cuda:0')\n",
            "logits: tensor([19.9936], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2701], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7292], device='cuda:0')\n",
            " 92% 5748/6237 [1:40:04<08:37,  1.06s/it]losses: tensor([0.0279], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-167.3510], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.4277], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.8414], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.2700], device='cuda:0')\n",
            "logits: tensor([35.6481], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9490], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6158], device='cuda:0')\n",
            " 92% 5749/6237 [1:40:05<08:02,  1.01it/s]losses: tensor([0.0394], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-880.9672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.9993], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-892.2957], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.1896], device='cuda:0')\n",
            "logits: tensor([32.1383], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1329], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0810], device='cuda:0')\n",
            "{'loss': 0.1039, 'learning_rate': 4.453946196329948e-08, 'rewards/real': 1.0739842653274536, 'rewards/generated': -1.549304485321045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.623289108276367, 'logps/generated': -375.38922119140625, 'logps/real': -449.91241455078125, 'logits/generated': -1.2578603029251099, 'logits/real': -1.2174158096313477, 'epoch': 2.77}\n",
            " 92% 5750/6237 [1:40:07<08:39,  1.07s/it]losses: tensor([0.0824], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-276.5437], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.8958], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-274.8590], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-473.6580], device='cuda:0')\n",
            "logits: tensor([24.5531], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1685], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6238], device='cuda:0')\n",
            " 92% 5751/6237 [1:40:08<09:47,  1.21s/it]losses: tensor([0.2564], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1042.9358], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-354.9847], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1046.9630], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-346.7123], device='cuda:0')\n",
            "logits: tensor([12.2997], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4027], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8272], device='cuda:0')\n",
            " 92% 5752/6237 [1:40:09<10:12,  1.26s/it]losses: tensor([0.0852], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-402.8293], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-542.6094], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-410.2037], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-525.7853], device='cuda:0')\n",
            "logits: tensor([24.1985], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7374], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6824], device='cuda:0')\n",
            " 92% 5753/6237 [1:40:10<08:49,  1.09s/it]losses: tensor([0.1957], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-916.4909], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-491.5773], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-910.3265], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-470.0975], device='cuda:0')\n",
            "logits: tensor([15.3153], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6164], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1480], device='cuda:0')\n",
            " 92% 5754/6237 [1:40:11<09:01,  1.12s/it]losses: tensor([0.0619], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-176.3152], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-444.8320], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.3283], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.3421], device='cuda:0')\n",
            "logits: tensor([27.5030], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2013], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5490], device='cuda:0')\n",
            " 92% 5755/6237 [1:40:13<10:40,  1.33s/it]losses: tensor([0.0581], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-921.1682], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.9813], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-933.2621], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.9155], device='cuda:0')\n",
            "logits: tensor([28.1597], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2094], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6066], device='cuda:0')\n",
            " 92% 5756/6237 [1:40:14<10:12,  1.27s/it]losses: tensor([0.1149], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-551.3876], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.6520], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-554.1579], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-458.3655], device='cuda:0')\n",
            "logits: tensor([21.0568], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2770], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8286], device='cuda:0')\n",
            " 92% 5757/6237 [1:40:15<08:32,  1.07s/it]losses: tensor([0.0239], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-99.4294], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.0564], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-114.0254], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.4388], device='cuda:0')\n",
            "logits: tensor([37.2136], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4596], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2618], device='cuda:0')\n",
            " 92% 5758/6237 [1:40:16<09:00,  1.13s/it]losses: tensor([0.2086], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-414.1739], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.7166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-417.7273], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.6570], device='cuda:0')\n",
            "logits: tensor([14.6130], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3553], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1060], device='cuda:0')\n",
            " 92% 5759/6237 [1:40:17<08:01,  1.01s/it]losses: tensor([0.0962], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-107.4677], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.2043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-115.6210], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.4346], device='cuda:0')\n",
            "logits: tensor([22.9231], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8153], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4770], device='cuda:0')\n",
            "{'loss': 0.1183, 'learning_rate': 4.364867272403349e-08, 'rewards/real': 0.5673235654830933, 'rewards/generated': -1.7110321521759033, 'rewards/accuracies': 1.0, 'rewards/margins': 2.278355836868286, 'logps/generated': -458.25103759765625, 'logps/real': -490.8741760253906, 'logits/generated': -1.4877480268478394, 'logits/real': -1.2862763404846191, 'epoch': 2.77}\n",
            " 92% 5760/6237 [1:40:18<08:51,  1.11s/it]losses: tensor([0.1003], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-300.3271], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-543.1510], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-306.0050], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-526.3427], device='cuda:0')\n",
            "logits: tensor([22.4862], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5678], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6808], device='cuda:0')\n",
            " 92% 5761/6237 [1:40:20<09:50,  1.24s/it]losses: tensor([0.1275], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-497.5133], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.5914], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-505.5876], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.7106], device='cuda:0')\n",
            "logits: tensor([19.9550], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8074], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1881], device='cuda:0')\n",
            " 92% 5762/6237 [1:40:20<08:18,  1.05s/it]losses: tensor([0.0255], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-369.4470], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.6923], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-381.8004], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.4979], device='cuda:0')\n",
            "logits: tensor([36.5479], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2353], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4194], device='cuda:0')\n",
            " 92% 5763/6237 [1:40:21<07:34,  1.04it/s]losses: tensor([0.0763], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-238.0634], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.2115], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-242.0513], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-354.8473], device='cuda:0')\n",
            "logits: tensor([25.3521], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3988], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1364], device='cuda:0')\n",
            " 92% 5764/6237 [1:40:22<06:37,  1.19it/s]losses: tensor([0.2075], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-923.5647], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-356.5362], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-929.2287], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-347.5307], device='cuda:0')\n",
            "logits: tensor([14.6694], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5664], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9005], device='cuda:0')\n",
            " 92% 5765/6237 [1:40:23<07:43,  1.02it/s]losses: tensor([0.0735], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-461.0974], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.0731], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-477.0156], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-352.2494], device='cuda:0')\n",
            "logits: tensor([25.7419], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5918], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9824], device='cuda:0')\n",
            " 92% 5766/6237 [1:40:24<08:19,  1.06s/it]losses: tensor([0.1122], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1113.0698], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.4499], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1116.5039], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-344.5741], device='cuda:0')\n",
            "logits: tensor([21.3099], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3434], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7876], device='cuda:0')\n",
            " 92% 5767/6237 [1:40:26<10:15,  1.31s/it]losses: tensor([0.0426], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-100.6512], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.8074], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-112.4508], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.2580], device='cuda:0')\n",
            "logits: tensor([31.3490], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1800], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9549], device='cuda:0')\n",
            " 92% 5768/6237 [1:40:27<09:55,  1.27s/it]losses: tensor([0.1177], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-563.3247], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-344.5198], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-576.0942], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-336.4891], device='cuda:0')\n",
            "logits: tensor([20.8002], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2770], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8031], device='cuda:0')\n",
            " 92% 5769/6237 [1:40:28<09:04,  1.16s/it]losses: tensor([0.1920], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-269.3536], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-352.4380], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-274.9377], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-342.4970], device='cuda:0')\n",
            "logits: tensor([15.5251], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5584], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9941], device='cuda:0')\n",
            "{'loss': 0.1075, 'learning_rate': 4.275788348476751e-08, 'rewards/real': 0.8526300191879272, 'rewards/generated': -1.4847379922866821, 'rewards/accuracies': 1.0, 'rewards/margins': 2.337367534637451, 'logps/generated': -392.9470520019531, 'logps/real': -483.6412048339844, 'logits/generated': -1.7281296253204346, 'logits/real': -1.6316112279891968, 'epoch': 2.78}\n",
            " 93% 5770/6237 [1:40:29<08:09,  1.05s/it]losses: tensor([5.3038], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-276.7818], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-2109.4897], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-287.7054], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-2173.4016], device='cuda:0')\n",
            "logits: tensor([-52.9882], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0924], device='cuda:0')\n",
            "generated_rewards: tensor([6.3912], device='cuda:0')\n",
            " 93% 5771/6237 [1:40:30<07:24,  1.05it/s]losses: tensor([0.0538], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-217.3413], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.3960], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-224.5155], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.6104], device='cuda:0')\n",
            "logits: tensor([28.9598], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7174], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1786], device='cuda:0')\n",
            " 93% 5772/6237 [1:40:30<06:21,  1.22it/s]losses: tensor([0.0368], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-224.2241], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.3669], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-237.2429], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.5437], device='cuda:0')\n",
            "logits: tensor([32.8421], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3019], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9823], device='cuda:0')\n",
            " 93% 5773/6237 [1:40:31<06:23,  1.21it/s]losses: tensor([0.0185], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-247.6995], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.8948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.3746], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-358.7602], device='cuda:0')\n",
            "logits: tensor([39.8097], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0675], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9135], device='cuda:0')\n",
            " 93% 5774/6237 [1:40:33<08:55,  1.16s/it]losses: tensor([0.3339], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-521.9969], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.9199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.9099], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.5796], device='cuda:0')\n",
            "logits: tensor([9.2533], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0087], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9340], device='cuda:0')\n",
            " 93% 5775/6237 [1:40:34<08:28,  1.10s/it]losses: tensor([0.1195], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-698.5541], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-390.9524], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-698.0753], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.8285], device='cuda:0')\n",
            "logits: tensor([20.6451], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0479], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1124], device='cuda:0')\n",
            " 93% 5776/6237 [1:40:35<08:49,  1.15s/it]losses: tensor([0.0616], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-187.9891], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.5191], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-197.0505], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-464.0225], device='cuda:0')\n",
            "logits: tensor([27.5580], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9061], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8497], device='cuda:0')\n",
            " 93% 5777/6237 [1:40:37<09:41,  1.26s/it]losses: tensor([0.1581], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-331.8329], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-392.1248], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-341.3638], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.0118], device='cuda:0')\n",
            "logits: tensor([17.6438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9531], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8113], device='cuda:0')\n",
            " 93% 5778/6237 [1:40:39<10:53,  1.42s/it]losses: tensor([0.0145], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-267.3686], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.0963], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-278.2111], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-461.6877], device='cuda:0')\n",
            "logits: tensor([42.2511], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0842], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1409], device='cuda:0')\n",
            " 93% 5779/6237 [1:40:40<10:45,  1.41s/it]losses: tensor([0.1541], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-561.1582], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-354.2443], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-568.7542], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-343.9169], device='cuda:0')\n",
            "logits: tensor([17.9233], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7596], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0327], device='cuda:0')\n",
            "{'loss': 0.6255, 'learning_rate': 4.186709424550151e-08, 'rewards/real': 0.7825669050216675, 'rewards/generated': -1.0564135313034058, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.8389804363250732, 'logps/generated': -584.1004028320312, 'logps/real': -353.4946594238281, 'logits/generated': -1.3692575693130493, 'logits/real': -1.5469551086425781, 'epoch': 2.78}\n",
            " 93% 5780/6237 [1:40:41<09:40,  1.27s/it]losses: tensor([0.0771], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-381.3876], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.0800], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-385.8833], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.3357], device='cuda:0')\n",
            "logits: tensor([25.2400], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4496], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0744], device='cuda:0')\n",
            " 93% 5781/6237 [1:40:42<10:13,  1.34s/it]losses: tensor([0.1317], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-885.8452], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-377.2286], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-885.1228], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-356.9022], device='cuda:0')\n",
            "logits: tensor([19.6039], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0722], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0326], device='cuda:0')\n",
            " 93% 5782/6237 [1:40:44<10:20,  1.36s/it]losses: tensor([0.2786], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-899.1345], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-446.0607], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-897.8773], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-433.4474], device='cuda:0')\n",
            "logits: tensor([11.3560], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1257], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2613], device='cuda:0')\n",
            " 93% 5783/6237 [1:40:46<11:11,  1.48s/it]losses: tensor([0.0935], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-434.8049], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-392.4410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-440.5123], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-374.9220], device='cuda:0')\n",
            "logits: tensor([23.2264], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5707], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7519], device='cuda:0')\n",
            " 93% 5784/6237 [1:40:46<09:05,  1.20s/it]losses: tensor([0.0573], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-642.2505], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.5597], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-643.6375], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.6364], device='cuda:0')\n",
            "logits: tensor([28.3102], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1387], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6923], device='cuda:0')\n",
            " 93% 5785/6237 [1:40:47<07:59,  1.06s/it]losses: tensor([0.1174], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-88.3207], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.3320], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-98.9244], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.1112], device='cuda:0')\n",
            "logits: tensor([20.8245], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0604], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0221], device='cuda:0')\n",
            " 93% 5786/6237 [1:40:48<08:01,  1.07s/it]losses: tensor([0.1004], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-115.5043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-587.6471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-125.8987], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-575.5619], device='cuda:0')\n",
            "logits: tensor([22.4796], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0394], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2085], device='cuda:0')\n",
            " 93% 5787/6237 [1:40:49<09:03,  1.21s/it]losses: tensor([0.0776], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-572.2626], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.8120], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-571.0366], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.4131], device='cuda:0')\n",
            "logits: tensor([25.1730], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1226], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6399], device='cuda:0')\n",
            " 93% 5788/6237 [1:40:50<08:24,  1.12s/it]losses: tensor([0.1729], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1056.2451], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.7924], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1060.7738], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.6477], device='cuda:0')\n",
            "logits: tensor([16.6733], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4529], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2145], device='cuda:0')\n",
            " 93% 5789/6237 [1:40:52<08:49,  1.18s/it]losses: tensor([0.0486], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-171.3184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.5681], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-181.9637], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.2242], device='cuda:0')\n",
            "logits: tensor([29.9892], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0645], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9344], device='cuda:0')\n",
            "{'loss': 0.1155, 'learning_rate': 4.097630500623552e-08, 'rewards/real': 0.4455651640892029, 'rewards/generated': -1.7831974029541016, 'rewards/accuracies': 1.0, 'rewards/margins': 2.228762626647949, 'logps/generated': -439.75213623046875, 'logps/real': -524.7073974609375, 'logits/generated': -1.7124216556549072, 'logits/real': -1.8124357461929321, 'epoch': 2.78}\n",
            " 93% 5790/6237 [1:40:53<08:18,  1.11s/it]losses: tensor([0.1130], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-710.1509], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.6205], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-704.4430], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.6835], device='cuda:0')\n",
            "logits: tensor([21.2292], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5708], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6937], device='cuda:0')\n",
            " 93% 5791/6237 [1:40:54<08:22,  1.13s/it]losses: tensor([0.0690], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-284.1639], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.1833], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-294.8045], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.4403], device='cuda:0')\n",
            "logits: tensor([26.3836], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0641], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5743], device='cuda:0')\n",
            " 93% 5792/6237 [1:40:55<07:27,  1.00s/it]losses: tensor([0.0489], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-188.6657], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.0948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-197.7959], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.2948], device='cuda:0')\n",
            "logits: tensor([29.9302], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9130], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0800], device='cuda:0')\n",
            " 93% 5793/6237 [1:40:55<06:29,  1.14it/s]losses: tensor([0.0743], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-327.4264], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.2888], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-335.8104], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.0466], device='cuda:0')\n",
            "logits: tensor([25.6263], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8384], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7242], device='cuda:0')\n",
            " 93% 5794/6237 [1:40:56<07:02,  1.05it/s]losses: tensor([0.1395], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-854.6600], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-390.6513], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-853.5109], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.5098], device='cuda:0')\n",
            "logits: tensor([18.9923], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1149], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0141], device='cuda:0')\n",
            " 93% 5795/6237 [1:40:57<07:20,  1.00it/s]losses: tensor([0.3520], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1216.9988], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-357.1942], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1212.5123], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-344.0767], device='cuda:0')\n",
            "logits: tensor([8.6310], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4486], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3117], device='cuda:0')\n",
            " 93% 5796/6237 [1:40:59<09:22,  1.28s/it]losses: tensor([0.0100], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-171.6538], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.2711], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-183.3205], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.9513], device='cuda:0')\n",
            "logits: tensor([45.9865], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1667], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4320], device='cuda:0')\n",
            " 93% 5797/6237 [1:41:01<09:44,  1.33s/it]losses: tensor([0.3858], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-610.5276], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-374.8841], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-608.4813], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.3031], device='cuda:0')\n",
            "logits: tensor([7.5347], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2046], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9581], device='cuda:0')\n",
            " 93% 5798/6237 [1:41:02<09:03,  1.24s/it]losses: tensor([0.0516], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-169.9786], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.2247], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.5936], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.4633], device='cuda:0')\n",
            "logits: tensor([29.3764], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8615], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0761], device='cuda:0')\n",
            " 93% 5799/6237 [1:41:03<08:08,  1.11s/it]losses: tensor([0.1485], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-242.5033], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-516.7680], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-246.8247], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-502.7680], device='cuda:0')\n",
            "logits: tensor([18.3214], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4321], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4000], device='cuda:0')\n",
            "{'loss': 0.1393, 'learning_rate': 4.008551576696953e-08, 'rewards/real': 0.4936807155609131, 'rewards/generated': -1.8264353275299072, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3201162815093994, 'logps/generated': -427.9181213378906, 'logps/real': -477.6728515625, 'logits/generated': -1.2926546335220337, 'logits/real': -1.3875982761383057, 'epoch': 2.79}\n",
            " 93% 5800/6237 [1:41:04<09:02,  1.24s/it]losses: tensor([0.0671], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-309.1157], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.6048], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-317.4856], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-449.2903], device='cuda:0')\n",
            "logits: tensor([26.6844], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8370], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8315], device='cuda:0')\n",
            " 93% 5801/6237 [1:41:05<07:26,  1.02s/it]losses: tensor([0.1884], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-245.7029], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-369.4615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-252.3513], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.3751], device='cuda:0')\n",
            "logits: tensor([15.7348], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6648], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9086], device='cuda:0')\n",
            " 93% 5802/6237 [1:41:05<06:18,  1.15it/s]losses: tensor([0.0568], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-920.9753], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-375.6071], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-929.7180], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.9594], device='cuda:0')\n",
            "logits: tensor([28.3904], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8743], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9648], device='cuda:0')\n",
            " 93% 5803/6237 [1:41:06<06:54,  1.05it/s]losses: tensor([0.0717], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-111.5208], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-444.6621], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-125.6440], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.7982], device='cuda:0')\n",
            "logits: tensor([25.9870], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4123], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1864], device='cuda:0')\n",
            " 93% 5804/6237 [1:41:07<06:39,  1.08it/s]losses: tensor([0.0697], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-702.9502], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.0949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-711.2510], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.1107], device='cuda:0')\n",
            "logits: tensor([26.2850], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8301], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7984], device='cuda:0')\n",
            " 93% 5805/6237 [1:41:08<06:27,  1.11it/s]losses: tensor([0.3764], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-395.8375], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-312.3816], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-400.0599], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-308.7751], device='cuda:0')\n",
            "logits: tensor([7.8290], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4222], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3607], device='cuda:0')\n",
            " 93% 5806/6237 [1:41:09<05:54,  1.22it/s]losses: tensor([0.0079], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-466.8919], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.6869], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-488.2491], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.6773], device='cuda:0')\n",
            "logits: tensor([48.3667], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.1357], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7010], device='cuda:0')\n",
            " 93% 5807/6237 [1:41:10<07:39,  1.07s/it]losses: tensor([0.1167], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-400.8170], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.4475], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-405.8096], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.5491], device='cuda:0')\n",
            "logits: tensor([20.8910], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4993], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5898], device='cuda:0')\n",
            " 93% 5808/6237 [1:41:11<06:40,  1.07it/s]losses: tensor([0.0242], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-604.5223], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-440.1836], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-620.7494], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-419.3075], device='cuda:0')\n",
            "logits: tensor([37.1032], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6227], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0876], device='cuda:0')\n",
            " 93% 5809/6237 [1:41:12<06:18,  1.13it/s]losses: tensor([0.0674], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-253.6746], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-435.5952], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.8463], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.1322], device='cuda:0')\n",
            "logits: tensor([26.6347], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5172], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1463], device='cuda:0')\n",
            "{'loss': 0.1046, 'learning_rate': 3.9194726527703544e-08, 'rewards/real': 0.9815579652786255, 'rewards/generated': -1.6575047969818115, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6390628814697266, 'logps/generated': -408.67254638671875, 'logps/real': -441.2007751464844, 'logits/generated': -1.4216495752334595, 'logits/real': -1.300641417503357, 'epoch': 2.79}\n",
            " 93% 5810/6237 [1:41:12<05:52,  1.21it/s]losses: tensor([0.0723], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-683.5424], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.1334], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-689.0271], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.7079], device='cuda:0')\n",
            "logits: tensor([25.9102], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5485], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0425], device='cuda:0')\n",
            " 93% 5811/6237 [1:41:13<05:57,  1.19it/s]losses: tensor([0.0348], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-90.6254], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.0230], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-103.9226], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.9074], device='cuda:0')\n",
            "logits: tensor([33.4128], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3297], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0116], device='cuda:0')\n",
            " 93% 5812/6237 [1:41:14<05:13,  1.35it/s]losses: tensor([0.0678], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1260.1265], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.3062], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1266.0149], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.6277], device='cuda:0')\n",
            "logits: tensor([26.5670], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5888], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0679], device='cuda:0')\n",
            " 93% 5813/6237 [1:41:16<07:25,  1.05s/it]losses: tensor([0.2161], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-271.3814], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-249.8574], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-284.2992], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-248.5566], device='cuda:0')\n",
            "logits: tensor([14.2185], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2918], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1301], device='cuda:0')\n",
            " 93% 5814/6237 [1:41:16<06:29,  1.09it/s]losses: tensor([0.0829], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-275.9895], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.2645], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-285.0252], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.8177], device='cuda:0')\n",
            "logits: tensor([24.4824], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9036], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5447], device='cuda:0')\n",
            " 93% 5815/6237 [1:41:17<06:08,  1.15it/s]losses: tensor([0.0195], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-187.3654], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.5471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-201.3759], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.2586], device='cuda:0')\n",
            "logits: tensor([39.2990], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4011], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5288], device='cuda:0')\n",
            " 93% 5816/6237 [1:41:18<05:44,  1.22it/s]losses: tensor([0.1292], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-326.4684], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.0822], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-340.3833], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-466.1870], device='cuda:0')\n",
            "logits: tensor([19.8101], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3915], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5895], device='cuda:0')\n",
            " 93% 5817/6237 [1:41:19<06:42,  1.04it/s]losses: tensor([0.0135], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-119.0579], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-450.6720], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-130.0173], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-418.6668], device='cuda:0')\n",
            "logits: tensor([42.9645], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0959], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2005], device='cuda:0')\n",
            " 93% 5818/6237 [1:41:20<06:09,  1.13it/s]losses: tensor([0.0672], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-382.0443], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.7656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-383.8223], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.8752], device='cuda:0')\n",
            "logits: tensor([26.6684], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1778], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4890], device='cuda:0')\n",
            " 93% 5819/6237 [1:41:20<05:38,  1.23it/s]losses: tensor([0.0261], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1490.5548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-505.5745], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1502.0826], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.7921], device='cuda:0')\n",
            "logits: tensor([36.3102], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1528], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4782], device='cuda:0')\n",
            "{'loss': 0.0729, 'learning_rate': 3.8303937288437555e-08, 'rewards/real': 0.9881445169448853, 'rewards/generated': -1.908286690711975, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8964309692382812, 'logps/generated': -435.72259521484375, 'logps/real': -508.715576171875, 'logits/generated': -1.8311564922332764, 'logits/real': -1.5553499460220337, 'epoch': 2.8}\n",
            " 93% 5820/6237 [1:41:22<06:56,  1.00it/s]losses: tensor([0.1959], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-617.6476], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-344.4708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-631.4506], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-342.9693], device='cuda:0')\n",
            "logits: tensor([15.3044], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3803], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1501], device='cuda:0')\n",
            " 93% 5821/6237 [1:41:22<06:30,  1.07it/s]losses: tensor([0.3498], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-953.1667], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-372.9805], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-954.3975], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.5089], device='cuda:0')\n",
            "logits: tensor([8.7023], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1231], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7472], device='cuda:0')\n",
            " 93% 5822/6237 [1:41:24<06:46,  1.02it/s]losses: tensor([0.0994], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1393.5159], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.5775], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1402.5389], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-374.0150], device='cuda:0')\n",
            "logits: tensor([22.5855], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9023], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3563], device='cuda:0')\n",
            " 93% 5823/6237 [1:41:25<08:24,  1.22s/it]losses: tensor([0.0241], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-206.8244], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.1011], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-212.5738], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.7268], device='cuda:0')\n",
            "logits: tensor([37.1238], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5749], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1374], device='cuda:0')\n",
            " 93% 5824/6237 [1:41:26<07:17,  1.06s/it]losses: tensor([0.1012], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.9471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-398.2184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-475.1499], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.0277], device='cuda:0')\n",
            "logits: tensor([22.3935], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0203], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2191], device='cuda:0')\n",
            " 93% 5825/6237 [1:41:27<06:21,  1.08it/s]losses: tensor([0.0427], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-135.7059], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.3124], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-151.8973], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.1785], device='cuda:0')\n",
            "logits: tensor([31.3254], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6191], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5134], device='cuda:0')\n",
            " 93% 5826/6237 [1:41:28<07:31,  1.10s/it]losses: tensor([0.0477], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-118.3082], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-386.4713], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-132.7004], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.6732], device='cuda:0')\n",
            "logits: tensor([30.1904], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4392], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5798], device='cuda:0')\n",
            " 93% 5827/6237 [1:41:29<06:18,  1.08it/s]losses: tensor([0.0583], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-432.0009], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.9564], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-438.0283], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-425.8474], device='cuda:0')\n",
            "logits: tensor([28.1364], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6027], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2109], device='cuda:0')\n",
            " 93% 5828/6237 [1:41:29<05:26,  1.25it/s]losses: tensor([0.2423], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-360.6553], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.4405], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-367.6272], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.4736], device='cuda:0')\n",
            "logits: tensor([12.9388], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6972], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5967], device='cuda:0')\n",
            " 93% 5829/6237 [1:41:30<05:22,  1.27it/s]losses: tensor([0.2734], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1001.4171], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-287.6678], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1008.5950], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-283.2744], device='cuda:0')\n",
            "logits: tensor([11.5714], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7178], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4393], device='cuda:0')\n",
            "{'loss': 0.1435, 'learning_rate': 3.741314804917156e-08, 'rewards/real': 0.9076985120773315, 'rewards/generated': -1.2950208187103271, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2027194499969482, 'logps/generated': -381.91961669921875, 'logps/real': -568.4188842773438, 'logits/generated': -1.7090976238250732, 'logits/real': -1.6626815795898438, 'epoch': 2.8}\n",
            " 93% 5830/6237 [1:41:32<07:37,  1.12s/it]losses: tensor([0.0081], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-633.4656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.1538], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-653.9295], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.4995], device='cuda:0')\n",
            "logits: tensor([48.1183], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0464], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7654], device='cuda:0')\n",
            " 93% 5831/6237 [1:41:32<06:29,  1.04it/s]losses: tensor([0.0686], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1065.5895], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.3953], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1073.3025], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.6579], device='cuda:0')\n",
            "logits: tensor([26.4504], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7713], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8737], device='cuda:0')\n",
            " 94% 5832/6237 [1:41:34<07:22,  1.09s/it]losses: tensor([0.0456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1464.4449], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.3590], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1479.8318], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.0907], device='cuda:0')\n",
            "logits: tensor([30.6552], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5387], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5268], device='cuda:0')\n",
            " 94% 5833/6237 [1:41:35<08:15,  1.23s/it]losses: tensor([0.1180], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-390.8153], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-336.7706], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-399.2101], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-324.3936], device='cuda:0')\n",
            "logits: tensor([20.7717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8395], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2377], device='cuda:0')\n",
            " 94% 5834/6237 [1:41:36<06:47,  1.01s/it]losses: tensor([0.0999], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-716.1561], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-338.7554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-731.4391], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-331.5072], device='cuda:0')\n",
            "logits: tensor([22.5311], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5283], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7248], device='cuda:0')\n",
            " 94% 5835/6237 [1:41:37<06:51,  1.02s/it]losses: tensor([0.0514], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-107.2894], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-301.1310], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-118.4669], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-282.8924], device='cuda:0')\n",
            "logits: tensor([29.4160], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1177], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8239], device='cuda:0')\n",
            " 94% 5836/6237 [1:41:38<06:48,  1.02s/it]losses: tensor([0.0254], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.5655], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.8853], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-481.2133], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.9258], device='cuda:0')\n",
            "logits: tensor([36.6073], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6648], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9960], device='cuda:0')\n",
            " 94% 5837/6237 [1:41:39<06:07,  1.09it/s]losses: tensor([0.0191], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-228.4551], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.7236], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-240.2398], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.0403], device='cuda:0')\n",
            "logits: tensor([39.4679], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1785], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7683], device='cuda:0')\n",
            " 94% 5838/6237 [1:41:40<06:22,  1.04it/s]losses: tensor([8.3407], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-115.1852], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1537.8934], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-123.4423], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1629.5549], device='cuda:0')\n",
            "logits: tensor([-83.4044], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8257], device='cuda:0')\n",
            "generated_rewards: tensor([9.1662], device='cuda:0')\n",
            " 94% 5839/6237 [1:41:41<06:43,  1.01s/it]losses: tensor([0.1704], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-835.7975], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-453.1043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-835.4661], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.9414], device='cuda:0')\n",
            "logits: tensor([16.8315], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0331], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7163], device='cuda:0')\n",
            "{'loss': 0.8947, 'learning_rate': 3.652235880990558e-08, 'rewards/real': 1.1477713584899902, 'rewards/generated': -0.7266791462898254, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.8744503259658813, 'logps/generated': -507.11712646484375, 'logps/real': -602.1763916015625, 'logits/generated': -1.7420886754989624, 'logits/real': -1.584137201309204, 'epoch': 2.81}\n",
            " 94% 5840/6237 [1:41:42<07:09,  1.08s/it]losses: tensor([0.0608], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-146.8253], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-302.4911], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-163.2811], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-291.2570], device='cuda:0')\n",
            "logits: tensor([27.6898], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6456], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1234], device='cuda:0')\n",
            " 94% 5841/6237 [1:41:43<07:06,  1.08s/it]losses: tensor([0.0816], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-180.5703], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-374.0559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-192.7153], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-361.5519], device='cuda:0')\n",
            "logits: tensor([24.6489], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2145], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2504], device='cuda:0')\n",
            " 94% 5842/6237 [1:41:44<06:26,  1.02it/s]losses: tensor([0.3242], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-664.9982], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-366.7629], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-664.7163], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-356.8803], device='cuda:0')\n",
            "logits: tensor([9.6008], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0282], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9883], device='cuda:0')\n",
            " 94% 5843/6237 [1:41:45<06:47,  1.03s/it]losses: tensor([0.0193], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-294.0166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-469.4268], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-300.7684], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-436.8177], device='cuda:0')\n",
            "logits: tensor([39.3609], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6752], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2609], device='cuda:0')\n",
            " 94% 5844/6237 [1:41:46<06:45,  1.03s/it]losses: tensor([0.2588], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-502.6199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-359.1681], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-510.1035], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-354.4573], device='cuda:0')\n",
            "logits: tensor([12.1943], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7484], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4711], device='cuda:0')\n",
            " 94% 5845/6237 [1:41:47<05:59,  1.09it/s]losses: tensor([0.1434], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-611.2722], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-494.3472], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-617.4191], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-481.7960], device='cuda:0')\n",
            "logits: tensor([18.6981], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6147], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2551], device='cuda:0')\n",
            " 94% 5846/6237 [1:41:47<05:42,  1.14it/s]losses: tensor([0.0782], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-425.7277], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-440.4744], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-437.2671], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.9270], device='cuda:0')\n",
            "logits: tensor([25.0868], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1539], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3547], device='cuda:0')\n",
            " 94% 5847/6237 [1:41:48<04:58,  1.31it/s]losses: tensor([0.0095], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-185.3700], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-451.7627], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-192.5016], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.3761], device='cuda:0')\n",
            "logits: tensor([46.5183], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7132], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9387], device='cuda:0')\n",
            " 94% 5848/6237 [1:41:48<04:27,  1.45it/s]losses: tensor([0.2552], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1108.7600], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.4778], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1103.5474], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-475.9096], device='cuda:0')\n",
            "logits: tensor([12.3555], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5213], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7568], device='cuda:0')\n",
            " 94% 5849/6237 [1:41:50<06:00,  1.08it/s]losses: tensor([0.0398], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1108.7180], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.1162], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1125.4069], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.7539], device='cuda:0')\n",
            "logits: tensor([32.0511], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6689], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5362], device='cuda:0')\n",
            "{'loss': 0.1271, 'learning_rate': 3.563156957063959e-08, 'rewards/real': 0.7884820699691772, 'rewards/generated': -1.6935632228851318, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4820454120635986, 'logps/generated': -417.308349609375, 'logps/real': -522.8878173828125, 'logits/generated': -1.907731056213379, 'logits/real': -1.9569556713104248, 'epoch': 2.81}\n",
            " 94% 5850/6237 [1:41:51<06:52,  1.07s/it]losses: tensor([0.0550], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-544.7578], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.2042], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-549.7565], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.4788], device='cuda:0')\n",
            "logits: tensor([28.7241], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4999], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3725], device='cuda:0')\n",
            " 94% 5851/6237 [1:41:52<06:13,  1.03it/s]losses: tensor([0.1282], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-727.3850], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.9865], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-728.9535], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.6641], device='cuda:0')\n",
            "logits: tensor([19.8909], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1568], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8322], device='cuda:0')\n",
            " 94% 5852/6237 [1:41:54<07:04,  1.10s/it]losses: tensor([0.0296], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-124.0163], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.0203], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-138.2124], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-342.1653], device='cuda:0')\n",
            "logits: tensor([35.0511], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4196], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0855], device='cuda:0')\n",
            " 94% 5853/6237 [1:41:54<06:10,  1.04it/s]losses: tensor([0.1189], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-885.1908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-434.2101], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-889.2059], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.5276], device='cuda:0')\n",
            "logits: tensor([20.6977], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4015], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6683], device='cuda:0')\n",
            " 94% 5854/6237 [1:41:55<06:43,  1.05s/it]losses: tensor([0.1796], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-601.5099], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.2328], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-602.1328], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.5972], device='cuda:0')\n",
            "logits: tensor([16.2585], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0623], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5636], device='cuda:0')\n",
            " 94% 5855/6237 [1:41:56<06:31,  1.03s/it]losses: tensor([0.1407], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-471.3319], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-374.0700], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-482.2194], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.0583], device='cuda:0')\n",
            "logits: tensor([18.8992], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0888], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8012], device='cuda:0')\n",
            " 94% 5856/6237 [1:41:57<05:42,  1.11it/s]losses: tensor([0.2641], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-299.1548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-307.0213], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-312.0425], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-307.9457], device='cuda:0')\n",
            "logits: tensor([11.9633], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2888], device='cuda:0')\n",
            "generated_rewards: tensor([0.0924], device='cuda:0')\n",
            " 94% 5857/6237 [1:41:58<05:37,  1.12it/s]losses: tensor([0.4179], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-720.8127], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-329.5417], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-722.3468], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-324.5141], device='cuda:0')\n",
            "logits: tensor([6.5618], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1534], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5028], device='cuda:0')\n",
            " 94% 5858/6237 [1:41:59<06:18,  1.00it/s]losses: tensor([0.0333], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-399.6989], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-514.6364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-410.5779], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-491.6754], device='cuda:0')\n",
            "logits: tensor([33.8400], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0879], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2961], device='cuda:0')\n",
            " 94% 5859/6237 [1:42:01<07:17,  1.16s/it]losses: tensor([0.0352], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-232.6884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.1497], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-242.1172], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.2880], device='cuda:0')\n",
            "logits: tensor([33.2905], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9429], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3862], device='cuda:0')\n",
            "{'loss': 0.1403, 'learning_rate': 3.474078033137359e-08, 'rewards/real': 0.7101829051971436, 'rewards/generated': -1.5415880680084229, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2517709732055664, 'logps/generated': -393.40728759765625, 'logps/real': -500.6546325683594, 'logits/generated': -1.0734691619873047, 'logits/real': -1.198839545249939, 'epoch': 2.82}\n",
            " 94% 5860/6237 [1:42:02<06:50,  1.09s/it]losses: tensor([0.0841], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-235.6918], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.8860], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-245.1324], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.9922], device='cuda:0')\n",
            "logits: tensor([24.3343], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9441], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4894], device='cuda:0')\n",
            " 94% 5861/6237 [1:42:02<06:11,  1.01it/s]losses: tensor([0.2266], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-511.7115], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.4160], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-514.7899], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.8019], device='cuda:0')\n",
            "logits: tensor([13.6925], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3078], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0614], device='cuda:0')\n",
            " 94% 5862/6237 [1:42:03<05:26,  1.15it/s]losses: tensor([0.0483], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-100.2201], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.3703], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-111.7279], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.8153], device='cuda:0')\n",
            "logits: tensor([30.0628], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1508], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8555], device='cuda:0')\n",
            " 94% 5863/6237 [1:42:03<04:54,  1.27it/s]losses: tensor([0.0281], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-132.3079], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.1826], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-147.5244], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.8137], device='cuda:0')\n",
            "logits: tensor([35.5854], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5216], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0369], device='cuda:0')\n",
            " 94% 5864/6237 [1:42:04<04:56,  1.26it/s]losses: tensor([0.3170], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-632.2941], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-292.0597], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-642.0032], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-291.9087], device='cuda:0')\n",
            "logits: tensor([9.8601], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9709], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0151], device='cuda:0')\n",
            " 94% 5865/6237 [1:42:06<06:21,  1.03s/it]losses: tensor([0.1053], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-123.4793], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-360.4100], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-133.9571], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-348.9124], device='cuda:0')\n",
            "logits: tensor([21.9754], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0478], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1498], device='cuda:0')\n",
            " 94% 5866/6237 [1:42:06<05:31,  1.12it/s]losses: tensor([0.0289], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-817.1754], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.7840], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-825.9879], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.2868], device='cuda:0')\n",
            "logits: tensor([35.3097], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8813], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6497], device='cuda:0')\n",
            " 94% 5867/6237 [1:42:08<06:01,  1.02it/s]losses: tensor([0.3877], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-285.9281], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-231.5955], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-297.2865], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-235.4804], device='cuda:0')\n",
            "logits: tensor([7.4735], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1358], device='cuda:0')\n",
            "generated_rewards: tensor([0.3885], device='cuda:0')\n",
            " 94% 5868/6237 [1:42:09<06:16,  1.02s/it]losses: tensor([0.1269], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-640.9945], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.8028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-649.4716], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.2736], device='cuda:0')\n",
            "logits: tensor([20.0063], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8477], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1529], device='cuda:0')\n",
            " 94% 5869/6237 [1:42:10<06:19,  1.03s/it]losses: tensor([0.4251], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-578.0293], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.4209], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-576.6068], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.6434], device='cuda:0')\n",
            "logits: tensor([6.3550], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1422], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7778], device='cuda:0')\n",
            "{'loss': 0.1778, 'learning_rate': 3.384999109210761e-08, 'rewards/real': 0.8665555715560913, 'rewards/generated': -1.1799943447113037, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0465502738952637, 'logps/generated': -396.79278564453125, 'logps/real': -405.78314208984375, 'logits/generated': -1.314868450164795, 'logits/real': -1.3872547149658203, 'epoch': 2.82}\n",
            " 94% 5870/6237 [1:42:11<06:06,  1.00it/s]losses: tensor([0.0545], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-263.1966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.9730], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-271.6384], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.5906], device='cuda:0')\n",
            "logits: tensor([28.8242], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8442], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0382], device='cuda:0')\n",
            " 94% 5871/6237 [1:42:12<07:04,  1.16s/it]losses: tensor([0.0698], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-147.3985], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.5237], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-158.1245], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.9747], device='cuda:0')\n",
            "logits: tensor([26.2751], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0726], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5549], device='cuda:0')\n",
            " 94% 5872/6237 [1:42:13<07:04,  1.16s/it]losses: tensor([0.4178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-202.0817], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-390.8961], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-210.8647], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.1122], device='cuda:0')\n",
            "logits: tensor([6.5668], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8783], device='cuda:0')\n",
            "generated_rewards: tensor([0.2216], device='cuda:0')\n",
            " 94% 5873/6237 [1:42:15<07:41,  1.27s/it]losses: tensor([0.1222], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-479.2284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-586.8475], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-491.1732], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-578.3906], device='cuda:0')\n",
            "logits: tensor([20.4018], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1945], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8457], device='cuda:0')\n",
            " 94% 5874/6237 [1:42:16<08:09,  1.35s/it]losses: tensor([0.2758], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-876.2567], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.3176], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-882.6504], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.2410], device='cuda:0')\n",
            "logits: tensor([11.4703], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6394], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5077], device='cuda:0')\n",
            " 94% 5875/6237 [1:42:18<07:38,  1.27s/it]losses: tensor([0.0912], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-717.6597], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.5323], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-714.8062], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.1942], device='cuda:0')\n",
            "logits: tensor([23.4847], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2853], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6338], device='cuda:0')\n",
            " 94% 5876/6237 [1:42:19<07:19,  1.22s/it]losses: tensor([0.1704], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-521.3090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-333.7998], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-530.3011], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-325.9597], device='cuda:0')\n",
            "logits: tensor([16.8322], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8992], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7840], device='cuda:0')\n",
            " 94% 5877/6237 [1:42:20<07:23,  1.23s/it]losses: tensor([0.0968], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-924.9982], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-377.9808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-934.0362], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.1576], device='cuda:0')\n",
            "logits: tensor([22.8613], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9038], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3823], device='cuda:0')\n",
            " 94% 5878/6237 [1:42:21<07:39,  1.28s/it]losses: tensor([0.1047], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.0126], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.3909], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-472.3567], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.7006], device='cuda:0')\n",
            "logits: tensor([22.0344], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8344], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3690], device='cuda:0')\n",
            " 94% 5879/6237 [1:42:22<06:20,  1.06s/it]losses: tensor([0.1079], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1263.6711], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-414.3186], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1271.5300], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.4579], device='cuda:0')\n",
            "logits: tensor([21.7196], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7859], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3861], device='cuda:0')\n",
            "{'loss': 0.1511, 'learning_rate': 3.2959201852841613e-08, 'rewards/real': 0.7766897678375244, 'rewards/generated': -1.228014588356018, 'rewards/accuracies': 1.0, 'rewards/margins': 2.004704475402832, 'logps/generated': -413.1580505371094, 'logps/real': -585.9812622070312, 'logits/generated': -1.5885899066925049, 'logits/real': -1.6709258556365967, 'epoch': 2.83}\n",
            " 94% 5880/6237 [1:42:23<07:13,  1.22s/it]losses: tensor([0.2190], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-361.6061], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.2645], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-361.0368], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-347.6251], device='cuda:0')\n",
            "logits: tensor([14.0702], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0569], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4639], device='cuda:0')\n",
            " 94% 5881/6237 [1:42:24<06:04,  1.02s/it]losses: tensor([0.0205], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-164.5337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.8180], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-177.7455], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.2661], device='cuda:0')\n",
            "logits: tensor([38.7636], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3212], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5552], device='cuda:0')\n",
            " 94% 5882/6237 [1:42:25<06:30,  1.10s/it]losses: tensor([0.1185], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-580.1042], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.3827], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-583.7817], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.3297], device='cuda:0')\n",
            "logits: tensor([20.7304], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3677], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7053], device='cuda:0')\n",
            " 94% 5883/6237 [1:42:26<05:59,  1.02s/it]losses: tensor([0.0730], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-514.4802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.3487], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.7561], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.8206], device='cuda:0')\n",
            "logits: tensor([25.8040], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7276], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8528], device='cuda:0')\n",
            " 94% 5884/6237 [1:42:27<05:37,  1.05it/s]losses: tensor([0.1630], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1053.0865], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.6650], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1048.6405], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.9055], device='cuda:0')\n",
            "logits: tensor([17.3134], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4446], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1759], device='cuda:0')\n",
            " 94% 5885/6237 [1:42:28<06:33,  1.12s/it]losses: tensor([0.1195], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-310.6552], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-401.2548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-326.7530], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.7113], device='cuda:0')\n",
            "logits: tensor([20.6412], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6098], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4543], device='cuda:0')\n",
            " 94% 5886/6237 [1:42:30<07:14,  1.24s/it]losses: tensor([0.0105], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-174.5547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.4023], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.7979], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.0979], device='cuda:0')\n",
            "logits: tensor([45.5476], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4243], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1304], device='cuda:0')\n",
            " 94% 5887/6237 [1:42:31<07:00,  1.20s/it]losses: tensor([0.1943], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-355.2520], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-546.8553], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-359.2318], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-535.4409], device='cuda:0')\n",
            "logits: tensor([15.3942], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3980], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1414], device='cuda:0')\n",
            " 94% 5888/6237 [1:42:33<07:31,  1.29s/it]losses: tensor([0.0823], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1081.6647], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.1015], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1100.4720], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.3497], device='cuda:0')\n",
            "logits: tensor([24.5591], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8807], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5752], device='cuda:0')\n",
            " 94% 5889/6237 [1:42:34<07:19,  1.26s/it]losses: tensor([0.1909], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-455.0866], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-367.7032], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-461.5147], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-358.5429], device='cuda:0')\n",
            "logits: tensor([15.5884], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6428], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9160], device='cuda:0')\n",
            "{'loss': 0.1192, 'learning_rate': 3.2068412613575624e-08, 'rewards/real': 0.7870598435401917, 'rewards/generated': -1.5970615148544312, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3841214179992676, 'logps/generated': -439.1795959472656, 'logps/real': -505.1023864746094, 'logits/generated': -1.7291316986083984, 'logits/real': -1.7473061084747314, 'epoch': 2.83}\n",
            " 94% 5890/6237 [1:42:35<06:36,  1.14s/it]losses: tensor([0.0467], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-197.1705], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-364.9379], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-208.3971], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-345.7524], device='cuda:0')\n",
            "logits: tensor([30.4120], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1227], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9185], device='cuda:0')\n",
            " 94% 5891/6237 [1:42:36<06:12,  1.08s/it]losses: tensor([0.3874], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-710.5977], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.4442], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-707.8876], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.2521], device='cuda:0')\n",
            "logits: tensor([7.4821], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2710], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0192], device='cuda:0')\n",
            " 94% 5892/6237 [1:42:36<05:37,  1.02it/s]losses: tensor([0.0872], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-257.5674], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.5286], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-271.4842], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.4890], device='cuda:0')\n",
            "logits: tensor([23.9563], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3917], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0040], device='cuda:0')\n",
            " 94% 5893/6237 [1:42:37<05:05,  1.13it/s]losses: tensor([0.3592], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1328.0100], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.7619], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1322.3546], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.7180], device='cuda:0')\n",
            "logits: tensor([8.3885], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5655], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4044], device='cuda:0')\n",
            " 95% 5894/6237 [1:42:39<06:48,  1.19s/it]losses: tensor([0.1257], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-780.9424], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.2030], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-784.7296], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.8885], device='cuda:0')\n",
            "logits: tensor([20.1017], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3787], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6314], device='cuda:0')\n",
            " 95% 5895/6237 [1:42:40<06:31,  1.15s/it]losses: tensor([0.0416], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-103.4644], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.7324], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-114.0684], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-352.7496], device='cuda:0')\n",
            "logits: tensor([31.5868], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0604], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0983], device='cuda:0')\n",
            " 95% 5896/6237 [1:42:41<06:28,  1.14s/it]losses: tensor([0.0177], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-512.3365], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.9162], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-520.4020], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.7502], device='cuda:0')\n",
            "logits: tensor([40.2315], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8065], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2166], device='cuda:0')\n",
            " 95% 5897/6237 [1:42:42<05:56,  1.05s/it]losses: tensor([0.1092], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-860.2676], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.0646], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-868.3244], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-379.5302], device='cuda:0')\n",
            "logits: tensor([21.5912], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8057], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3534], device='cuda:0')\n",
            " 95% 5898/6237 [1:42:44<06:55,  1.22s/it]losses: tensor([0.0432], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-270.1686], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-370.2722], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-280.0668], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-348.9777], device='cuda:0')\n",
            "logits: tensor([31.1926], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9898], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1294], device='cuda:0')\n",
            " 95% 5899/6237 [1:42:45<07:55,  1.41s/it]losses: tensor([0.2858], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1215.6038], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-400.9808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1215.7563], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.0734], device='cuda:0')\n",
            "logits: tensor([11.0600], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0153], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0907], device='cuda:0')\n",
            "{'loss': 0.1504, 'learning_rate': 3.1177623374309635e-08, 'rewards/real': 0.5734223127365112, 'rewards/generated': -1.6866061687469482, 'rewards/accuracies': 1.0, 'rewards/margins': 2.26002836227417, 'logps/generated': -406.6841735839844, 'logps/real': -623.6129150390625, 'logits/generated': -1.7630078792572021, 'logits/real': -1.787803292274475, 'epoch': 2.84}\n",
            " 95% 5900/6237 [1:42:47<08:47,  1.56s/it]losses: tensor([0.0838], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-346.5287], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.0902], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-358.7809], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-449.9706], device='cuda:0')\n",
            "logits: tensor([24.3718], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2252], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2120], device='cuda:0')\n",
            " 95% 5901/6237 [1:42:48<07:08,  1.27s/it]losses: tensor([0.0223], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-124.1245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.5450], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-129.8623], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.3461], device='cuda:0')\n",
            "logits: tensor([37.9366], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5738], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2199], device='cuda:0')\n",
            " 95% 5902/6237 [1:42:49<06:14,  1.12s/it]losses: tensor([0.1178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1005.6877], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.9719], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1006.3808], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.8712], device='cuda:0')\n",
            "logits: tensor([20.7938], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0693], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0101], device='cuda:0')\n",
            " 95% 5903/6237 [1:42:50<06:19,  1.14s/it]losses: tensor([0.1446], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-548.5166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.3156], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-549.3479], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.5386], device='cuda:0')\n",
            "logits: tensor([18.6083], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0831], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7777], device='cuda:0')\n",
            " 95% 5904/6237 [1:42:51<05:47,  1.04s/it]losses: tensor([0.2525], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-759.3444], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.3901], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-756.0565], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.6261], device='cuda:0')\n",
            "logits: tensor([12.4761], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3288], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5764], device='cuda:0')\n",
            " 95% 5905/6237 [1:42:52<06:01,  1.09s/it]losses: tensor([0.1348], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-966.8772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-364.4714], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-971.0889], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.3275], device='cuda:0')\n",
            "logits: tensor([19.3556], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4212], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5144], device='cuda:0')\n",
            " 95% 5906/6237 [1:42:53<06:07,  1.11s/it]losses: tensor([0.0904], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-875.9707], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.6062], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-887.4170], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.4714], device='cuda:0')\n",
            "logits: tensor([23.5811], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1446], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2135], device='cuda:0')\n",
            " 95% 5907/6237 [1:42:54<06:10,  1.12s/it]losses: tensor([0.0378], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-505.3411], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.1545], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-514.1587], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.3960], device='cuda:0')\n",
            "logits: tensor([32.5761], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8818], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3758], device='cuda:0')\n",
            " 95% 5908/6237 [1:42:55<05:34,  1.02s/it]losses: tensor([0.1220], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-792.3813], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.5496], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-795.3518], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-345.0980], device='cuda:0')\n",
            "logits: tensor([20.4221], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2971], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7452], device='cuda:0')\n",
            " 95% 5909/6237 [1:42:56<05:43,  1.05s/it]losses: tensor([0.0867], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-540.8588], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.4566], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-551.6108], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-382.1933], device='cuda:0')\n",
            "logits: tensor([24.0153], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0752], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3263], device='cuda:0')\n",
            "{'loss': 0.1093, 'learning_rate': 3.0286834135043646e-08, 'rewards/real': 0.5442463159561157, 'rewards/generated': -1.7971222400665283, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3413684368133545, 'logps/generated': -414.75506591796875, 'logps/real': -646.5631103515625, 'logits/generated': -1.5875358581542969, 'logits/real': -1.2718794345855713, 'epoch': 2.84}\n",
            " 95% 5910/6237 [1:42:57<04:52,  1.12it/s]losses: tensor([0.1090], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1777.0233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.8572], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1778.4536], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.6744], device='cuda:0')\n",
            "logits: tensor([21.6132], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1430], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0183], device='cuda:0')\n",
            " 95% 5911/6237 [1:42:58<06:02,  1.11s/it]losses: tensor([0.1745], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1171.2145], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.2864], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1172.0090], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.5087], device='cuda:0')\n",
            "logits: tensor([16.5723], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0795], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5778], device='cuda:0')\n",
            " 95% 5912/6237 [1:43:00<06:30,  1.20s/it]losses: tensor([0.3313], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-907.2282], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.4627], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-899.3666], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.2570], device='cuda:0')\n",
            "logits: tensor([9.3441], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7862], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7206], device='cuda:0')\n",
            " 95% 5913/6237 [1:43:01<06:51,  1.27s/it]losses: tensor([0.0836], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-795.8079], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.4668], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-803.8129], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.0760], device='cuda:0')\n",
            "logits: tensor([24.3958], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8005], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6391], device='cuda:0')\n",
            " 95% 5914/6237 [1:43:02<06:49,  1.27s/it]losses: tensor([0.1422], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1130.2560], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.2671], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1132.4939], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.7180], device='cuda:0')\n",
            "logits: tensor([18.7870], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2238], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6549], device='cuda:0')\n",
            " 95% 5915/6237 [1:43:04<07:04,  1.32s/it]losses: tensor([0.1495], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-261.7926], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.1343], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-269.5486], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-469.6432], device='cuda:0')\n",
            "logits: tensor([18.2472], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7756], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0491], device='cuda:0')\n",
            " 95% 5916/6237 [1:43:05<07:19,  1.37s/it]losses: tensor([0.1504], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-873.9089], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-369.3855], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-883.4247], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.7210], device='cuda:0')\n",
            "logits: tensor([18.1803], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9516], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8665], device='cuda:0')\n",
            " 95% 5917/6237 [1:43:07<07:22,  1.38s/it]losses: tensor([0.2375], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-625.4582], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-349.9535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-634.3198], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-345.6507], device='cuda:0')\n",
            "logits: tensor([13.1644], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8862], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4303], device='cuda:0')\n",
            " 95% 5918/6237 [1:43:07<06:12,  1.17s/it]losses: tensor([0.0693], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-451.5904], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.7331], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-464.0390], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.8389], device='cuda:0')\n",
            "logits: tensor([26.3428], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2449], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3894], device='cuda:0')\n",
            " 95% 5919/6237 [1:43:08<05:09,  1.03it/s]losses: tensor([0.0388], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-407.9772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.4199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-422.5958], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.7481], device='cuda:0')\n",
            "logits: tensor([32.2904], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4619], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7672], device='cuda:0')\n",
            "{'loss': 0.1486, 'learning_rate': 2.939604489577766e-08, 'rewards/real': 0.5780690908432007, 'rewards/generated': -1.4113059043884277, 'rewards/accuracies': 1.0, 'rewards/margins': 1.989375114440918, 'logps/generated': -415.8966369628906, 'logps/real': -840.2255859375, 'logits/generated': -1.6384994983673096, 'logits/real': -1.5460747480392456, 'epoch': 2.85}\n",
            " 95% 5920/6237 [1:43:09<04:41,  1.13it/s]losses: tensor([0.1220], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-982.0760], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-332.9343], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-981.8182], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-312.2560], device='cuda:0')\n",
            "logits: tensor([20.4205], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0258], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0678], device='cuda:0')\n",
            " 95% 5921/6237 [1:43:10<06:03,  1.15s/it]losses: tensor([0.0386], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-347.2178], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-383.5344], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-356.7312], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.6930], device='cuda:0')\n",
            "logits: tensor([32.3549], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9513], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2841], device='cuda:0')\n",
            " 95% 5922/6237 [1:43:11<05:18,  1.01s/it]losses: tensor([0.2018], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-882.6865], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-446.5182], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-881.3814], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.2352], device='cuda:0')\n",
            "logits: tensor([14.9779], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1305], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6283], device='cuda:0')\n",
            " 95% 5923/6237 [1:43:12<05:32,  1.06s/it]losses: tensor([0.0146], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-96.2365], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-586.8732], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-109.3599], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-557.8141], device='cuda:0')\n",
            "logits: tensor([42.1825], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3123], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9059], device='cuda:0')\n",
            " 95% 5924/6237 [1:43:13<05:44,  1.10s/it]losses: tensor([0.0166], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-706.1149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.6878], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-724.8495], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-371.4919], device='cuda:0')\n",
            "logits: tensor([40.9305], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8735], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2196], device='cuda:0')\n",
            " 95% 5925/6237 [1:43:14<05:02,  1.03it/s]losses: tensor([0.0301], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-219.1722], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-504.5173], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-232.8881], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-483.3357], device='cuda:0')\n",
            "logits: tensor([34.8975], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3716], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1182], device='cuda:0')\n",
            " 95% 5926/6237 [1:43:15<04:53,  1.06it/s]losses: tensor([0.1429], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-844.7144], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.6602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-849.8277], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.0426], device='cuda:0')\n",
            "logits: tensor([18.7309], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5113], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3618], device='cuda:0')\n",
            " 95% 5927/6237 [1:43:16<04:46,  1.08it/s]losses: tensor([0.0979], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-713.0480], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-411.8770], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-724.0721], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.1537], device='cuda:0')\n",
            "logits: tensor([22.7474], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1024], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1723], device='cuda:0')\n",
            " 95% 5928/6237 [1:43:17<04:38,  1.11it/s]losses: tensor([0.2425], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-451.1512], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-300.1880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-458.3168], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-294.4238], device='cuda:0')\n",
            "logits: tensor([12.9297], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7166], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5764], device='cuda:0')\n",
            " 95% 5929/6237 [1:43:18<04:50,  1.06it/s]losses: tensor([0.2357], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-993.8311], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.2708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-990.9553], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.1426], device='cuda:0')\n",
            "logits: tensor([13.2524], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2876], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6128], device='cuda:0')\n",
            "{'loss': 0.1143, 'learning_rate': 2.8505255656511667e-08, 'rewards/real': 0.7395158410072327, 'rewards/generated': -1.7947269678115845, 'rewards/accuracies': 1.0, 'rewards/margins': 2.534242868423462, 'logps/generated': -422.006103515625, 'logps/real': -623.6248779296875, 'logits/generated': -1.8897647857666016, 'logits/real': -1.8587716817855835, 'epoch': 2.85}\n",
            " 95% 5930/6237 [1:43:19<05:20,  1.04s/it]losses: tensor([0.0599], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-260.5063], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-392.2765], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-270.1417], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-374.0697], device='cuda:0')\n",
            "logits: tensor([27.8422], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9635], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8207], device='cuda:0')\n",
            " 95% 5931/6237 [1:43:19<04:31,  1.13it/s]losses: tensor([0.0746], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-422.0196], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.7092], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-426.4046], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.5093], device='cuda:0')\n",
            "logits: tensor([25.5849], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4385], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1200], device='cuda:0')\n",
            " 95% 5932/6237 [1:43:20<04:26,  1.14it/s]losses: tensor([0.0729], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-602.7597], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.1528], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-607.6289], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.2017], device='cuda:0')\n",
            "logits: tensor([25.8203], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4869], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0951], device='cuda:0')\n",
            " 95% 5933/6237 [1:43:21<04:28,  1.13it/s]losses: tensor([0.1197], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-392.0631], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-378.8657], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-402.2195], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.4016], device='cuda:0')\n",
            "logits: tensor([20.6204], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0156], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0464], device='cuda:0')\n",
            " 95% 5934/6237 [1:43:22<04:23,  1.15it/s]losses: tensor([0.0671], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1146.9785], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-404.3135], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1155.1274], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.7812], device='cuda:0')\n",
            "logits: tensor([26.6812], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8149], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8532], device='cuda:0')\n",
            " 95% 5935/6237 [1:43:23<04:51,  1.03it/s]losses: tensor([0.2660], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-451.5066], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.3700], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-452.5228], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.5024], device='cuda:0')\n",
            "logits: tensor([11.8838], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1016], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0868], device='cuda:0')\n",
            " 95% 5936/6237 [1:43:25<05:22,  1.07s/it]losses: tensor([0.2736], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-682.0980], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-313.5727], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-686.3706], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-306.2822], device='cuda:0')\n",
            "logits: tensor([11.5631], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4273], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7291], device='cuda:0')\n",
            " 95% 5937/6237 [1:43:26<05:44,  1.15s/it]losses: tensor([0.0603], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-825.3949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.1321], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-833.2985], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-423.2533], device='cuda:0')\n",
            "logits: tensor([27.7823], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7904], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9879], device='cuda:0')\n",
            " 95% 5938/6237 [1:43:27<05:47,  1.16s/it]losses: tensor([0.0456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-417.3459], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-576.1404], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-421.9944], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-550.1388], device='cuda:0')\n",
            "logits: tensor([30.6502], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4649], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6002], device='cuda:0')\n",
            " 95% 5939/6237 [1:43:29<06:17,  1.27s/it]losses: tensor([0.0628], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-337.0699], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.0523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-351.3200], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.9382], device='cuda:0')\n",
            "logits: tensor([27.3642], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4250], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3114], device='cuda:0')\n",
            "{'loss': 0.1102, 'learning_rate': 2.7614466417245678e-08, 'rewards/real': 0.6928598284721375, 'rewards/generated': -1.6650670766830444, 'rewards/accuracies': 1.0, 'rewards/margins': 2.357926845550537, 'logps/generated': -426.95849609375, 'logps/real': -553.7742919921875, 'logits/generated': -1.441349744796753, 'logits/real': -1.399221658706665, 'epoch': 2.86}\n",
            " 95% 5940/6237 [1:43:29<05:36,  1.13s/it]losses: tensor([0.1843], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1183.3702], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.7629], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1189.7305], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.1443], device='cuda:0')\n",
            "logits: tensor([15.9788], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6360], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9619], device='cuda:0')\n",
            " 95% 5941/6237 [1:43:31<06:04,  1.23s/it]losses: tensor([0.0788], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-829.4756], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.7148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-837.9164], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.1459], device='cuda:0')\n",
            "logits: tensor([25.0096], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8441], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6569], device='cuda:0')\n",
            " 95% 5942/6237 [1:43:32<05:52,  1.20s/it]losses: tensor([0.0590], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-131.8884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.6087], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-148.4475], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.1675], device='cuda:0')\n",
            "logits: tensor([28.0003], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6559], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1441], device='cuda:0')\n",
            " 95% 5943/6237 [1:43:33<05:09,  1.05s/it]losses: tensor([0.1117], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-326.1451], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-398.4059], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-331.2736], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-382.1783], device='cuda:0')\n",
            "logits: tensor([21.3562], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5129], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6228], device='cuda:0')\n",
            " 95% 5944/6237 [1:43:33<04:22,  1.12it/s]losses: tensor([0.0628], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-304.4100], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.6128], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-310.0349], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-453.8749], device='cuda:0')\n",
            "logits: tensor([27.3627], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5625], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1738], device='cuda:0')\n",
            " 95% 5945/6237 [1:43:35<05:08,  1.06s/it]losses: tensor([0.1232], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-835.0402], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.9170], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-838.9912], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.5490], device='cuda:0')\n",
            "logits: tensor([20.3190], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3951], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6368], device='cuda:0')\n",
            " 95% 5946/6237 [1:43:36<04:56,  1.02s/it]losses: tensor([0.3428], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-889.3275], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.1425], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-886.4037], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.2761], device='cuda:0')\n",
            "logits: tensor([8.9426], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2924], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1866], device='cuda:0')\n",
            " 95% 5947/6237 [1:43:37<05:11,  1.07s/it]losses: tensor([0.0458], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-258.5849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.7448], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-263.5855], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-458.1389], device='cuda:0')\n",
            "logits: tensor([30.6066], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5001], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5606], device='cuda:0')\n",
            " 95% 5948/6237 [1:43:37<04:38,  1.04it/s]losses: tensor([0.0825], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-579.1249], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-361.8842], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-599.1511], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-357.3823], device='cuda:0')\n",
            "logits: tensor([24.5281], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0026], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4502], device='cuda:0')\n",
            " 95% 5949/6237 [1:43:38<03:59,  1.20it/s]losses: tensor([0.1926], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-941.6321], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.4802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-934.6719], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.0255], device='cuda:0')\n",
            "logits: tensor([15.4946], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6960], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2455], device='cuda:0')\n",
            "{'loss': 0.1284, 'learning_rate': 2.672367717797969e-08, 'rewards/real': 0.6120749115943909, 'rewards/generated': -1.5639092922210693, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1759846210479736, 'logps/generated': -427.327392578125, 'logps/real': -627.89990234375, 'logits/generated': -1.8121439218521118, 'logits/real': -1.7471176385879517, 'epoch': 2.86}\n",
            " 95% 5950/6237 [1:43:40<04:58,  1.04s/it]losses: tensor([0.0192], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1122.3206], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.1711], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1139.6270], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.0566], device='cuda:0')\n",
            "logits: tensor([39.4209], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7306], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2115], device='cuda:0')\n",
            " 95% 5951/6237 [1:43:41<05:08,  1.08s/it]losses: tensor([0.1061], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-192.7127], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-345.3029], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-206.2690], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-336.9562], device='cuda:0')\n",
            "logits: tensor([21.9029], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3556], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8347], device='cuda:0')\n",
            " 95% 5952/6237 [1:43:41<04:25,  1.07it/s]losses: tensor([0.5110], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-928.6998], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.0268], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-933.2952], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-423.5710], device='cuda:0')\n",
            "logits: tensor([4.0511], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4595], device='cuda:0')\n",
            "generated_rewards: tensor([0.0544], device='cuda:0')\n",
            " 95% 5953/6237 [1:43:43<05:50,  1.23s/it]losses: tensor([0.3309], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.8287], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.4756], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-754.3869], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.6758], device='cuda:0')\n",
            "logits: tensor([9.3580], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1442], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0800], device='cuda:0')\n",
            " 95% 5954/6237 [1:43:44<05:40,  1.20s/it]losses: tensor([0.0114], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-214.7788], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.1646], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-224.9869], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.6741], device='cuda:0')\n",
            "logits: tensor([44.6986], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0208], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4490], device='cuda:0')\n",
            " 95% 5955/6237 [1:43:45<05:16,  1.12s/it]losses: tensor([0.2979], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-248.6134], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-235.9263], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-260.8414], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-237.5708], device='cuda:0')\n",
            "logits: tensor([10.5835], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2228], device='cuda:0')\n",
            "generated_rewards: tensor([0.1644], device='cuda:0')\n",
            " 95% 5956/6237 [1:43:46<04:42,  1.01s/it]losses: tensor([0.1490], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-233.8468], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.2431], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-238.8667], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.9809], device='cuda:0')\n",
            "logits: tensor([18.2821], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5020], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3262], device='cuda:0')\n",
            " 96% 5957/6237 [1:43:47<04:00,  1.16it/s]losses: tensor([0.4162], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-958.5952], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.0165], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-958.6525], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.4617], device='cuda:0')\n",
            "logits: tensor([6.6121], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0057], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6555], device='cuda:0')\n",
            " 96% 5958/6237 [1:43:48<04:44,  1.02s/it]losses: tensor([0.0716], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-194.9075], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-341.1849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-212.7313], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-332.9953], device='cuda:0')\n",
            "logits: tensor([26.0135], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7824], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8190], device='cuda:0')\n",
            " 96% 5959/6237 [1:43:48<04:02,  1.15it/s]losses: tensor([0.0346], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-184.5066], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.6600], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-196.1566], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.8392], device='cuda:0')\n",
            "logits: tensor([33.4708], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1650], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1821], device='cuda:0')\n",
            "{'loss': 0.1948, 'learning_rate': 2.5832887938713697e-08, 'rewards/real': 0.9100324511528015, 'rewards/generated': -1.233902096748352, 'rewards/accuracies': 1.0, 'rewards/margins': 2.143934726715088, 'logps/generated': -383.41717529296875, 'logps/real': -503.4810485839844, 'logits/generated': -1.487852692604065, 'logits/real': -1.3195202350616455, 'epoch': 2.87}\n",
            " 96% 5960/6237 [1:43:49<03:32,  1.31it/s]losses: tensor([0.0518], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-420.7516], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.4731], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-433.3962], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.7734], device='cuda:0')\n",
            "logits: tensor([29.3444], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2645], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6700], device='cuda:0')\n",
            " 96% 5961/6237 [1:43:50<03:17,  1.40it/s]losses: tensor([0.0625], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-299.5554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.2090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-310.1893], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.4302], device='cuda:0')\n",
            "logits: tensor([27.4127], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0634], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6779], device='cuda:0')\n",
            " 96% 5962/6237 [1:43:50<03:07,  1.47it/s]losses: tensor([0.0168], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-249.2543], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.3873], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-260.9853], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.3560], device='cuda:0')\n",
            "logits: tensor([40.7623], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1731], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9031], device='cuda:0')\n",
            " 96% 5963/6237 [1:43:51<03:55,  1.16it/s]losses: tensor([0.2394], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-299.7960], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-287.9676], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-311.4900], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-286.5884], device='cuda:0')\n",
            "logits: tensor([13.0732], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1694], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1379], device='cuda:0')\n",
            " 96% 5964/6237 [1:43:52<03:29,  1.30it/s]losses: tensor([0.0527], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-573.6634], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.3027], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-582.6607], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.1417], device='cuda:0')\n",
            "logits: tensor([29.1584], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8997], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0161], device='cuda:0')\n",
            " 96% 5965/6237 [1:43:53<03:27,  1.31it/s]losses: tensor([0.1079], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-373.2294], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-400.6096], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-377.9115], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.5670], device='cuda:0')\n",
            "logits: tensor([21.7247], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4682], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7043], device='cuda:0')\n",
            " 96% 5966/6237 [1:43:53<03:06,  1.46it/s]losses: tensor([0.0381], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-224.8867], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-342.8058], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-239.3119], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-324.7334], device='cuda:0')\n",
            "logits: tensor([32.4976], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4425], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8072], device='cuda:0')\n",
            " 96% 5967/6237 [1:43:54<03:16,  1.38it/s]losses: tensor([0.0404], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-236.5298], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.5730], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-241.0231], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.1690], device='cuda:0')\n",
            "logits: tensor([31.8972], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4493], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7404], device='cuda:0')\n",
            " 96% 5968/6237 [1:43:55<03:12,  1.40it/s]losses: tensor([0.1236], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-349.7200], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-290.6000], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-359.3683], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-279.9700], device='cuda:0')\n",
            "logits: tensor([20.2784], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9648], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0630], device='cuda:0')\n",
            " 96% 5969/6237 [1:43:56<03:25,  1.30it/s]losses: tensor([0.1709], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-191.1716], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.5011], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-199.0081], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.5370], device='cuda:0')\n",
            "logits: tensor([16.8006], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7837], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8964], device='cuda:0')\n",
            "{'loss': 0.0904, 'learning_rate': 2.494209869944771e-08, 'rewards/real': 0.9678629040718079, 'rewards/generated': -1.6616309881210327, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6294939517974854, 'logps/generated': -385.44293212890625, 'logps/real': -321.8558349609375, 'logits/generated': -1.3963452577590942, 'logits/real': -1.3967806100845337, 'epoch': 2.87}\n",
            " 96% 5970/6237 [1:43:56<03:16,  1.36it/s]losses: tensor([0.2793], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1024.4548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.1115], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1019.7036], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.0347], device='cuda:0')\n",
            "logits: tensor([11.3256], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4751], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6077], device='cuda:0')\n",
            " 96% 5971/6237 [1:43:58<04:11,  1.06it/s]losses: tensor([0.0708], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1170.6079], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.1712], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1172.5122], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.9548], device='cuda:0')\n",
            "logits: tensor([26.1207], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1904], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4216], device='cuda:0')\n",
            " 96% 5972/6237 [1:43:59<04:50,  1.10s/it]losses: tensor([0.0624], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-233.8988], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.2554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-245.4164], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.3408], device='cuda:0')\n",
            "logits: tensor([27.4323], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1518], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5915], device='cuda:0')\n",
            " 96% 5973/6237 [1:44:00<04:24,  1.00s/it]losses: tensor([0.1108], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-274.2933], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.6933], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-278.6528], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.6125], device='cuda:0')\n",
            "logits: tensor([21.4404], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4360], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7081], device='cuda:0')\n",
            " 96% 5974/6237 [1:44:01<03:45,  1.17it/s]losses: tensor([0.1046], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-731.0703], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.0922], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-735.8104], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.7887], device='cuda:0')\n",
            "logits: tensor([22.0436], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4740], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7303], device='cuda:0')\n",
            " 96% 5975/6237 [1:44:01<03:52,  1.13it/s]losses: tensor([0.1846], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1011.1116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.9971], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1019.7844], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.7105], device='cuda:0')\n",
            "logits: tensor([15.9593], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8673], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7287], device='cuda:0')\n",
            " 96% 5976/6237 [1:44:02<04:01,  1.08it/s]losses: tensor([0.0703], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-170.2509], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-492.9672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-177.4884], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-474.0142], device='cuda:0')\n",
            "logits: tensor([26.1905], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7237], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8953], device='cuda:0')\n",
            " 96% 5977/6237 [1:44:03<04:00,  1.08it/s]losses: tensor([0.2549], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-160.3556], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-286.4437], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-173.0968], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-286.8167], device='cuda:0')\n",
            "logits: tensor([12.3683], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2741], device='cuda:0')\n",
            "generated_rewards: tensor([0.0373], device='cuda:0')\n",
            " 96% 5978/6237 [1:44:05<04:34,  1.06s/it]losses: tensor([0.0061], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-107.0308], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-554.1410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-125.5587], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-521.7096], device='cuda:0')\n",
            "logits: tensor([50.9593], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8528], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2431], device='cuda:0')\n",
            " 96% 5979/6237 [1:44:06<04:16,  1.00it/s]losses: tensor([0.1571], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-179.9311], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.6964], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-187.5695], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.6244], device='cuda:0')\n",
            "logits: tensor([17.7103], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7638], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0072], device='cuda:0')\n",
            "{'loss': 0.1301, 'learning_rate': 2.405130946018172e-08, 'rewards/real': 0.72588050365448, 'rewards/generated': -1.5896209478378296, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3155014514923096, 'logps/generated': -433.55694580078125, 'logps/real': -506.30047607421875, 'logits/generated': -1.6024587154388428, 'logits/real': -1.4648271799087524, 'epoch': 2.88}\n",
            " 96% 5980/6237 [1:44:06<03:46,  1.13it/s]losses: tensor([0.2087], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-147.2255], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-360.4344], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-156.0454], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-354.6466], device='cuda:0')\n",
            "logits: tensor([14.6076], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8820], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5788], device='cuda:0')\n",
            " 96% 5981/6237 [1:44:07<03:17,  1.30it/s]losses: tensor([0.1260], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-134.9649], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.4892], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-143.4052], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-359.8535], device='cuda:0')\n",
            "logits: tensor([20.0760], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8440], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1636], device='cuda:0')\n",
            " 96% 5982/6237 [1:44:07<03:04,  1.38it/s]losses: tensor([0.1844], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-278.1194], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-338.6082], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-283.3415], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-327.8596], device='cuda:0')\n",
            "logits: tensor([15.9707], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5222], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0749], device='cuda:0')\n",
            " 96% 5983/6237 [1:44:08<02:55,  1.45it/s]losses: tensor([0.1319], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-184.4271], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-318.8140], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-193.2055], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-308.0032], device='cuda:0')\n",
            "logits: tensor([19.5891], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8778], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0811], device='cuda:0')\n",
            " 96% 5984/6237 [1:44:09<03:11,  1.32it/s]losses: tensor([0.1968], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-763.2995], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-377.7450], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-764.7643], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.9536], device='cuda:0')\n",
            "logits: tensor([15.2563], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1465], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3791], device='cuda:0')\n",
            " 96% 5985/6237 [1:44:10<03:26,  1.22it/s]losses: tensor([0.0598], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-113.6155], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.1542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-124.4552], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.1219], device='cuda:0')\n",
            "logits: tensor([27.8720], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0840], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7032], device='cuda:0')\n",
            " 96% 5986/6237 [1:44:11<03:59,  1.05it/s]losses: tensor([0.1299], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-172.6817], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-316.9426], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.1875], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-312.6940], device='cuda:0')\n",
            "logits: tensor([19.7545], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5506], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4249], device='cuda:0')\n",
            " 96% 5987/6237 [1:44:12<03:49,  1.09it/s]losses: tensor([0.3146], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-395.0976], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-335.7655], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-394.9443], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-325.6617], device='cuda:0')\n",
            "logits: tensor([9.9505], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0153], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0104], device='cuda:0')\n",
            " 96% 5988/6237 [1:44:13<03:33,  1.17it/s]losses: tensor([0.0330], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-804.4067], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.0041], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-815.8731], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.5243], device='cuda:0')\n",
            "logits: tensor([33.9462], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1466], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2480], device='cuda:0')\n",
            " 96% 5989/6237 [1:44:14<03:47,  1.09it/s]losses: tensor([0.1134], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-628.0504], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-401.7748], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-632.2489], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.7733], device='cuda:0')\n",
            "logits: tensor([21.2001], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4198], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7002], device='cuda:0')\n",
            "{'loss': 0.1498, 'learning_rate': 2.316052022091573e-08, 'rewards/real': 0.7458267211914062, 'rewards/generated': -1.2364026308059692, 'rewards/accuracies': 1.0, 'rewards/margins': 1.982229471206665, 'logps/generated': -364.3731689453125, 'logps/real': -362.1888427734375, 'logits/generated': -1.77643620967865, 'logits/real': -1.5801074504852295, 'epoch': 2.88}\n",
            " 96% 5990/6237 [1:44:15<03:49,  1.08it/s]losses: tensor([0.1114], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-750.0238], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-335.1766], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-762.1222], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-325.8910], device='cuda:0')\n",
            "logits: tensor([21.3840], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2098], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9286], device='cuda:0')\n",
            " 96% 5991/6237 [1:44:16<04:03,  1.01it/s]losses: tensor([0.4714], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-936.8108], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.9675], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-933.2938], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-372.3789], device='cuda:0')\n",
            "logits: tensor([5.0717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3517], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8589], device='cuda:0')\n",
            " 96% 5992/6237 [1:44:17<04:35,  1.12s/it]losses: tensor([0.1074], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1022.8160], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.2130], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1032.3311], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.9602], device='cuda:0')\n",
            "logits: tensor([21.7679], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9515], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2253], device='cuda:0')\n",
            " 96% 5993/6237 [1:44:19<04:55,  1.21s/it]losses: tensor([0.0306], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-417.1467], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-345.9818], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-433.6294], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-327.7500], device='cuda:0')\n",
            "logits: tensor([34.7144], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6483], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8232], device='cuda:0')\n",
            " 96% 5994/6237 [1:44:19<04:08,  1.02s/it]losses: tensor([0.0270], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-282.7622], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.4890], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-287.7933], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.5491], device='cuda:0')\n",
            "logits: tensor([35.9710], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5031], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0940], device='cuda:0')\n",
            " 96% 5995/6237 [1:44:21<04:36,  1.14s/it]losses: tensor([0.2024], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-483.0245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-262.0670], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-493.5514], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-257.6503], device='cuda:0')\n",
            "logits: tensor([14.9435], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0527], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4417], device='cuda:0')\n",
            " 96% 5996/6237 [1:44:21<04:05,  1.02s/it]losses: tensor([0.2774], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-472.6871], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.0871], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-473.1995], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.1947], device='cuda:0')\n",
            "logits: tensor([11.4048], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0512], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0892], device='cuda:0')\n",
            " 96% 5997/6237 [1:44:22<03:30,  1.14it/s]losses: tensor([0.0964], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-441.3068], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.5292], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-437.2549], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.5671], device='cuda:0')\n",
            "logits: tensor([22.9102], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4052], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6962], device='cuda:0')\n",
            " 96% 5998/6237 [1:44:23<03:32,  1.13it/s]losses: tensor([0.0165], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-158.9309], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.7759], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-174.3122], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.2169], device='cuda:0')\n",
            "logits: tensor([40.9404], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5381], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5559], device='cuda:0')\n",
            " 96% 5999/6237 [1:44:24<03:25,  1.16it/s]losses: tensor([0.3574], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-794.5193], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.9643], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-788.7894], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.7864], device='cuda:0')\n",
            "logits: tensor([8.4481], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5730], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4178], device='cuda:0')\n",
            "{'loss': 0.1698, 'learning_rate': 2.226973098164974e-08, 'rewards/real': 0.5624908208847046, 'rewards/generated': -1.6130691766738892, 'rewards/accuracies': 1.0, 'rewards/margins': 2.175560235977173, 'logps/generated': -379.025146484375, 'logps/real': -576.0028076171875, 'logits/generated': -1.4935238361358643, 'logits/real': -1.3058762550354004, 'epoch': 2.89}\n",
            " 96% 6000/6237 [1:44:25<03:49,  1.03it/s]losses: tensor([0.4220], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-394.9520], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-250.7050], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-406.8123], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-256.1215], device='cuda:0')\n",
            "logits: tensor([6.4438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1860], device='cuda:0')\n",
            "generated_rewards: tensor([0.5417], device='cuda:0')\n",
            " 96% 6001/6237 [1:44:26<03:36,  1.09it/s]losses: tensor([0.1723], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-576.9673], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-425.2422], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-575.8571], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.4213], device='cuda:0')\n",
            "logits: tensor([16.7107], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1110], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7821], device='cuda:0')\n",
            " 96% 6002/6237 [1:44:26<03:20,  1.17it/s]losses: tensor([0.1926], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-493.3802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-326.8409], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-502.9318], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-320.9012], device='cuda:0')\n",
            "logits: tensor([15.4913], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9552], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5940], device='cuda:0')\n",
            " 96% 6003/6237 [1:44:28<03:37,  1.08it/s]losses: tensor([0.0263], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-195.2546], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.7999], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-214.4006], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.6931], device='cuda:0')\n",
            "logits: tensor([36.2529], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.9146], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7107], device='cuda:0')\n",
            " 96% 6004/6237 [1:44:29<03:47,  1.02it/s]losses: tensor([0.0252], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-491.1793], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-375.1612], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-510.1268], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-357.4131], device='cuda:0')\n",
            "logits: tensor([36.6956], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8947], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7748], device='cuda:0')\n",
            " 96% 6005/6237 [1:44:29<03:36,  1.07it/s]losses: tensor([0.0355], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-594.3684], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.6884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-603.7555], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-479.8848], device='cuda:0')\n",
            "logits: tensor([33.1907], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9387], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3804], device='cuda:0')\n",
            " 96% 6006/6237 [1:44:30<03:12,  1.20it/s]losses: tensor([0.1268], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-266.2538], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-355.1970], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-276.2030], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-345.1393], device='cuda:0')\n",
            "logits: tensor([20.0069], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9949], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0058], device='cuda:0')\n",
            " 96% 6007/6237 [1:44:31<03:49,  1.00it/s]losses: tensor([0.0269], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-345.9334], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.4056], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-347.3238], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.7662], device='cuda:0')\n",
            "logits: tensor([36.0298], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1390], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4639], device='cuda:0')\n",
            " 96% 6008/6237 [1:44:32<03:15,  1.17it/s]losses: tensor([0.0763], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-713.7927], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.1776], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-721.6023], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.6425], device='cuda:0')\n",
            "logits: tensor([25.3446], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7810], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7535], device='cuda:0')\n",
            " 96% 6009/6237 [1:44:33<03:41,  1.03it/s]losses: tensor([0.2922], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-360.4074], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-348.9877], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-362.9208], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-340.6950], device='cuda:0')\n",
            "logits: tensor([10.8061], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2513], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8293], device='cuda:0')\n",
            "{'loss': 0.1396, 'learning_rate': 2.1378941742383754e-08, 'rewards/real': 0.8944485783576965, 'rewards/generated': -1.475274920463562, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3697235584259033, 'logps/generated': -386.1205139160156, 'logps/real': -443.2489318847656, 'logits/generated': -1.5271776914596558, 'logits/real': -1.4925686120986938, 'epoch': 2.89}\n",
            " 96% 6010/6237 [1:44:34<03:09,  1.20it/s]losses: tensor([0.0089], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1616.4988], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.5764], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1634.9489], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-381.8546], device='cuda:0')\n",
            "logits: tensor([47.1719], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8450], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8722], device='cuda:0')\n",
            " 96% 6011/6237 [1:44:36<04:21,  1.16s/it]losses: tensor([0.2388], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-843.6553], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-450.6035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-843.1818], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.0270], device='cuda:0')\n",
            "logits: tensor([13.1029], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0474], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3576], device='cuda:0')\n",
            " 96% 6012/6237 [1:44:37<04:20,  1.16s/it]losses: tensor([0.2391], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-433.1265], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-312.8172], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-439.3011], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-305.9008], device='cuda:0')\n",
            "logits: tensor([13.0910], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6175], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6916], device='cuda:0')\n",
            " 96% 6013/6237 [1:44:38<04:18,  1.15s/it]losses: tensor([0.0289], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-411.6558], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.9489], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-421.3086], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.3026], device='cuda:0')\n",
            "logits: tensor([35.2990], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9653], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5646], device='cuda:0')\n",
            " 96% 6014/6237 [1:44:38<03:34,  1.04it/s]losses: tensor([0.0167], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-121.2886], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.4289], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-140.6526], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.9241], device='cuda:0')\n",
            "logits: tensor([40.8688], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.9364], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1505], device='cuda:0')\n",
            " 96% 6015/6237 [1:44:39<03:30,  1.05it/s]losses: tensor([0.0421], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-170.5361], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.1751], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-187.6429], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.8279], device='cuda:0')\n",
            "logits: tensor([31.4540], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7107], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4347], device='cuda:0')\n",
            " 96% 6016/6237 [1:44:40<03:32,  1.04it/s]losses: tensor([0.2108], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-866.7338], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-414.3511], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-867.2372], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.3605], device='cuda:0')\n",
            "logits: tensor([14.4941], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0503], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3991], device='cuda:0')\n",
            " 96% 6017/6237 [1:44:42<04:07,  1.13s/it]losses: tensor([0.0315], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-402.9175], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.0964], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-409.0763], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.8264], device='cuda:0')\n",
            "logits: tensor([34.4289], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6159], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8270], device='cuda:0')\n",
            " 96% 6018/6237 [1:44:42<03:33,  1.02it/s]losses: tensor([0.1165], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-280.9044], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-510.6610], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-288.8387], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-497.6844], device='cuda:0')\n",
            "logits: tensor([20.9110], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7934], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2977], device='cuda:0')\n",
            " 97% 6019/6237 [1:44:44<04:07,  1.14s/it]losses: tensor([0.0539], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-940.0043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.5682], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-951.1470], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.7789], device='cuda:0')\n",
            "logits: tensor([28.9321], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1143], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7789], device='cuda:0')\n",
            "{'loss': 0.0987, 'learning_rate': 2.048815250311776e-08, 'rewards/real': 0.9601408243179321, 'rewards/generated': -1.8373947143554688, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7975356578826904, 'logps/generated': -415.52264404296875, 'logps/real': -608.7321166992188, 'logits/generated': -1.8037617206573486, 'logits/real': -1.7910207509994507, 'epoch': 2.9}\n",
            " 97% 6020/6237 [1:44:45<03:48,  1.06s/it]losses: tensor([0.0206], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-230.8122], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.7503], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-246.3081], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.5052], device='cuda:0')\n",
            "logits: tensor([38.7410], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5496], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3245], device='cuda:0')\n",
            " 97% 6021/6237 [1:44:46<03:24,  1.05it/s]losses: tensor([0.2233], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-791.6797], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.2908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-799.2173], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.9715], device='cuda:0')\n",
            "logits: tensor([13.8569], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7538], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6319], device='cuda:0')\n",
            " 97% 6022/6237 [1:44:47<03:30,  1.02it/s]losses: tensor([0.0413], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-426.7519], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-474.4615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-437.7943], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-453.8322], device='cuda:0')\n",
            "logits: tensor([31.6717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1042], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0629], device='cuda:0')\n",
            " 97% 6023/6237 [1:44:48<03:33,  1.00it/s]losses: tensor([0.1098], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-444.2561], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.2394], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-457.2267], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.6731], device='cuda:0')\n",
            "logits: tensor([21.5369], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2971], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8566], device='cuda:0')\n",
            " 97% 6024/6237 [1:44:48<03:01,  1.17it/s]losses: tensor([0.0354], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.0629], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.2877], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-300.2124], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.2071], device='cuda:0')\n",
            "logits: tensor([33.2300], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2149], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1081], device='cuda:0')\n",
            " 97% 6025/6237 [1:44:50<03:44,  1.06s/it]losses: tensor([0.2504], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-331.1655], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-315.4050], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-341.0797], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-312.7516], device='cuda:0')\n",
            "logits: tensor([12.5676], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9914], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2653], device='cuda:0')\n",
            " 97% 6026/6237 [1:44:51<03:33,  1.01s/it]losses: tensor([0.2171], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-324.6906], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.6548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-335.1468], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.9410], device='cuda:0')\n",
            "logits: tensor([14.1700], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0456], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3714], device='cuda:0')\n",
            " 97% 6027/6237 [1:44:52<04:04,  1.16s/it]losses: tensor([0.1774], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-366.0201], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.4162], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-378.0564], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.0600], device='cuda:0')\n",
            "logits: tensor([16.3925], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2036], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4356], device='cuda:0')\n",
            " 97% 6028/6237 [1:44:54<04:19,  1.24s/it]losses: tensor([0.0386], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-122.5868], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.8025], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-136.6444], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.4968], device='cuda:0')\n",
            "logits: tensor([32.3633], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4058], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8306], device='cuda:0')\n",
            " 97% 6029/6237 [1:44:55<04:19,  1.25s/it]losses: tensor([0.0542], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-191.0304], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.1498], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-200.8622], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.1115], device='cuda:0')\n",
            "logits: tensor([28.8702], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9832], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9038], device='cuda:0')\n",
            "{'loss': 0.1168, 'learning_rate': 1.9597363263851772e-08, 'rewards/real': 1.1549217700958252, 'rewards/generated': -1.279078483581543, 'rewards/accuracies': 1.0, 'rewards/margins': 2.434000253677368, 'logps/generated': -434.0458068847656, 'logps/real': -351.70562744140625, 'logits/generated': -1.1501915454864502, 'logits/real': -1.2268999814987183, 'epoch': 2.9}\n",
            " 97% 6030/6237 [1:44:56<04:25,  1.28s/it]losses: tensor([0.0600], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-547.3845], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-506.6805], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-556.2334], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-487.6973], device='cuda:0')\n",
            "logits: tensor([27.8322], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8849], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8983], device='cuda:0')\n",
            " 97% 6031/6237 [1:44:58<04:39,  1.36s/it]losses: tensor([0.1487], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-161.1578], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-339.1510], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.4527], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-336.1373], device='cuda:0')\n",
            "logits: tensor([18.3086], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5295], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3014], device='cuda:0')\n",
            " 97% 6032/6237 [1:44:59<04:48,  1.41s/it]losses: tensor([0.1846], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-733.5948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-402.7651], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-739.6287], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.8378], device='cuda:0')\n",
            "logits: tensor([15.9611], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6034], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9927], device='cuda:0')\n",
            " 97% 6033/6237 [1:45:00<04:05,  1.20s/it]losses: tensor([0.0370], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1056.7991], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.6849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1066.3901], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-433.4881], device='cuda:0')\n",
            "logits: tensor([32.7878], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9591], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3197], device='cuda:0')\n",
            " 97% 6034/6237 [1:45:01<04:00,  1.19s/it]losses: tensor([0.1229], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-335.6853], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-507.6626], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-340.7452], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.3822], device='cuda:0')\n",
            "logits: tensor([20.3403], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5060], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5280], device='cuda:0')\n",
            " 97% 6035/6237 [1:45:03<04:38,  1.38s/it]losses: tensor([0.0667], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-108.9246], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-478.6248], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-121.4190], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-464.3751], device='cuda:0')\n",
            "logits: tensor([26.7441], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2494], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4250], device='cuda:0')\n",
            " 97% 6036/6237 [1:45:04<04:21,  1.30s/it]losses: tensor([0.0194], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-516.0297], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-427.8242], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-533.3486], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.8300], device='cuda:0')\n",
            "logits: tensor([39.3131], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7319], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1994], device='cuda:0')\n",
            " 97% 6037/6237 [1:45:05<03:33,  1.07s/it]losses: tensor([0.2232], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-294.5098], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-252.2265], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-308.9698], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-252.8277], device='cuda:0')\n",
            "logits: tensor([13.8588], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4460], device='cuda:0')\n",
            "generated_rewards: tensor([0.0601], device='cuda:0')\n",
            " 97% 6038/6237 [1:45:05<03:23,  1.02s/it]losses: tensor([0.1014], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-376.9108], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-361.9427], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-385.2220], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-347.8757], device='cuda:0')\n",
            "logits: tensor([22.3783], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8311], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4067], device='cuda:0')\n",
            " 97% 6039/6237 [1:45:06<03:01,  1.09it/s]losses: tensor([0.1010], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-205.7760], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-298.7357], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-216.7368], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-287.2816], device='cuda:0')\n",
            "logits: tensor([22.4149], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0961], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1454], device='cuda:0')\n",
            "{'loss': 0.1065, 'learning_rate': 1.870657402458578e-08, 'rewards/real': 1.0837398767471313, 'rewards/generated': -1.315651774406433, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3993916511535645, 'logps/generated': -403.22979736328125, 'logps/real': -433.67724609375, 'logits/generated': -1.3816524744033813, 'logits/real': -1.3398771286010742, 'epoch': 2.91}\n",
            " 97% 6040/6237 [1:45:08<03:41,  1.12s/it]losses: tensor([0.2428], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.1588], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.4391], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-469.4768], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.8427], device='cuda:0')\n",
            "logits: tensor([12.9146], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5318], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7596], device='cuda:0')\n",
            " 97% 6041/6237 [1:45:08<03:10,  1.03it/s]losses: tensor([0.0746], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-230.6912], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-486.5502], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-240.4253], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-470.6999], device='cuda:0')\n",
            "logits: tensor([25.5843], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9734], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5850], device='cuda:0')\n",
            " 97% 6042/6237 [1:45:10<03:46,  1.16s/it]losses: tensor([0.0633], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-265.1184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.2236], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-273.5457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.3694], device='cuda:0')\n",
            "logits: tensor([27.2815], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8427], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8854], device='cuda:0')\n",
            " 97% 6043/6237 [1:45:10<03:07,  1.03it/s]losses: tensor([0.1752], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-901.9908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.2261], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-892.5001], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.2046], device='cuda:0')\n",
            "logits: tensor([16.5308], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9491], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6022], device='cuda:0')\n",
            " 97% 6044/6237 [1:45:12<03:29,  1.08s/it]losses: tensor([0.1120], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-987.8397], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-378.0001], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-998.2332], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.0638], device='cuda:0')\n",
            "logits: tensor([21.3297], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0393], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0936], device='cuda:0')\n",
            " 97% 6045/6237 [1:45:13<03:52,  1.21s/it]losses: tensor([0.2046], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-388.6542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-332.2992], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-395.6490], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-324.4688], device='cuda:0')\n",
            "logits: tensor([14.8252], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6995], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7830], device='cuda:0')\n",
            " 97% 6046/6237 [1:45:14<03:18,  1.04s/it]losses: tensor([0.1265], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-197.4122], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.6307], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-206.2910], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-428.4708], device='cuda:0')\n",
            "logits: tensor([20.0386], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8879], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1160], device='cuda:0')\n",
            " 97% 6047/6237 [1:45:16<03:45,  1.19s/it]losses: tensor([0.0469], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-281.7161], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.5414], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-294.2214], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.6937], device='cuda:0')\n",
            "logits: tensor([30.3530], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2505], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7848], device='cuda:0')\n",
            " 97% 6048/6237 [1:45:16<03:21,  1.06s/it]losses: tensor([0.0269], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-233.8344], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.6266], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-243.4451], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.2202], device='cuda:0')\n",
            "logits: tensor([36.0170], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9611], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6406], device='cuda:0')\n",
            " 97% 6049/6237 [1:45:17<03:06,  1.01it/s]losses: tensor([0.0809], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1137.7174], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.0189], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1146.1897], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.7495], device='cuda:0')\n",
            "logits: tensor([24.7417], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8472], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6269], device='cuda:0')\n",
            "{'loss': 0.1154, 'learning_rate': 1.7815784785319794e-08, 'rewards/real': 0.7084396481513977, 'rewards/generated': -1.587726354598999, 'rewards/accuracies': 1.0, 'rewards/margins': 2.296166181564331, 'logps/generated': -428.95562744140625, 'logps/real': -508.91339111328125, 'logits/generated': -1.668808937072754, 'logits/real': -1.5542738437652588, 'epoch': 2.91}\n",
            " 97% 6050/6237 [1:45:18<03:23,  1.09s/it]losses: tensor([0.0565], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-289.3326], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.9025], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-303.3071], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.4266], device='cuda:0')\n",
            "logits: tensor([28.4504], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3975], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4476], device='cuda:0')\n",
            " 97% 6051/6237 [1:45:19<02:57,  1.05it/s]losses: tensor([0.0504], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-499.5576], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-383.4866], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-509.0545], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.3642], device='cuda:0')\n",
            "logits: tensor([29.6193], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9497], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0122], device='cuda:0')\n",
            " 97% 6052/6237 [1:45:20<02:33,  1.20it/s]losses: tensor([0.1980], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-510.3480], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.0837], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-514.7457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.2923], device='cuda:0')\n",
            "logits: tensor([15.1891], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4398], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0791], device='cuda:0')\n",
            " 97% 6053/6237 [1:45:20<02:24,  1.27it/s]losses: tensor([0.0456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-972.5667], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.0966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-983.3271], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.2185], device='cuda:0')\n",
            "logits: tensor([30.6385], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0760], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9878], device='cuda:0')\n",
            " 97% 6054/6237 [1:45:22<02:59,  1.02it/s]losses: tensor([0.1020], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-702.4970], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.1599], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-704.3582], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.7111], device='cuda:0')\n",
            "logits: tensor([22.3100], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1861], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0449], device='cuda:0')\n",
            " 97% 6055/6237 [1:45:23<03:01,  1.00it/s]losses: tensor([0.0300], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-429.1171], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.2311], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-431.3121], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.5022], device='cuda:0')\n",
            "logits: tensor([34.9240], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2195], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2729], device='cuda:0')\n",
            " 97% 6056/6237 [1:45:23<02:34,  1.17it/s]losses: tensor([0.0676], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-934.2884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.7702], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-946.2256], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.1106], device='cuda:0')\n",
            "logits: tensor([26.5968], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1937], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4660], device='cuda:0')\n",
            " 97% 6057/6237 [1:45:25<02:59,  1.01it/s]losses: tensor([0.0808], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-156.0070], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-388.5905], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-164.5950], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-372.4249], device='cuda:0')\n",
            "logits: tensor([24.7536], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8588], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6166], device='cuda:0')\n",
            " 97% 6058/6237 [1:45:26<03:22,  1.13s/it]losses: tensor([0.0943], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-632.9636], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.1588], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-635.1089], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.1643], device='cuda:0')\n",
            "logits: tensor([23.1399], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2145], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0995], device='cuda:0')\n",
            " 97% 6059/6237 [1:45:27<03:09,  1.07s/it]losses: tensor([0.2603], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-728.1007], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-358.7440], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-726.3629], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-344.8767], device='cuda:0')\n",
            "logits: tensor([12.1294], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1738], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3867], device='cuda:0')\n",
            "{'loss': 0.0986, 'learning_rate': 1.6924995546053805e-08, 'rewards/real': 0.6361860036849976, 'rewards/generated': -1.8413234949111938, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4775097370147705, 'logps/generated': -416.1224060058594, 'logps/real': -585.4778442382812, 'logits/generated': -1.749861478805542, 'logits/real': -1.68271803855896, 'epoch': 2.91}\n",
            " 97% 6060/6237 [1:45:28<03:12,  1.09s/it]losses: tensor([0.1130], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-750.1300], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.6155], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-759.8363], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.0905], device='cuda:0')\n",
            "logits: tensor([21.2314], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9706], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1525], device='cuda:0')\n",
            " 97% 6061/6237 [1:45:29<02:56,  1.00s/it]losses: tensor([0.0150], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-581.0321], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.3217], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-596.2371], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.6061], device='cuda:0')\n",
            "logits: tensor([41.9205], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5205], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6716], device='cuda:0')\n",
            " 97% 6062/6237 [1:45:30<02:55,  1.00s/it]losses: tensor([0.0677], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-486.9727], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.3272], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-484.8311], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-379.5930], device='cuda:0')\n",
            "logits: tensor([26.5926], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2142], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8734], device='cuda:0')\n",
            " 97% 6063/6237 [1:45:31<02:34,  1.13it/s]losses: tensor([0.0274], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-480.3841], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.0437], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-494.1725], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.9790], device='cuda:0')\n",
            "logits: tensor([35.8531], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3788], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2065], device='cuda:0')\n",
            " 97% 6064/6237 [1:45:31<02:14,  1.29it/s]losses: tensor([0.0999], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-373.4544], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.9880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-384.5764], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-453.5758], device='cuda:0')\n",
            "logits: tensor([22.5342], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1122], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1412], device='cuda:0')\n",
            " 97% 6065/6237 [1:45:32<02:05,  1.37it/s]losses: tensor([0.0748], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-97.4283], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-370.7112], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-105.0892], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-352.8181], device='cuda:0')\n",
            "logits: tensor([25.5540], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7661], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7893], device='cuda:0')\n",
            " 97% 6066/6237 [1:45:32<01:53,  1.51it/s]losses: tensor([0.0621], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-595.9028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.1046], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-601.1219], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.8539], device='cuda:0')\n",
            "logits: tensor([27.4698], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5219], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2251], device='cuda:0')\n",
            " 97% 6067/6237 [1:45:33<01:58,  1.44it/s]losses: tensor([0.3583], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-649.6613], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-267.0513], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-661.0421], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-270.0120], device='cuda:0')\n",
            "logits: tensor([8.4201], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1381], device='cuda:0')\n",
            "generated_rewards: tensor([0.2961], device='cuda:0')\n",
            " 97% 6068/6237 [1:45:35<02:44,  1.03it/s]losses: tensor([0.0423], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1123.6743], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-389.9175], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1132.7781], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.6081], device='cuda:0')\n",
            "logits: tensor([31.4132], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9104], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2309], device='cuda:0')\n",
            " 97% 6069/6237 [1:45:36<03:00,  1.08s/it]losses: tensor([0.0209], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-316.1065], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.1017], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-319.7365], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.1771], device='cuda:0')\n",
            "logits: tensor([38.5546], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3630], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4925], device='cuda:0')\n",
            "{'loss': 0.0881, 'learning_rate': 1.6034206306787812e-08, 'rewards/real': 0.8467483520507812, 'rewards/generated': -1.9486875534057617, 'rewards/accuracies': 1.0, 'rewards/margins': 2.795435667037964, 'logps/generated': -403.4182434082031, 'logps/real': -545.474609375, 'logits/generated': -1.511315107345581, 'logits/real': -1.5945886373519897, 'epoch': 2.92}\n",
            " 97% 6070/6237 [1:45:37<02:42,  1.03it/s]losses: tensor([0.0990], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-448.6954], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-295.7319], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-457.8541], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-282.2584], device='cuda:0')\n",
            "logits: tensor([22.6322], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9159], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3473], device='cuda:0')\n",
            " 97% 6071/6237 [1:45:38<02:42,  1.02it/s]losses: tensor([0.1393], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-338.6345], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.8208], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-345.8539], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.0304], device='cuda:0')\n",
            "logits: tensor([19.0098], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7219], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1790], device='cuda:0')\n",
            " 97% 6072/6237 [1:45:38<02:18,  1.19it/s]losses: tensor([0.0772], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-466.0993], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-346.7827], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-482.3815], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-337.8385], device='cuda:0')\n",
            "logits: tensor([25.2263], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6282], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8944], device='cuda:0')\n",
            " 97% 6073/6237 [1:45:39<02:19,  1.18it/s]losses: tensor([0.0924], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-803.5471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.2551], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-807.3765], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.7286], device='cuda:0')\n",
            "logits: tensor([23.3560], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3829], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9526], device='cuda:0')\n",
            " 97% 6074/6237 [1:45:40<02:32,  1.07it/s]losses: tensor([0.0698], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-576.1493], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.9310], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-582.8684], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.3847], device='cuda:0')\n",
            "logits: tensor([26.2654], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6719], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9546], device='cuda:0')\n",
            " 97% 6075/6237 [1:45:41<02:26,  1.11it/s]losses: tensor([0.0143], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-113.6456], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-494.0164], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-123.7729], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-461.7744], device='cuda:0')\n",
            "logits: tensor([42.3694], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0127], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2242], device='cuda:0')\n",
            " 97% 6076/6237 [1:45:42<02:17,  1.17it/s]losses: tensor([0.0571], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-285.3719], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-367.5602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-303.6883], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-357.5345], device='cuda:0')\n",
            "logits: tensor([28.3421], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8316], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0026], device='cuda:0')\n",
            " 97% 6077/6237 [1:45:42<02:00,  1.33it/s]losses: tensor([0.0516], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-544.9242], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-511.3826], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-549.8571], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-486.9398], device='cuda:0')\n",
            "logits: tensor([29.3756], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4933], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4443], device='cuda:0')\n",
            " 97% 6078/6237 [1:45:43<02:16,  1.16it/s]losses: tensor([0.0383], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1009.0096], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-446.5902], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1025.6555], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.8172], device='cuda:0')\n",
            "logits: tensor([32.4188], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6646], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5773], device='cuda:0')\n",
            " 97% 6079/6237 [1:45:44<02:22,  1.11it/s]losses: tensor([0.2439], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-668.9839], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.9073], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-668.0665], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.1241], device='cuda:0')\n",
            "logits: tensor([12.8657], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0917], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3783], device='cuda:0')\n",
            "{'loss': 0.0883, 'learning_rate': 1.5143417067521823e-08, 'rewards/real': 0.923139750957489, 'rewards/generated': -1.695474624633789, 'rewards/accuracies': 1.0, 'rewards/margins': 2.618614435195923, 'logps/generated': -413.0977478027344, 'logps/real': -525.506103515625, 'logits/generated': -1.7828872203826904, 'logits/real': -1.8531038761138916, 'epoch': 2.92}\n",
            " 97% 6080/6237 [1:45:45<02:20,  1.12it/s]losses: tensor([0.0485], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-486.5375], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.7689], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-498.1541], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.3611], device='cuda:0')\n",
            "logits: tensor([30.0244], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1617], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8408], device='cuda:0')\n",
            " 97% 6081/6237 [1:45:46<02:01,  1.28it/s]losses: tensor([0.0583], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1374.1445], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.2704], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1382.0870], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.0765], device='cuda:0')\n",
            "logits: tensor([28.1364], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7943], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0194], device='cuda:0')\n",
            " 98% 6082/6237 [1:45:47<02:18,  1.12it/s]losses: tensor([0.0672], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-156.4534], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.0760], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-166.0862], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.0422], device='cuda:0')\n",
            "logits: tensor([26.6666], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9633], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7034], device='cuda:0')\n",
            " 98% 6083/6237 [1:45:48<02:29,  1.03it/s]losses: tensor([0.2159], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-747.5559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.0580], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-748.2508], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-428.5208], device='cuda:0')\n",
            "logits: tensor([14.2320], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0695], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3537], device='cuda:0')\n",
            " 98% 6084/6237 [1:45:49<02:40,  1.05s/it]losses: tensor([0.0687], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-993.3501], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.1718], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1004.8292], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.2230], device='cuda:0')\n",
            "logits: tensor([26.4280], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1479], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4949], device='cuda:0')\n",
            " 98% 6085/6237 [1:45:51<02:54,  1.15s/it]losses: tensor([0.4380], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-752.5941], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-370.9181], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-754.8733], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.2105], device='cuda:0')\n",
            "logits: tensor([5.9868], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2279], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3708], device='cuda:0')\n",
            " 98% 6086/6237 [1:45:52<02:59,  1.19s/it]losses: tensor([0.1985], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-539.4893], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-359.6837], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-538.2997], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-343.3308], device='cuda:0')\n",
            "logits: tensor([15.1633], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1190], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6353], device='cuda:0')\n",
            " 98% 6087/6237 [1:45:53<02:41,  1.08s/it]losses: tensor([0.4753], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-207.6654], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-280.8444], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-213.5493], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-281.7614], device='cuda:0')\n",
            "logits: tensor([4.9670], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5884], device='cuda:0')\n",
            "generated_rewards: tensor([0.0917], device='cuda:0')\n",
            " 98% 6088/6237 [1:45:53<02:19,  1.07it/s]losses: tensor([0.0385], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-310.1270], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.5522], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-316.7425], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.7834], device='cuda:0')\n",
            "logits: tensor([32.3843], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6616], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5769], device='cuda:0')\n",
            " 98% 6089/6237 [1:45:54<02:19,  1.06it/s]losses: tensor([0.1119], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-151.5672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-375.1819], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-164.3570], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.6334], device='cuda:0')\n",
            "logits: tensor([21.3384], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2790], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8549], device='cuda:0')\n",
            "{'loss': 0.1721, 'learning_rate': 1.4252627828255834e-08, 'rewards/real': 0.6774490475654602, 'rewards/generated': -1.3758227825164795, 'rewards/accuracies': 1.0, 'rewards/margins': 2.053271770477295, 'logps/generated': -399.5525207519531, 'logps/real': -571.9484252929688, 'logits/generated': -1.5869766473770142, 'logits/real': -1.417119026184082, 'epoch': 2.93}\n",
            " 98% 6090/6237 [1:45:55<02:17,  1.07it/s]losses: tensor([0.0993], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-499.8098], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-295.7775], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-510.5633], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-283.9323], device='cuda:0')\n",
            "logits: tensor([22.5987], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0753], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1845], device='cuda:0')\n",
            " 98% 6091/6237 [1:45:56<02:21,  1.04it/s]losses: tensor([0.0549], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-941.7922], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.8914], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-952.9562], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.3166], device='cuda:0')\n",
            "logits: tensor([28.7387], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1164], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7575], device='cuda:0')\n",
            " 98% 6092/6237 [1:45:57<02:23,  1.01it/s]losses: tensor([0.0881], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-931.4991], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.5720], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-943.0514], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.2786], device='cuda:0')\n",
            "logits: tensor([23.8456], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1552], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2293], device='cuda:0')\n",
            " 98% 6093/6237 [1:45:58<02:11,  1.09it/s]losses: tensor([0.3607], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-483.5607], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.8403], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-479.2977], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.2375], device='cuda:0')\n",
            "logits: tensor([8.3398], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4263], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2603], device='cuda:0')\n",
            " 98% 6094/6237 [1:45:59<01:57,  1.22it/s]losses: tensor([0.1300], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-538.2185], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.2949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-546.1514], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-335.4810], device='cuda:0')\n",
            "logits: tensor([19.7468], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7933], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1814], device='cuda:0')\n",
            " 98% 6095/6237 [1:46:00<02:09,  1.10it/s]losses: tensor([0.2867], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-301.7195], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-315.6135], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-310.5396], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-313.4089], device='cuda:0')\n",
            "logits: tensor([11.0247], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8820], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2205], device='cuda:0')\n",
            " 98% 6096/6237 [1:46:01<02:06,  1.11it/s]losses: tensor([0.0431], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-826.0804], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-474.5995], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-832.3228], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-449.6255], device='cuda:0')\n",
            "logits: tensor([31.2163], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6242], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4974], device='cuda:0')\n",
            " 98% 6097/6237 [1:46:02<02:17,  1.02it/s]losses: tensor([0.1123], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-748.4251], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.1337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-757.5982], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.0089], device='cuda:0')\n",
            "logits: tensor([21.2979], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9173], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2125], device='cuda:0')\n",
            " 98% 6098/6237 [1:46:03<02:21,  1.02s/it]losses: tensor([0.0392], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-105.5285], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-422.6547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-115.6199], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.5493], device='cuda:0')\n",
            "logits: tensor([32.1968], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0091], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2105], device='cuda:0')\n",
            " 98% 6099/6237 [1:46:04<02:14,  1.03it/s]losses: tensor([0.1050], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-233.1073], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.3651], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-237.1444], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.3914], device='cuda:0')\n",
            "logits: tensor([22.0108], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4037], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7974], device='cuda:0')\n",
            "{'loss': 0.1319, 'learning_rate': 1.3361838588989845e-08, 'rewards/real': 0.7550349235534668, 'rewards/generated': -1.4551265239715576, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2101616859436035, 'logps/generated': -398.8742980957031, 'logps/real': -560.97412109375, 'logits/generated': -1.7972711324691772, 'logits/real': -1.7249906063079834, 'epoch': 2.93}\n",
            " 98% 6100/6237 [1:46:04<01:54,  1.19it/s]losses: tensor([0.0727], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-518.0692], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.9174], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-522.0455], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.0500], device='cuda:0')\n",
            "logits: tensor([25.8437], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3976], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1867], device='cuda:0')\n",
            " 98% 6101/6237 [1:46:05<01:48,  1.25it/s]losses: tensor([0.1179], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-766.6458], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-333.6458], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-769.7435], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-315.9612], device='cuda:0')\n",
            "logits: tensor([20.7823], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3098], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7685], device='cuda:0')\n",
            " 98% 6102/6237 [1:46:06<02:02,  1.10it/s]losses: tensor([0.0898], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-280.6547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.8247], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-283.4301], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-375.9547], device='cuda:0')\n",
            "logits: tensor([23.6455], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2775], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0870], device='cuda:0')\n",
            " 98% 6103/6237 [1:46:07<02:15,  1.01s/it]losses: tensor([0.0356], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-416.1932], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.2906], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-426.2917], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.2141], device='cuda:0')\n",
            "logits: tensor([33.1750], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0099], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3076], device='cuda:0')\n",
            " 98% 6104/6237 [1:46:08<02:01,  1.10it/s]losses: tensor([0.1323], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-447.1808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.8459], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-448.9453], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.0558], device='cuda:0')\n",
            "logits: tensor([19.5545], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1764], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7790], device='cuda:0')\n",
            " 98% 6105/6237 [1:46:09<01:51,  1.19it/s]losses: tensor([0.0456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-312.1111], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.2367], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-321.7117], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.1948], device='cuda:0')\n",
            "logits: tensor([30.6424], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9601], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1042], device='cuda:0')\n",
            " 98% 6106/6237 [1:46:09<01:37,  1.35it/s]losses: tensor([0.1537], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-648.2497], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.8829], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-652.2320], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.9180], device='cuda:0')\n",
            "logits: tensor([17.9472], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3982], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3965], device='cuda:0')\n",
            " 98% 6107/6237 [1:46:10<01:52,  1.15it/s]losses: tensor([0.1564], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-209.3348], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-356.9417], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-221.5385], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-351.3835], device='cuda:0')\n",
            "logits: tensor([17.7619], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2204], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5558], device='cuda:0')\n",
            " 98% 6108/6237 [1:46:12<02:11,  1.02s/it]losses: tensor([0.1028], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-716.5513], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-325.1436], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-727.6548], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-314.0112], device='cuda:0')\n",
            "logits: tensor([22.2360], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1104], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1132], device='cuda:0')\n",
            " 98% 6109/6237 [1:46:13<02:16,  1.07s/it]losses: tensor([0.2163], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-335.8517], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-335.7249], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-341.7892], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-327.4536], device='cuda:0')\n",
            "logits: tensor([14.2087], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5938], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8271], device='cuda:0')\n",
            "{'loss': 0.1123, 'learning_rate': 1.2471049349723855e-08, 'rewards/real': 0.6453996896743774, 'rewards/generated': -1.6125726699829102, 'rewards/accuracies': 1.0, 'rewards/margins': 2.257972240447998, 'logps/generated': -387.84539794921875, 'logps/real': -465.084228515625, 'logits/generated': -1.6789491176605225, 'logits/real': -1.6465644836425781, 'epoch': 2.94}\n",
            " 98% 6110/6237 [1:46:14<02:10,  1.03s/it]losses: tensor([0.0522], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-250.4342], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.0059], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.4276], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.7385], device='cuda:0')\n",
            "logits: tensor([29.2609], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7993], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1267], device='cuda:0')\n",
            " 98% 6111/6237 [1:46:15<02:07,  1.01s/it]losses: tensor([0.0361], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-88.5858], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.4656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-98.5443], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.3788], device='cuda:0')\n",
            "logits: tensor([33.0453], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9958], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3087], device='cuda:0')\n",
            " 98% 6112/6237 [1:46:16<02:00,  1.03it/s]losses: tensor([0.1698], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-513.7375], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-357.3057], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-522.6293], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.3272], device='cuda:0')\n",
            "logits: tensor([16.8702], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8892], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7978], device='cuda:0')\n",
            " 98% 6113/6237 [1:46:16<01:43,  1.19it/s]losses: tensor([0.0442], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-237.7402], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.3525], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-242.3640], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.0180], device='cuda:0')\n",
            "logits: tensor([30.9583], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4624], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6335], device='cuda:0')\n",
            " 98% 6114/6237 [1:46:18<02:14,  1.09s/it]losses: tensor([0.1527], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-512.4753], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-383.9148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-520.0915], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.5089], device='cuda:0')\n",
            "logits: tensor([18.0221], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7616], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0406], device='cuda:0')\n",
            " 98% 6115/6237 [1:46:19<02:09,  1.07s/it]losses: tensor([0.0119], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-162.5949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.7041], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.1527], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.9977], device='cuda:0')\n",
            "logits: tensor([44.2642], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3558], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0706], device='cuda:0')\n",
            " 98% 6116/6237 [1:46:20<01:58,  1.02it/s]losses: tensor([0.1750], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-924.0689], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.3388], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-927.1714], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.8976], device='cuda:0')\n",
            "logits: tensor([16.5437], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3102], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3441], device='cuda:0')\n",
            " 98% 6117/6237 [1:46:22<02:31,  1.26s/it]losses: tensor([0.0971], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-452.7139], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.7434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-462.4420], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-450.6416], device='cuda:0')\n",
            "logits: tensor([22.8300], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9728], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3102], device='cuda:0')\n",
            " 98% 6118/6237 [1:46:23<02:15,  1.13s/it]losses: tensor([0.2695], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1220.7368], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-451.1998], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1219.0925], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.8202], device='cuda:0')\n",
            "logits: tensor([11.7353], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1644], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3380], device='cuda:0')\n",
            " 98% 6119/6237 [1:46:24<02:30,  1.28s/it]losses: tensor([0.0802], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-826.5880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.8293], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-835.8889], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-381.3037], device='cuda:0')\n",
            "logits: tensor([24.8264], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9301], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5526], device='cuda:0')\n",
            "{'loss': 0.1089, 'learning_rate': 1.1580260110457864e-08, 'rewards/real': 0.7312864065170288, 'rewards/generated': -1.7522780895233154, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4835643768310547, 'logps/generated': -418.9859924316406, 'logps/real': -518.9675903320312, 'logits/generated': -1.6013329029083252, 'logits/real': -1.5889103412628174, 'epoch': 2.94}\n",
            " 98% 6120/6237 [1:46:25<02:20,  1.20s/it]losses: tensor([0.1566], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-334.9618], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.6135], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-344.4339], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.3379], device='cuda:0')\n",
            "logits: tensor([17.7477], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9472], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8276], device='cuda:0')\n",
            " 98% 6121/6237 [1:46:26<01:57,  1.01s/it]losses: tensor([0.1396], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-269.9995], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.4358], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-284.3934], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.8443], device='cuda:0')\n",
            "logits: tensor([18.9854], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4394], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4591], device='cuda:0')\n",
            " 98% 6122/6237 [1:46:27<01:49,  1.05it/s]losses: tensor([0.0309], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-163.9393], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-366.1225], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-171.5365], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-339.1102], device='cuda:0')\n",
            "logits: tensor([34.6095], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7597], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7012], device='cuda:0')\n",
            " 98% 6123/6237 [1:46:28<02:13,  1.17s/it]losses: tensor([0.1096], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-642.4898], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.0497], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-658.9766], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.9830], device='cuda:0')\n",
            "logits: tensor([21.5535], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6487], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5067], device='cuda:0')\n",
            " 98% 6124/6237 [1:46:29<02:02,  1.08s/it]losses: tensor([0.0742], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-619.8602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-345.5251], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-630.9472], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-330.9712], device='cuda:0')\n",
            "logits: tensor([25.6409], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1087], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4554], device='cuda:0')\n",
            " 98% 6125/6237 [1:46:30<02:03,  1.10s/it]losses: tensor([0.0360], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-296.7326], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.9346], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-309.9000], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.0500], device='cuda:0')\n",
            "logits: tensor([33.0520], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3167], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9885], device='cuda:0')\n",
            " 98% 6126/6237 [1:46:31<01:53,  1.02s/it]losses: tensor([0.1299], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1244.4558], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-469.8706], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1248.1895], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-453.8474], device='cuda:0')\n",
            "logits: tensor([19.7569], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3734], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6023], device='cuda:0')\n",
            " 98% 6127/6237 [1:46:33<02:05,  1.14s/it]losses: tensor([0.1450], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-289.1435], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-311.3579], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-301.4592], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-305.0945], device='cuda:0')\n",
            "logits: tensor([18.5790], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2316], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6263], device='cuda:0')\n",
            " 98% 6128/6237 [1:46:34<02:22,  1.30s/it]losses: tensor([0.0752], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-459.7318], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-557.7940], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-471.6223], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-544.1890], device='cuda:0')\n",
            "logits: tensor([25.4955], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1890], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3605], device='cuda:0')\n",
            " 98% 6129/6237 [1:46:36<02:28,  1.37s/it]losses: tensor([0.1851], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-148.6143], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.3010], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-158.9103], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.6708], device='cuda:0')\n",
            "logits: tensor([15.9261], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0296], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5630], device='cuda:0')\n",
            "{'loss': 0.1082, 'learning_rate': 1.0689470871191877e-08, 'rewards/real': 1.1044025421142578, 'rewards/generated': -1.2090638875961304, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3134665489196777, 'logps/generated': -405.80047607421875, 'logps/real': -446.99285888671875, 'logits/generated': -1.5995447635650635, 'logits/real': -1.5757566690444946, 'epoch': 2.95}\n",
            " 98% 6130/6237 [1:46:37<02:20,  1.31s/it]losses: tensor([0.0742], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-711.9106], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-460.5028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-719.4111], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.3700], device='cuda:0')\n",
            "logits: tensor([25.6334], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7501], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8133], device='cuda:0')\n",
            " 98% 6131/6237 [1:46:38<02:07,  1.20s/it]losses: tensor([0.0955], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-633.2245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.6148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-645.8181], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.2027], device='cuda:0')\n",
            "logits: tensor([23.0057], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2594], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0412], device='cuda:0')\n",
            " 98% 6132/6237 [1:46:38<01:47,  1.03s/it]losses: tensor([0.0882], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-581.4234], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.3324], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-590.4711], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-484.5417], device='cuda:0')\n",
            "logits: tensor([23.8383], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9048], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4791], device='cuda:0')\n",
            " 98% 6133/6237 [1:46:40<01:49,  1.06s/it]losses: tensor([0.0850], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1402.7732], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.4675], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1414.0386], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.5053], device='cuda:0')\n",
            "logits: tensor([24.2276], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1265], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2962], device='cuda:0')\n",
            " 98% 6134/6237 [1:46:41<02:06,  1.23s/it]losses: tensor([0.0607], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-148.9167], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-358.5054], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-164.9465], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-346.8188], device='cuda:0')\n",
            "logits: tensor([27.7163], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6030], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1687], device='cuda:0')\n",
            " 98% 6135/6237 [1:46:42<01:43,  1.01s/it]losses: tensor([0.0914], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-583.8568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.6331], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-604.2340], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.5508], device='cuda:0')\n",
            "logits: tensor([23.4594], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0377], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3082], device='cuda:0')\n",
            " 98% 6136/6237 [1:46:42<01:34,  1.07it/s]losses: tensor([0.0266], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-410.4529], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.2441], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-418.5605], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.1981], device='cuda:0')\n",
            "logits: tensor([36.1537], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8108], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8046], device='cuda:0')\n",
            " 98% 6137/6237 [1:46:43<01:20,  1.24it/s]losses: tensor([0.0274], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-133.4228], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.3240], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-147.1477], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-481.2323], device='cuda:0')\n",
            "logits: tensor([35.8165], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3725], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2092], device='cuda:0')\n",
            " 98% 6138/6237 [1:46:45<01:43,  1.05s/it]losses: tensor([0.2258], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-540.1829], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.2801], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-545.5400], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-338.9040], device='cuda:0')\n",
            "logits: tensor([13.7333], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5357], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8376], device='cuda:0')\n",
            " 98% 6139/6237 [1:46:45<01:35,  1.03it/s]losses: tensor([0.0545], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-142.1068], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.0514], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-150.5113], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.6266], device='cuda:0')\n",
            "logits: tensor([28.8293], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8404], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0425], device='cuda:0')\n",
            "{'loss': 0.0829, 'learning_rate': 9.798681631925886e-09, 'rewards/real': 1.1240837574005127, 'rewards/generated': -1.5000519752502441, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6241354942321777, 'logps/generated': -419.49560546875, 'logps/real': -528.8270263671875, 'logits/generated': -1.711412787437439, 'logits/real': -1.5173267126083374, 'epoch': 2.95}\n",
            " 98% 6140/6237 [1:46:46<01:24,  1.15it/s]losses: tensor([0.2529], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1033.9313], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-378.8130], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1034.1558], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.5809], device='cuda:0')\n",
            "logits: tensor([12.4566], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0224], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2232], device='cuda:0')\n",
            " 98% 6141/6237 [1:46:47<01:37,  1.02s/it]losses: tensor([0.4220], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-435.4627], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-253.4915], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-443.6693], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-255.2546], device='cuda:0')\n",
            "logits: tensor([6.4436], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8207], device='cuda:0')\n",
            "generated_rewards: tensor([0.1763], device='cuda:0')\n",
            " 98% 6142/6237 [1:46:49<01:49,  1.16s/it]losses: tensor([0.1828], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-104.2402], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-332.9093], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-113.3010], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-325.9043], device='cuda:0')\n",
            "logits: tensor([16.0658], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9061], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7005], device='cuda:0')\n",
            " 98% 6143/6237 [1:46:50<01:54,  1.22s/it]losses: tensor([0.0893], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-837.1384], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.5139], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-840.6954], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.3625], device='cuda:0')\n",
            "logits: tensor([23.7083], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3557], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0151], device='cuda:0')\n",
            " 99% 6144/6237 [1:46:51<01:51,  1.20s/it]losses: tensor([0.0349], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-123.7052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.0639], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-140.5566], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.5474], device='cuda:0')\n",
            "logits: tensor([33.3679], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6851], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6517], device='cuda:0')\n",
            " 99% 6145/6237 [1:46:53<01:56,  1.26s/it]losses: tensor([0.1580], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-412.5656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.6483], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-416.6424], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.0759], device='cuda:0')\n",
            "logits: tensor([17.6493], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4077], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3572], device='cuda:0')\n",
            " 99% 6146/6237 [1:46:53<01:34,  1.04s/it]losses: tensor([0.1355], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1186.0293], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-459.5400], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1186.2097], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.4144], device='cuda:0')\n",
            "logits: tensor([19.3060], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0180], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9126], device='cuda:0')\n",
            " 99% 6147/6237 [1:46:55<01:40,  1.11s/it]losses: tensor([0.1046], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-384.0059], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.8682], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-389.5713], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-433.3858], device='cuda:0')\n",
            "logits: tensor([22.0477], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5565], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6482], device='cuda:0')\n",
            " 99% 6148/6237 [1:46:56<01:49,  1.23s/it]losses: tensor([0.0252], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-162.0294], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-435.1573], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-179.6195], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-416.0807], device='cuda:0')\n",
            "logits: tensor([36.6667], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7590], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9077], device='cuda:0')\n",
            " 99% 6149/6237 [1:46:57<01:36,  1.09s/it]losses: tensor([0.0082], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-341.6773], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.5828], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-354.6703], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.5846], device='cuda:0')\n",
            "logits: tensor([47.9912], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2993], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4998], device='cuda:0')\n",
            "{'loss': 0.1413, 'learning_rate': 8.907892392659897e-09, 'rewards/real': 0.7830601334571838, 'rewards/generated': -1.5739703178405762, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3570306301116943, 'logps/generated': -404.25885009765625, 'logps/real': -502.0785217285156, 'logits/generated': -1.8090463876724243, 'logits/real': -1.7564804553985596, 'epoch': 2.96}\n",
            " 99% 6150/6237 [1:46:57<01:19,  1.09it/s]losses: tensor([0.0340], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-256.6933], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.2363], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-266.3871], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.2727], device='cuda:0')\n",
            "logits: tensor([33.6574], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9694], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3964], device='cuda:0')\n",
            " 99% 6151/6237 [1:46:58<01:12,  1.18it/s]losses: tensor([0.0322], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-319.1140], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.4564], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-327.2805], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.4328], device='cuda:0')\n",
            "logits: tensor([34.1901], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8167], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6024], device='cuda:0')\n",
            " 99% 6152/6237 [1:46:59<01:03,  1.34it/s]losses: tensor([0.0741], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-193.6499], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-573.3401], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-204.0872], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-558.1254], device='cuda:0')\n",
            "logits: tensor([25.6521], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0437], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5215], device='cuda:0')\n",
            " 99% 6153/6237 [1:47:00<01:22,  1.02it/s]losses: tensor([0.0368], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-90.0072], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.3768], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-107.7855], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-381.3035], device='cuda:0')\n",
            "logits: tensor([32.8517], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7778], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5073], device='cuda:0')\n",
            " 99% 6154/6237 [1:47:01<01:12,  1.15it/s]losses: tensor([0.1042], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-178.7401], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-494.2908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-190.6171], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-484.0746], device='cuda:0')\n",
            "logits: tensor([22.0932], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1877], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0216], device='cuda:0')\n",
            " 99% 6155/6237 [1:47:02<01:27,  1.07s/it]losses: tensor([0.0945], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-304.7015], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.9400], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-309.9613], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.0803], device='cuda:0')\n",
            "logits: tensor([23.1194], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5260], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7860], device='cuda:0')\n",
            " 99% 6156/6237 [1:47:03<01:15,  1.07it/s]losses: tensor([0.1906], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1090.4661], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.0233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1086.5679], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.5194], device='cuda:0')\n",
            "logits: tensor([15.6057], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3898], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9504], device='cuda:0')\n",
            " 99% 6157/6237 [1:47:04<01:20,  1.01s/it]losses: tensor([0.0241], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-282.1628], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.6935], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-299.8543], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.2576], device='cuda:0')\n",
            "logits: tensor([37.1274], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7691], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9436], device='cuda:0')\n",
            " 99% 6158/6237 [1:47:06<01:32,  1.17s/it]losses: tensor([0.1528], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-119.9963], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.1279], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-130.4172], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-326.5367], device='cuda:0')\n",
            "logits: tensor([18.0121], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0421], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7591], device='cuda:0')\n",
            " 99% 6159/6237 [1:47:07<01:30,  1.17s/it]losses: tensor([0.1051], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-383.1737], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.4861], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-388.2985], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-379.6166], device='cuda:0')\n",
            "logits: tensor([21.9942], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5125], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6869], device='cuda:0')\n",
            "{'loss': 0.0848, 'learning_rate': 8.017103153393906e-09, 'rewards/real': 0.9255176782608032, 'rewards/generated': -1.7175159454345703, 'rewards/accuracies': 1.0, 'rewards/margins': 2.643033504486084, 'logps/generated': -436.3970642089844, 'logps/real': -321.8704833984375, 'logits/generated': -1.4486663341522217, 'logits/real': -1.5451602935791016, 'epoch': 2.96}\n",
            " 99% 6160/6237 [1:47:07<01:14,  1.03it/s]losses: tensor([0.0501], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-318.4744], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.0966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-331.2006], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.1408], device='cuda:0')\n",
            "logits: tensor([29.6819], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2726], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6956], device='cuda:0')\n",
            " 99% 6161/6237 [1:47:08<01:05,  1.15it/s]losses: tensor([0.1505], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1126.2183], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.8088], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1130.4402], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-416.8583], device='cuda:0')\n",
            "logits: tensor([18.1724], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4222], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3950], device='cuda:0')\n",
            " 99% 6162/6237 [1:47:09<01:14,  1.01it/s]losses: tensor([0.0523], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-612.3875], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.6381], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-629.2134], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.2240], device='cuda:0')\n",
            "logits: tensor([29.2400], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6826], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2414], device='cuda:0')\n",
            " 99% 6163/6237 [1:47:10<01:07,  1.10it/s]losses: tensor([0.1200], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-615.8401], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.3151], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-624.4778], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.3542], device='cuda:0')\n",
            "logits: tensor([20.5986], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8638], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1961], device='cuda:0')\n",
            " 99% 6164/6237 [1:47:11<01:08,  1.07it/s]losses: tensor([0.0474], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-311.9548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.1163], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-319.2050], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.1202], device='cuda:0')\n",
            "logits: tensor([30.2462], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7250], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2996], device='cuda:0')\n",
            " 99% 6165/6237 [1:47:11<00:58,  1.23it/s]losses: tensor([0.2222], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-533.1857], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-367.0875], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-529.5391], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.5316], device='cuda:0')\n",
            "logits: tensor([13.9093], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3647], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7556], device='cuda:0')\n",
            " 99% 6166/6237 [1:47:12<01:02,  1.14it/s]losses: tensor([0.6238], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-364.2494], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-292.2712], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-372.4488], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-299.0325], device='cuda:0')\n",
            "logits: tensor([1.4381], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8199], device='cuda:0')\n",
            "generated_rewards: tensor([0.6761], device='cuda:0')\n",
            " 99% 6167/6237 [1:47:13<01:04,  1.08it/s]losses: tensor([0.0445], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-625.4575], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.7099], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-634.0306], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.3932], device='cuda:0')\n",
            "logits: tensor([30.8898], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8573], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2317], device='cuda:0')\n",
            " 99% 6168/6237 [1:47:14<01:02,  1.11it/s]losses: tensor([0.2111], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-122.4525], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-296.3887], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-136.4985], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-295.9520], device='cuda:0')\n",
            "logits: tensor([14.4827], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4046], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0437], device='cuda:0')\n",
            " 99% 6169/6237 [1:47:16<01:19,  1.17s/it]losses: tensor([0.0703], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-258.3027], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.7763], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-266.7115], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.9873], device='cuda:0')\n",
            "logits: tensor([26.1978], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8409], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7789], device='cuda:0')\n",
            "{'loss': 0.1592, 'learning_rate': 7.126313914127917e-09, 'rewards/real': 0.8524262309074402, 'rewards/generated': -1.2961437702178955, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1485700607299805, 'logps/generated': -390.22088623046875, 'logps/real': -488.852294921875, 'logits/generated': -1.3907430171966553, 'logits/real': -1.3007341623306274, 'epoch': 2.97}\n",
            " 99% 6170/6237 [1:47:17<01:16,  1.15s/it]losses: tensor([0.3861], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-250.0286], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-211.7045], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-261.9077], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-216.0586], device='cuda:0')\n",
            "logits: tensor([7.5249], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1879], device='cuda:0')\n",
            "generated_rewards: tensor([0.4354], device='cuda:0')\n",
            " 99% 6171/6237 [1:47:18<01:07,  1.03s/it]losses: tensor([0.0269], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-127.5968], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.2902], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-143.1102], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.7902], device='cuda:0')\n",
            "logits: tensor([36.0135], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5513], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0500], device='cuda:0')\n",
            " 99% 6172/6237 [1:47:19<00:58,  1.11it/s]losses: tensor([0.0460], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-145.2956], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.9437], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-156.3673], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.4573], device='cuda:0')\n",
            "logits: tensor([30.5581], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1072], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9486], device='cuda:0')\n",
            " 99% 6173/6237 [1:47:20<00:59,  1.07it/s]losses: tensor([0.2141], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-276.7492], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.5325], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-289.0574], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-332.5192], device='cuda:0')\n",
            "logits: tensor([14.3215], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2308], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2013], device='cuda:0')\n",
            " 99% 6174/6237 [1:47:20<00:56,  1.12it/s]losses: tensor([0.0217], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-303.0082], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.7767], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-311.9003], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.4539], device='cuda:0')\n",
            "logits: tensor([38.2149], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8892], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9323], device='cuda:0')\n",
            " 99% 6175/6237 [1:47:21<00:54,  1.14it/s]losses: tensor([0.3268], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-644.1198], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-512.8453], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-635.9994], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-495.2196], device='cuda:0')\n",
            "logits: tensor([9.5053], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8120], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7626], device='cuda:0')\n",
            " 99% 6176/6237 [1:47:23<01:09,  1.14s/it]losses: tensor([0.0178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-168.7388], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-394.9747], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.8419], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-374.9059], device='cuda:0')\n",
            "logits: tensor([40.1720], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0103], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0069], device='cuda:0')\n",
            " 99% 6177/6237 [1:47:25<01:17,  1.29s/it]losses: tensor([0.1072], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-824.5063], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.8696], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-838.9449], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.5137], device='cuda:0')\n",
            "logits: tensor([21.7945], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4439], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7356], device='cuda:0')\n",
            " 99% 6178/6237 [1:47:26<01:14,  1.26s/it]losses: tensor([0.0488], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-316.7382], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-538.2282], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-320.1203], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-511.6653], device='cuda:0')\n",
            "logits: tensor([29.9450], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3382], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6563], device='cuda:0')\n",
            " 99% 6179/6237 [1:47:27<01:17,  1.34s/it]losses: tensor([0.0619], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-971.7322], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.0370], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-981.9922], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.7775], device='cuda:0')\n",
            "logits: tensor([27.5194], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0260], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7259], device='cuda:0')\n",
            "{'loss': 0.1257, 'learning_rate': 6.235524674861928e-09, 'rewards/real': 0.9972785711288452, 'rewards/generated': -1.5584129095077515, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5556914806365967, 'logps/generated': -418.8202209472656, 'logps/real': -402.85137939453125, 'logits/generated': -1.3949553966522217, 'logits/real': -1.5381146669387817, 'epoch': 2.97}\n",
            " 99% 6180/6237 [1:47:28<01:12,  1.26s/it]losses: tensor([0.1754], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-364.7472], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-301.5698], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-375.0045], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-295.3075], device='cuda:0')\n",
            "logits: tensor([16.5195], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0257], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6262], device='cuda:0')\n",
            " 99% 6181/6237 [1:47:29<01:00,  1.07s/it]losses: tensor([0.1647], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-784.5987], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.1293], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-790.0759], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-375.4083], device='cuda:0')\n",
            "logits: tensor([17.1982], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5477], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1721], device='cuda:0')\n",
            " 99% 6182/6237 [1:47:30<01:00,  1.10s/it]losses: tensor([0.1847], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-576.7880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.9664], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-582.3919], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.6192], device='cuda:0')\n",
            "logits: tensor([15.9511], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5604], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0347], device='cuda:0')\n",
            " 99% 6183/6237 [1:47:31<00:56,  1.05s/it]losses: tensor([0.0881], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-135.6273], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-189.1880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-151.0815], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-180.7983], device='cuda:0')\n",
            "logits: tensor([23.8438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5454], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8390], device='cuda:0')\n",
            " 99% 6184/6237 [1:47:32<00:58,  1.11s/it]losses: tensor([0.1053], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-235.2148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.6809], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-250.0014], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.4860], device='cuda:0')\n",
            "logits: tensor([21.9816], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4787], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7195], device='cuda:0')\n",
            " 99% 6185/6237 [1:47:34<00:58,  1.13s/it]losses: tensor([0.0826], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-336.5976], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.3070], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-331.2960], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-470.4824], device='cuda:0')\n",
            "logits: tensor([24.5230], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5302], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9825], device='cuda:0')\n",
            " 99% 6186/6237 [1:47:34<00:53,  1.06s/it]losses: tensor([0.2429], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-543.1747], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-404.4838], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-550.5833], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.9796], device='cuda:0')\n",
            "logits: tensor([12.9128], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7409], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5504], device='cuda:0')\n",
            " 99% 6187/6237 [1:47:35<00:49,  1.02it/s]losses: tensor([0.2652], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-878.1506], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.6201], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-878.5605], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.1135], device='cuda:0')\n",
            "logits: tensor([11.9166], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0410], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1507], device='cuda:0')\n",
            " 99% 6188/6237 [1:47:37<00:54,  1.11s/it]losses: tensor([0.4043], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-254.4404], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-290.1862], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-261.2447], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-290.0236], device='cuda:0')\n",
            "logits: tensor([6.9670], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6804], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0163], device='cuda:0')\n",
            " 99% 6189/6237 [1:47:38<00:59,  1.23s/it]losses: tensor([0.0975], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-206.5262], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-312.0651], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-217.6684], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-300.4236], device='cuda:0')\n",
            "logits: tensor([22.7838], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1142], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1642], device='cuda:0')\n",
            "{'loss': 0.1811, 'learning_rate': 5.3447354355959385e-09, 'rewards/real': 0.720427930355072, 'rewards/generated': -1.0255472660064697, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7459748983383179, 'logps/generated': -356.5196838378906, 'logps/real': -431.5865783691406, 'logits/generated': -1.4576150178909302, 'logits/real': -1.4353445768356323, 'epoch': 2.98}\n",
            " 99% 6190/6237 [1:47:39<00:47,  1.01s/it]losses: tensor([0.1111], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-517.0406], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.8659], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-532.5203], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.9290], device='cuda:0')\n",
            "logits: tensor([21.4165], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5480], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5937], device='cuda:0')\n",
            " 99% 6191/6237 [1:47:39<00:42,  1.09it/s]losses: tensor([0.0304], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-138.1137], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.1523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-147.2120], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.4601], device='cuda:0')\n",
            "logits: tensor([34.7905], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9098], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5692], device='cuda:0')\n",
            " 99% 6192/6237 [1:47:40<00:41,  1.08it/s]losses: tensor([0.1730], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-466.7200], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-367.7073], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-466.9657], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-351.2861], device='cuda:0')\n",
            "logits: tensor([16.6668], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0246], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6421], device='cuda:0')\n",
            " 99% 6193/6237 [1:47:41<00:37,  1.17it/s]losses: tensor([0.1456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-527.2528], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.0291], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-536.4003], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.6477], device='cuda:0')\n",
            "logits: tensor([18.5289], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9148], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9381], device='cuda:0')\n",
            " 99% 6194/6237 [1:47:42<00:38,  1.13it/s]losses: tensor([0.0379], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-948.1708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.6687], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-961.2914], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.2456], device='cuda:0')\n",
            "logits: tensor([32.5437], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3121], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9423], device='cuda:0')\n",
            " 99% 6195/6237 [1:47:43<00:40,  1.05it/s]losses: tensor([0.0897], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-230.4134], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-340.7763], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-241.5424], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-328.2482], device='cuda:0')\n",
            "logits: tensor([23.6571], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1129], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2528], device='cuda:0')\n",
            " 99% 6196/6237 [1:47:44<00:34,  1.19it/s]losses: tensor([0.0635], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-457.2908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-369.6240], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-475.3881], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.4809], device='cuda:0')\n",
            "logits: tensor([27.2405], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8097], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9143], device='cuda:0')\n",
            " 99% 6197/6237 [1:47:44<00:30,  1.33it/s]losses: tensor([0.2682], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-245.6671], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-261.3284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-253.0052], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-256.8763], device='cuda:0')\n",
            "logits: tensor([11.7903], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7338], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4452], device='cuda:0')\n",
            " 99% 6198/6237 [1:47:45<00:29,  1.31it/s]losses: tensor([0.0547], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-982.9777], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.0892], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-990.9222], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.2525], device='cuda:0')\n",
            "logits: tensor([28.7812], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7945], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0837], device='cuda:0')\n",
            " 99% 6199/6237 [1:47:46<00:32,  1.16it/s]losses: tensor([0.0197], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-413.6979], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.0708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-422.1140], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-433.3244], device='cuda:0')\n",
            "logits: tensor([39.1624], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8416], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0746], device='cuda:0')\n",
            "{'loss': 0.0994, 'learning_rate': 4.4539461963299485e-09, 'rewards/real': 1.0001678466796875, 'rewards/generated': -1.545612096786499, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5457801818847656, 'logps/generated': -394.03118896484375, 'logps/real': -492.7344665527344, 'logits/generated': -1.551792025566101, 'logits/real': -1.4897171258926392, 'epoch': 2.98}\n",
            " 99% 6200/6237 [1:47:47<00:31,  1.17it/s]losses: tensor([0.0548], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-110.0259], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.1761], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-121.3273], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.7028], device='cuda:0')\n",
            "logits: tensor([28.7747], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1301], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7473], device='cuda:0')\n",
            " 99% 6201/6237 [1:47:49<00:40,  1.13s/it]losses: tensor([0.0554], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-441.2385], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-401.9752], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-445.2755], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.3640], device='cuda:0')\n",
            "logits: tensor([28.6483], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4037], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4611], device='cuda:0')\n",
            " 99% 6202/6237 [1:47:49<00:35,  1.01s/it]losses: tensor([0.0412], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-209.3506], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.1013], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-216.4450], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-455.5204], device='cuda:0')\n",
            "logits: tensor([31.6753], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7094], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4581], device='cuda:0')\n",
            " 99% 6203/6237 [1:47:51<00:37,  1.09s/it]losses: tensor([0.0301], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-83.9045], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.7372], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-95.9484], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-358.8904], device='cuda:0')\n",
            "logits: tensor([34.8907], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2044], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2847], device='cuda:0')\n",
            " 99% 6204/6237 [1:47:52<00:34,  1.05s/it]losses: tensor([0.0431], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-127.2587], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.3610], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-141.3047], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-356.1889], device='cuda:0')\n",
            "logits: tensor([31.2181], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4046], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7172], device='cuda:0')\n",
            " 99% 6205/6237 [1:47:53<00:32,  1.03s/it]losses: tensor([0.3022], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1118.4379], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.1172], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1115.8667], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.1269], device='cuda:0')\n",
            "logits: tensor([10.4192], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2571], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2990], device='cuda:0')\n",
            "100% 6206/6237 [1:47:55<00:40,  1.30s/it]losses: tensor([0.2585], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-742.7368], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-345.4740], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-753.0457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-343.5758], device='cuda:0')\n",
            "logits: tensor([12.2071], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0309], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1898], device='cuda:0')\n",
            "100% 6207/6237 [1:47:56<00:36,  1.22s/it]losses: tensor([0.1494], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-660.1703], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.1879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-667.2206], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-335.9812], device='cuda:0')\n",
            "logits: tensor([18.2570], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7050], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1207], device='cuda:0')\n",
            "100% 6208/6237 [1:47:57<00:35,  1.21s/it]losses: tensor([0.0651], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1508.6676], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.7291], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1524.0815], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.1569], device='cuda:0')\n",
            "logits: tensor([26.9861], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5414], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1572], device='cuda:0')\n",
            "100% 6209/6237 [1:47:59<00:38,  1.37s/it]losses: tensor([0.0513], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1075.5559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.4910], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1084.3677], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.8555], device='cuda:0')\n",
            "logits: tensor([29.4473], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8812], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0635], device='cuda:0')\n",
            "{'loss': 0.1051, 'learning_rate': 3.5631569570639584e-09, 'rewards/real': 0.875363826751709, 'rewards/generated': -1.6498730182647705, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5252370834350586, 'logps/generated': -404.135009765625, 'logps/real': -607.7347412109375, 'logits/generated': -1.7168689966201782, 'logits/real': -1.6110188961029053, 'epoch': 2.99}\n",
            "100% 6210/6237 [1:48:00<00:35,  1.32s/it]losses: tensor([0.5688], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-742.4813], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.7319], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-733.8489], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.4355], device='cuda:0')\n",
            "logits: tensor([2.6640], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8632], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1296], device='cuda:0')\n",
            "100% 6211/6237 [1:48:01<00:32,  1.26s/it]losses: tensor([0.0584], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1527.4773], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-530.4440], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1535.5837], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-510.4393], device='cuda:0')\n",
            "logits: tensor([28.1111], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8106], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0005], device='cuda:0')\n",
            "100% 6212/6237 [1:48:03<00:34,  1.38s/it]losses: tensor([0.4467], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-827.8771], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-372.6498], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-825.2559], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.2874], device='cuda:0')\n",
            "logits: tensor([5.7411], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2621], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8362], device='cuda:0')\n",
            "100% 6213/6237 [1:48:04<00:31,  1.31s/it]losses: tensor([0.0883], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-124.9423], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-366.6337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-137.9523], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.8125], device='cuda:0')\n",
            "logits: tensor([23.8312], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3010], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0821], device='cuda:0')\n",
            "100% 6214/6237 [1:48:05<00:27,  1.17s/it]losses: tensor([0.0918], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-287.6746], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.4208], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-304.0727], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.3956], device='cuda:0')\n",
            "logits: tensor([23.4233], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6398], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7025], device='cuda:0')\n",
            "100% 6215/6237 [1:48:06<00:28,  1.28s/it]losses: tensor([0.1353], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1000.2685], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.9035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1001.2554], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.5747], device='cuda:0')\n",
            "logits: tensor([19.3157], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0987], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8329], device='cuda:0')\n",
            "100% 6216/6237 [1:48:07<00:25,  1.24s/it]losses: tensor([0.0238], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-286.8632], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-440.1360], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-302.5374], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-418.5292], device='cuda:0')\n",
            "logits: tensor([37.2810], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5674], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1607], device='cuda:0')\n",
            "100% 6217/6237 [1:48:08<00:20,  1.04s/it]losses: tensor([0.0557], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-248.8264], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.9474], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-255.4667], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.9900], device='cuda:0')\n",
            "logits: tensor([28.5978], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6640], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1957], device='cuda:0')\n",
            "100% 6218/6237 [1:48:09<00:19,  1.03s/it]losses: tensor([0.1382], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-174.6969], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.3798], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-182.4079], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-368.9963], device='cuda:0')\n",
            "logits: tensor([19.0946], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7711], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1384], device='cuda:0')\n",
            "100% 6219/6237 [1:48:10<00:18,  1.05s/it]losses: tensor([0.2131], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1574.5472], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-495.8130], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1570.9973], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-477.8858], device='cuda:0')\n",
            "logits: tensor([14.3774], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3550], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7927], device='cuda:0')\n",
            "{'loss': 0.182, 'learning_rate': 2.6723677177979692e-09, 'rewards/real': 0.5372346639633179, 'rewards/generated': -1.4871375560760498, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0243723392486572, 'logps/generated': -426.20599365234375, 'logps/real': -679.5655517578125, 'logits/generated': -1.5715417861938477, 'logits/real': -1.5043613910675049, 'epoch': 2.99}\n",
            "100% 6220/6237 [1:48:12<00:21,  1.29s/it]losses: tensor([0.1035], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-551.3618], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.4653], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-564.7585], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.7042], device='cuda:0')\n",
            "logits: tensor([22.1578], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3397], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8761], device='cuda:0')\n",
            "100% 6221/6237 [1:48:12<00:18,  1.13s/it]losses: tensor([0.3660], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-427.4916], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-307.2516], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-435.0256], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-306.6213], device='cuda:0')\n",
            "logits: tensor([8.1643], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7534], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0630], device='cuda:0')\n",
            "100% 6222/6237 [1:48:13<00:14,  1.01it/s]losses: tensor([0.0302], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-262.4631], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.9330], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-276.9270], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.5622], device='cuda:0')\n",
            "logits: tensor([34.8346], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4464], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0371], device='cuda:0')\n",
            "100% 6223/6237 [1:48:14<00:12,  1.14it/s]losses: tensor([0.0664], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-753.5862], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.8976], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-765.1461], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-365.6647], device='cuda:0')\n",
            "logits: tensor([26.7929], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1560], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5233], device='cuda:0')\n",
            "100% 6224/6237 [1:48:15<00:14,  1.13s/it]losses: tensor([0.2851], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-294.9761], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-324.5315], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-301.0101], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-319.4740], device='cuda:0')\n",
            "logits: tensor([11.0916], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6034], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5057], device='cuda:0')\n",
            "100% 6225/6237 [1:48:16<00:11,  1.05it/s]losses: tensor([0.0347], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-866.9121], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.5547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-878.6976], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.8948], device='cuda:0')\n",
            "logits: tensor([33.4454], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1785], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1660], device='cuda:0')\n",
            "100% 6226/6237 [1:48:17<00:11,  1.06s/it]losses: tensor([0.0362], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-233.6365], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-411.1511], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-247.0389], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.5587], device='cuda:0')\n",
            "logits: tensor([32.9948], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3402], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9592], device='cuda:0')\n",
            "100% 6227/6237 [1:48:19<00:11,  1.18s/it]losses: tensor([0.0096], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-209.1963], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-498.2955], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-224.5148], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.2253], device='cuda:0')\n",
            "logits: tensor([46.3887], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5319], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1070], device='cuda:0')\n",
            "100% 6228/6237 [1:48:20<00:10,  1.13s/it]losses: tensor([0.0205], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-114.9095], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-510.1183], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-131.4558], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-487.8863], device='cuda:0')\n",
            "logits: tensor([38.7784], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6546], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2232], device='cuda:0')\n",
            "100% 6229/6237 [1:48:22<00:10,  1.37s/it]losses: tensor([0.0957], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1106.2926], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-402.7742], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1120.2382], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.7324], device='cuda:0')\n",
            "logits: tensor([22.9874], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3946], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9042], device='cuda:0')\n",
            "{'loss': 0.1048, 'learning_rate': 1.7815784785319792e-09, 'rewards/real': 1.2398686408996582, 'rewards/generated': -1.5364909172058105, 'rewards/accuracies': 1.0, 'rewards/margins': 2.776359796524048, 'logps/generated': -405.5972900390625, 'logps/real': -482.0826110839844, 'logits/generated': -1.5222299098968506, 'logits/real': -1.555606722831726, 'epoch': 3.0}\n",
            "100% 6230/6237 [1:48:23<00:10,  1.46s/it]losses: tensor([0.0355], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-167.6913], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.4836], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-185.7134], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-332.2986], device='cuda:0')\n",
            "logits: tensor([33.2071], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.8022], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5185], device='cuda:0')\n",
            "100% 6231/6237 [1:48:25<00:08,  1.47s/it]losses: tensor([0.3643], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-557.8021], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-318.4095], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-566.0681], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-318.4560], device='cuda:0')\n",
            "logits: tensor([8.2194], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8266], device='cuda:0')\n",
            "generated_rewards: tensor([0.0047], device='cuda:0')\n",
            "100% 6232/6237 [1:48:26<00:07,  1.41s/it]losses: tensor([0.1070], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-582.2897], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.6316], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-588.2296], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-459.7583], device='cuda:0')\n",
            "logits: tensor([21.8133], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5940], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5873], device='cuda:0')\n",
            "100% 6233/6237 [1:48:27<00:04,  1.16s/it]losses: tensor([0.1707], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-492.4739], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-350.1776], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-500.3194], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-341.2132], device='cuda:0')\n",
            "logits: tensor([16.8098], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7845], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8964], device='cuda:0')\n",
            "100% 6234/6237 [1:48:27<00:03,  1.03s/it]losses: tensor([0.2521], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-152.1470], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-349.9798], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-159.3664], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-344.7078], device='cuda:0')\n",
            "logits: tensor([12.4914], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7219], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5272], device='cuda:0')\n",
            "100% 6235/6237 [1:48:29<00:02,  1.23s/it]losses: tensor([0.0349], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-683.4280], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-353.8259], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-698.5258], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-335.5318], device='cuda:0')\n",
            "logits: tensor([33.3919], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5098], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8294], device='cuda:0')\n",
            "100% 6236/6237 [1:48:30<00:01,  1.10s/it]losses: tensor([0.0440], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-282.3641], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-470.4484], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-295.6314], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.6976], device='cuda:0')\n",
            "logits: tensor([31.0181], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3267], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7751], device='cuda:0')\n",
            "100% 6237/6237 [1:48:31<00:00,  1.20s/it][INFO|trainer.py:2926] 2025-04-30 14:10:27,570 >> Saving model checkpoint to outputs/tmp-checkpoint-6237\n",
            "[INFO|tokenization_utils_base.py:2433] 2025-04-30 14:10:27,603 >> tokenizer config file saved in outputs/tmp-checkpoint-6237/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2442] 2025-04-30 14:10:27,603 >> Special tokens file saved in outputs/tmp-checkpoint-6237/special_tokens_map.json\n",
            "[INFO|trainer.py:1962] 2025-04-30 14:10:27,826 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 6513.9457, 'train_samples_per_second': 0.957, 'train_steps_per_second': 0.957, 'train_loss': 0.3082248834113347, 'epoch': 3.0}\n",
            "100% 6237/6237 [1:48:32<00:00,  1.04s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.3082\n",
            "  train_runtime            = 1:48:33.94\n",
            "  train_samples            =       2079\n",
            "  train_samples_per_second =      0.957\n",
            "  train_steps_per_second   =      0.957\n",
            "2025-04-30 14:10:27 - INFO - __main__ - *** Training complete ***\n",
            "[INFO|trainer.py:2926] 2025-04-30 14:10:27,861 >> Saving model checkpoint to outputs\n",
            "[INFO|tokenization_utils_base.py:2433] 2025-04-30 14:10:27,894 >> tokenizer config file saved in outputs/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2442] 2025-04-30 14:10:27,895 >> Special tokens file saved in outputs/special_tokens_map.json\n",
            "[INFO|modelcard.py:452] 2025-04-30 14:10:28,309 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'dataset': {'name': 'qwen_datasets/iter0', 'type': 'qwen_datasets/iter0', 'config': None, 'split': 'None'}}\n",
            "[INFO|configuration_utils.py:473] 2025-04-30 14:10:28,313 >> Configuration saved in outputs/config.json\n",
            "2025-04-30 14:10:28 - INFO - __main__ - *** Waiting for all processes to finish ***\n",
            "2025-04-30 14:10:28 - INFO - __main__ - *** Run complete! ***\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mblooming-donkey-40\u001b[0m at: \u001b[34mhttps://wandb.ai/mu_qianyu-mipt/huggingface/runs/th84tfs7\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250430_122154-th84tfs7/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Qwen 2.5-0.5B iter2"
      ],
      "metadata": {
        "id": "evOfpTd8Ka73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r ./drive/MyDrive/qwen2.5/ ."
      ],
      "metadata": {
        "id": "d7fGfn0iHgde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "torch.backends.cuda.enable_flash_sdp(False)"
      ],
      "metadata": {
        "id": "DMRj6AwcMNIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ./qwen2.5/generated/iter1"
      ],
      "metadata": {
        "id": "x0mmXH7TcvcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import gather_object\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "import argparse\n",
        "import torch, time, json, os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "from accelerate.utils import InitProcessGroupKwargs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=36000))\n",
        "accelerator = Accelerator(kwargs_handlers=[kwargs])\n",
        "\n",
        "def parse_arguments():\n",
        "    \"\"\"Parse command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', type=str, default='UCLA-AGI/zephyr-7b-sft-full-SPIN-iter0')\n",
        "    parser.add_argument('--data_frac', type=int, default=0)\n",
        "    parser.add_argument('--frac_len', type=int, default=0)\n",
        "    parser.add_argument('--output_dir', type=str, default='generated/iter1')\n",
        "    parser.add_argument('--batch_size', type=int, default=16)\n",
        "    parser.add_argument('--input_dir', type=str, default='UCLA-AGI/SPIN_iter0')\n",
        "    parser.add_argument('--split', type=str, default='train')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def prepare_prompts(prompts, tokenizer, batch_size=4):\n",
        "    \"\"\"Prepare prompts for tokenization.\"\"\"\n",
        "    batches=[prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)]\n",
        "    batches_tok=[]\n",
        "    tokenizer.padding_side=\"left\"\n",
        "    for prompt_batch in batches:\n",
        "        batches_tok.append(\n",
        "            tokenizer(\n",
        "                prompt_batch,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='longest',\n",
        "                truncation=False,\n",
        "                pad_to_multiple_of=8,\n",
        "                add_special_tokens=False).to(\"cuda\")\n",
        "            )\n",
        "    tokenizer.padding_side=\"right\"\n",
        "    return batches_tok\n",
        "\n",
        "model_path = './qwen2.5/models/iter1'\n",
        "data_frac = 0\n",
        "frac_len = 0\n",
        "batch_size = 4\n",
        "output_dir = './qwen2.5/generated/iter1'\n",
        "split = 'test'\n",
        "\n",
        "# load a base model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map={\"\": accelerator.process_index},\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# load data\n",
        "data = load_dataset('./qwen2.5/reformatted', split=split + '[:1%]')\n",
        "data = data.shuffle(seed=42)\n",
        "if frac_len > 0:\n",
        "    sub_len = frac_len\n",
        "    if sub_len*(data_frac+1) > len(data):\n",
        "        data = data[sub_len*data_frac:]['real']\n",
        "    else:\n",
        "        data = data[sub_len*data_frac:sub_len*(data_frac+1)]['real']\n",
        "else:\n",
        "    data = data[:]['real']\n",
        "\n",
        "prompts_all = [\"### Instruction: \" + data[idx][0]['content'] + \"\\n\\n### Response: \" for idx in range(len(data))]\n",
        "prompts_old = [data[idx][0]['content'] for idx in range(len(data))]\n",
        "corrects_all = [data[idx][1]['content'] for idx in range(len(data))]\n",
        "\n",
        "# sync GPUs and start the timer\n",
        "accelerator.wait_for_everyone()\n",
        "start=time.time()\n",
        "\n",
        "# divide the prompt list onto the available GPUs\n",
        "with accelerator.split_between_processes(prompts_all) as prompts:\n",
        "    results = []\n",
        "    prompt_batches=prepare_prompts(prompts, tokenizer, batch_size=batch_size)\n",
        "\n",
        "    for prompts_tokenized in tqdm(prompt_batches):\n",
        "        # set max_new_tokens smaller for faster inference\n",
        "        outputs_tokenized=model.generate(**prompts_tokenized, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        # remove prompt from gen. tokens\n",
        "        outputs_tokenized=[ tok_out[len(tok_in):]\n",
        "            for tok_in, tok_out in zip(prompts_tokenized[\"input_ids\"], outputs_tokenized) ]\n",
        "        # decode gen. tokens\n",
        "        outputs=tokenizer.batch_decode(outputs_tokenized)\n",
        "        results.extend(outputs)\n",
        "\n",
        "# collect results from all the GPUs and remove paddings\n",
        "results_gathered=gather_object(results)\n",
        "results = [r.replace(\"</s>\",\"\").lstrip() for r in results_gathered]\n",
        "\n",
        "if accelerator.is_local_main_process:\n",
        "    timediff=time.time()-start\n",
        "    print(f\"time elapsed: {timediff}\")\n",
        "\n",
        "    # collecting data\n",
        "    for idx in range(len(corrects_all)):\n",
        "        d = {\"real\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": corrects_all[idx]}], \"generated\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": results[idx]}]}\n",
        "        if split == 'test':\n",
        "            filename = f\"{output_dir}/loser_{data_frac}_test.jsonl\"\n",
        "        else:\n",
        "            filename = f\"{output_dir}/loser_{data_frac}.jsonl\"\n",
        "        with open(filename, 'a') as f:\n",
        "            json.dump(d, f)\n",
        "            f.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2DG_dBaIbCm",
        "outputId": "9acacc75-e882-4d66-a39b-20b00e9bb0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "100%|██████████| 58/58 [10:58<00:00, 11.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time elapsed: 659.0869681835175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ./qwen2.5/datasets/iter1\n",
        "! python3 SPIN/spin/convert_data.py --num_fracs=5 --input_dir=./qwen2.5/generated/iter1 --output_dir=./qwen2.5/datasets/iter1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMC2p80l-QmI",
        "outputId": "61e9f9e3-f81c-4ac6-b743-17dd4b739e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2079\n",
            "231\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8830.11it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1257.66it/s]\n",
            "Generating train split: 2079 examples [00:00, 15586.66 examples/s]\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 10951.19it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1818.08it/s]\n",
            "Generating train split: 231 examples [00:00, 22037.63 examples/s]\n",
            "2079\n",
            "231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо немного подкорректировать файл SPIN/spin/alignemnt/trainer.py закомментировать проверку наличия peft и wandb"
      ],
      "metadata": {
        "id": "gAOd9fWLEvr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyPug_owQzsE",
        "outputId": "75b25996-d101-4a12-8fd0-a6ba38cedefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3523616 sha256=30bf6400bcea55f060ffeb83a46f55dd09ba99e2cc986e1d9861893a5ffafc32\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=2707989 sha256=2cf4fddae407fc46d0c340a6275f17b7f401436919ccdef39811ef393d80f2a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install numpy==1.26.4\n",
        "! python3 SPIN/spin/run_spin.py ./qwen2.5/configs/iter1.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKrZ9Bub_Tph",
        "outputId": "90eeea95-c086-46cd-b636-875cb7c75eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "policy_generated_logps: tensor([-551.9357], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-615.1365], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-516.6193], device='cuda:0')\n",
            "logits: tensor([26.9261], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8390], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5316], device='cuda:0')\n",
            " 90% 5624/6237 [1:35:47<07:43,  1.32it/s]losses: tensor([0.0831], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-276.7844], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-513.9277], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-287.3853], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-500.0727], device='cuda:0')\n",
            "logits: tensor([24.4559], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0601], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3855], device='cuda:0')\n",
            " 90% 5625/6237 [1:35:48<09:52,  1.03it/s]losses: tensor([0.0501], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-835.8972], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-411.4821], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-834.8192], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.7150], device='cuda:0')\n",
            "logits: tensor([29.6890], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1078], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0767], device='cuda:0')\n",
            " 90% 5626/6237 [1:35:49<10:57,  1.08s/it]losses: tensor([0.1173], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-670.1487], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.6203], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-656.6534], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.2832], device='cuda:0')\n",
            "logits: tensor([20.8419], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3495], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4337], device='cuda:0')\n",
            " 90% 5627/6237 [1:35:51<11:19,  1.11s/it]losses: tensor([0.0170], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-140.9187], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-804.1812], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-142.8435], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-765.4744], device='cuda:0')\n",
            "logits: tensor([40.6315], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1925], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8707], device='cuda:0')\n",
            " 90% 5628/6237 [1:35:52<12:22,  1.22s/it]losses: tensor([0.0661], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-228.7344], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-490.2248], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-233.2056], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.8591], device='cuda:0')\n",
            "logits: tensor([26.8369], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4471], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2366], device='cuda:0')\n",
            " 90% 5629/6237 [1:35:53<11:15,  1.11s/it]losses: tensor([0.1488], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-410.9971], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-510.0767], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-411.9211], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.7029], device='cuda:0')\n",
            "logits: tensor([18.2978], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0924], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7374], device='cuda:0')\n",
            "{'loss': 0.067, 'learning_rate': 5.513985391056476e-08, 'rewards/real': 0.3659101724624634, 'rewards/generated': -2.4848110675811768, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8507213592529297, 'logps/generated': -493.66973876953125, 'logps/real': -421.23516845703125, 'logits/generated': -1.1043248176574707, 'logits/real': -1.2676671743392944, 'epoch': 2.71}\n",
            " 90% 5630/6237 [1:35:54<09:57,  1.02it/s]losses: tensor([0.0926], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1042.7512], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-539.8983], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1032.0974], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-505.9174], device='cuda:0')\n",
            "logits: tensor([23.3270], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0654], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3981], device='cuda:0')\n",
            " 90% 5631/6237 [1:35:55<10:38,  1.05s/it]losses: tensor([0.0335], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-398.8501], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-348.1962], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-402.3642], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-317.9286], device='cuda:0')\n",
            "logits: tensor([33.7818], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3514], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0268], device='cuda:0')\n",
            " 90% 5632/6237 [1:35:56<10:26,  1.04s/it]losses: tensor([0.4210], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-579.5192], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-280.0221], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-579.3940], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-273.4243], device='cuda:0')\n",
            "logits: tensor([6.4727], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0125], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6598], device='cuda:0')\n",
            " 90% 5633/6237 [1:35:57<11:44,  1.17s/it]losses: tensor([0.2303], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-823.0397], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.9869], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-814.1618], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.6009], device='cuda:0')\n",
            "logits: tensor([13.5080], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8878], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2386], device='cuda:0')\n",
            " 90% 5634/6237 [1:35:58<11:13,  1.12s/it]losses: tensor([0.1625], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-419.8966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.6903], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-416.5012], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.9477], device='cuda:0')\n",
            "logits: tensor([17.3473], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3395], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0743], device='cuda:0')\n",
            " 90% 5635/6237 [1:35:59<09:31,  1.05it/s]losses: tensor([0.1293], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-793.5427], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-383.8958], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-793.4669], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.0148], device='cuda:0')\n",
            "logits: tensor([19.8052], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0076], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9881], device='cuda:0')\n",
            " 90% 5636/6237 [1:36:00<10:15,  1.02s/it]losses: tensor([0.0291], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-305.8011], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-506.9076], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-305.1753], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.0417], device='cuda:0')\n",
            "logits: tensor([35.2400], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0626], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5866], device='cuda:0')\n",
            " 90% 5637/6237 [1:36:01<08:45,  1.14it/s]losses: tensor([0.0219], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-296.6436], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.4412], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-294.6991], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.3986], device='cuda:0')\n",
            "logits: tensor([38.0981], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1944], device='cuda:0')\n",
            "generated_rewards: tensor([-4.0043], device='cuda:0')\n",
            " 90% 5638/6237 [1:36:01<07:41,  1.30it/s]losses: tensor([0.0564], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-291.1208], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.8025], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-290.8467], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.0632], device='cuda:0')\n",
            "logits: tensor([28.4651], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0274], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8739], device='cuda:0')\n",
            " 90% 5639/6237 [1:36:03<09:45,  1.02it/s]losses: tensor([0.1649], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-888.7366], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.6723], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-880.7338], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.4810], device='cuda:0')\n",
            "logits: tensor([17.1886], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8003], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5191], device='cuda:0')\n",
            "{'loss': 0.1342, 'learning_rate': 5.424906467129877e-08, 'rewards/real': -0.3046121299266815, 'rewards/generated': -2.6369495391845703, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3323371410369873, 'logps/generated': -440.85125732421875, 'logps/real': -583.9901733398438, 'logits/generated': -1.3975255489349365, 'logits/real': -1.3671367168426514, 'epoch': 2.71}\n",
            " 90% 5640/6237 [1:36:04<10:12,  1.03s/it]losses: tensor([0.0520], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-313.3769], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.2568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-323.9002], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.4716], device='cuda:0')\n",
            "logits: tensor([29.3085], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0523], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8785], device='cuda:0')\n",
            " 90% 5641/6237 [1:36:04<08:43,  1.14it/s]losses: tensor([0.1227], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-592.1469], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-342.7755], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-598.7162], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-328.9806], device='cuda:0')\n",
            "logits: tensor([20.3643], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6569], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3795], device='cuda:0')\n",
            " 90% 5642/6237 [1:36:05<08:42,  1.14it/s]losses: tensor([0.2292], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.8083], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-434.2289], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-743.4309], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.2871], device='cuda:0')\n",
            "logits: tensor([13.5645], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.2377], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5942], device='cuda:0')\n",
            " 90% 5643/6237 [1:36:06<08:17,  1.19it/s]losses: tensor([0.4548], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-530.0640], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-578.0854], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-534.8953], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-577.3976], device='cuda:0')\n",
            "logits: tensor([5.5191], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4831], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0688], device='cuda:0')\n",
            " 90% 5644/6237 [1:36:07<10:10,  1.03s/it]losses: tensor([0.0213], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-630.7112], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.1434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-623.9424], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.0085], device='cuda:0')\n",
            "logits: tensor([38.3660], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6769], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5135], device='cuda:0')\n",
            " 91% 5645/6237 [1:36:08<09:04,  1.09it/s]losses: tensor([0.1937], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1354.9072], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.5721], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1339.7052], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.9418], device='cuda:0')\n",
            "logits: tensor([15.4282], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5202], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0630], device='cuda:0')\n",
            " 91% 5646/6237 [1:36:10<11:19,  1.15s/it]losses: tensor([0.0346], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-136.1649], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-391.4957], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-140.4006], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.2516], device='cuda:0')\n",
            "logits: tensor([33.4798], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4236], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9244], device='cuda:0')\n",
            " 91% 5647/6237 [1:36:10<09:22,  1.05it/s]losses: tensor([0.0447], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-261.2363], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.2999], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-268.3385], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.5579], device='cuda:0')\n",
            "logits: tensor([30.8442], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7102], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3742], device='cuda:0')\n",
            " 91% 5648/6237 [1:36:11<09:36,  1.02it/s]losses: tensor([0.5130], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-739.3222], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-337.6512], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-737.5477], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-331.8757], device='cuda:0')\n",
            "logits: tensor([4.0010], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1775], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5776], device='cuda:0')\n",
            " 91% 5649/6237 [1:36:12<09:55,  1.01s/it]losses: tensor([0.0127], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-363.4610], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-548.2115], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-359.3719], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-500.4981], device='cuda:0')\n",
            "logits: tensor([43.6243], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4089], device='cuda:0')\n",
            "generated_rewards: tensor([-4.7713], device='cuda:0')\n",
            "{'loss': 0.1679, 'learning_rate': 5.335827543203278e-08, 'rewards/real': -0.06949950754642487, 'rewards/generated': -2.4144997596740723, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3450002670288086, 'logps/generated': -438.77203369140625, 'logps/real': -567.7199096679688, 'logits/generated': -1.4614394903182983, 'logits/real': -1.176443338394165, 'epoch': 2.72}\n",
            " 91% 5650/6237 [1:36:13<09:25,  1.04it/s]losses: tensor([0.4628], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-914.0642], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.8167], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-912.4443], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.8965], device='cuda:0')\n",
            "logits: tensor([5.3004], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1620], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6920], device='cuda:0')\n",
            " 91% 5651/6237 [1:36:14<09:19,  1.05it/s]losses: tensor([0.0777], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1127.7078], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.3477], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1125.4801], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.9678], device='cuda:0')\n",
            "logits: tensor([25.1523], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2228], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7380], device='cuda:0')\n",
            " 91% 5652/6237 [1:36:16<10:44,  1.10s/it]losses: tensor([0.3641], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-946.7387], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.5705], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-937.7477], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.3511], device='cuda:0')\n",
            "logits: tensor([8.2285], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8991], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7219], device='cuda:0')\n",
            " 91% 5653/6237 [1:36:17<11:29,  1.18s/it]losses: tensor([0.1528], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-803.5045], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.1403], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-788.6403], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.2631], device='cuda:0')\n",
            "logits: tensor([18.0130], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4864], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2877], device='cuda:0')\n",
            " 91% 5654/6237 [1:36:18<11:10,  1.15s/it]losses: tensor([0.2076], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-894.7104], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.2247], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-885.8531], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.7012], device='cuda:0')\n",
            "logits: tensor([14.6662], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8857], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3523], device='cuda:0')\n",
            " 91% 5655/6237 [1:36:19<11:02,  1.14s/it]losses: tensor([0.0299], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-265.4629], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-504.9463], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-277.1680], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-481.6989], device='cuda:0')\n",
            "logits: tensor([34.9525], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1705], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3247], device='cuda:0')\n",
            " 91% 5656/6237 [1:36:20<09:11,  1.05it/s]losses: tensor([0.0154], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-248.1248], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.2247], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-240.9559], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.3987], device='cuda:0')\n",
            "logits: tensor([41.6572], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7169], device='cuda:0')\n",
            "generated_rewards: tensor([-4.8826], device='cuda:0')\n",
            " 91% 5657/6237 [1:36:20<07:54,  1.22it/s]losses: tensor([0.0253], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-247.2695], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.2072], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-248.2474], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.5415], device='cuda:0')\n",
            "logits: tensor([36.6436], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0978], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5666], device='cuda:0')\n",
            " 91% 5658/6237 [1:36:22<09:22,  1.03it/s]losses: tensor([0.1756], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-362.1011], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-317.8345], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-368.8994], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-308.1280], device='cuda:0')\n",
            "logits: tensor([16.5049], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6798], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9707], device='cuda:0')\n",
            " 91% 5659/6237 [1:36:22<08:44,  1.10it/s]losses: tensor([0.2086], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1236.0378], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.1551], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1229.1306], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-381.6355], device='cuda:0')\n",
            "logits: tensor([14.6124], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6907], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1520], device='cuda:0')\n",
            "{'loss': 0.172, 'learning_rate': 5.2467486192766784e-08, 'rewards/real': -0.3115459978580475, 'rewards/generated': -2.468855381011963, 'rewards/accuracies': 1.0, 'rewards/margins': 2.157309055328369, 'logps/generated': -447.5467834472656, 'logps/real': -704.5721435546875, 'logits/generated': -1.3399564027786255, 'logits/real': -1.2198119163513184, 'epoch': 2.72}\n",
            " 91% 5660/6237 [1:36:24<11:00,  1.14s/it]losses: tensor([0.1464], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-273.5288], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.4611], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-268.2595], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-428.7180], device='cuda:0')\n",
            "logits: tensor([18.4737], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5269], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3743], device='cuda:0')\n",
            " 91% 5661/6237 [1:36:25<12:00,  1.25s/it]losses: tensor([0.2327], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-232.2601], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.0419], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-217.7415], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.1307], device='cuda:0')\n",
            "logits: tensor([13.3926], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4519], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7911], device='cuda:0')\n",
            " 91% 5662/6237 [1:36:27<12:20,  1.29s/it]losses: tensor([0.2611], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-554.3388], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-435.6039], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-542.6327], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.8053], device='cuda:0')\n",
            "logits: tensor([12.0925], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1706], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3799], device='cuda:0')\n",
            " 91% 5663/6237 [1:36:28<10:27,  1.09s/it]losses: tensor([0.0235], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-345.5823], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-426.9105], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-349.2061], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.1328], device='cuda:0')\n",
            "logits: tensor([37.4015], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3624], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3778], device='cuda:0')\n",
            " 91% 5664/6237 [1:36:28<08:44,  1.09it/s]losses: tensor([0.0056], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-222.6579], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-529.7551], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-222.8079], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-478.1609], device='cuda:0')\n",
            "logits: tensor([51.7442], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0150], device='cuda:0')\n",
            "generated_rewards: tensor([-5.1594], device='cuda:0')\n",
            " 91% 5665/6237 [1:36:29<07:50,  1.21it/s]losses: tensor([0.0025], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-238.6210], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-539.2567], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-239.0947], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-479.9178], device='cuda:0')\n",
            "logits: tensor([59.8125], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0474], device='cuda:0')\n",
            "generated_rewards: tensor([-5.9339], device='cuda:0')\n",
            " 91% 5666/6237 [1:36:30<08:15,  1.15it/s]losses: tensor([0.3114], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-323.0370], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.2248], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-307.5254], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-369.6440], device='cuda:0')\n",
            "logits: tensor([10.0692], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5512], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5581], device='cuda:0')\n",
            " 91% 5667/6237 [1:36:30<07:30,  1.26it/s]losses: tensor([0.6823], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-446.0779], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-292.3136], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-440.8265], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-286.8445], device='cuda:0')\n",
            "logits: tensor([0.2177], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5251], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5469], device='cuda:0')\n",
            " 91% 5668/6237 [1:36:31<08:02,  1.18it/s]losses: tensor([0.0687], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-611.7545], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.2380], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-609.8773], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.9275], device='cuda:0')\n",
            "logits: tensor([26.4334], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1877], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8311], device='cuda:0')\n",
            " 91% 5669/6237 [1:36:32<07:55,  1.19it/s]losses: tensor([0.1097], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1229.5618], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.2792], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1223.6448], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-475.8145], device='cuda:0')\n",
            "logits: tensor([21.5478], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5917], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7465], device='cuda:0')\n",
            "{'loss': 0.1844, 'learning_rate': 5.15766969535008e-08, 'rewards/real': -0.5580376982688904, 'rewards/generated': -3.0698890686035156, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5118510723114014, 'logps/generated': -449.60845947265625, 'logps/real': -447.7420349121094, 'logits/generated': -1.534232258796692, 'logits/real': -1.5531208515167236, 'epoch': 2.73}\n",
            " 91% 5670/6237 [1:36:33<08:44,  1.08it/s]losses: tensor([0.0040], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-120.7984], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-548.7151], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-135.4531], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-508.2807], device='cuda:0')\n",
            "logits: tensor([55.0891], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4655], device='cuda:0')\n",
            "generated_rewards: tensor([-4.0434], device='cuda:0')\n",
            " 91% 5671/6237 [1:36:35<10:17,  1.09s/it]losses: tensor([0.0522], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-998.2355], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-479.4984], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-998.5694], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-450.5628], device='cuda:0')\n",
            "logits: tensor([29.2694], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0334], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8936], device='cuda:0')\n",
            " 91% 5672/6237 [1:36:36<10:24,  1.11s/it]losses: tensor([0.1137], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-534.9691], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-538.7634], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-522.4764], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-505.0984], device='cuda:0')\n",
            "logits: tensor([21.1723], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.2493], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3665], device='cuda:0')\n",
            " 91% 5673/6237 [1:36:36<08:53,  1.06it/s]losses: tensor([0.0365], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-204.4691], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-336.8166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-211.1190], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-310.5542], device='cuda:0')\n",
            "logits: tensor([32.9122], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6650], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6262], device='cuda:0')\n",
            " 91% 5674/6237 [1:36:37<07:39,  1.23it/s]losses: tensor([0.1165], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-344.3534], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.8347], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-349.5468], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-478.1218], device='cuda:0')\n",
            "logits: tensor([20.9063], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5193], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5713], device='cuda:0')\n",
            " 91% 5675/6237 [1:36:38<07:31,  1.25it/s]losses: tensor([0.4523], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-274.5090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-294.7170], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-275.4089], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-290.0303], device='cuda:0')\n",
            "logits: tensor([5.5866], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0900], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4687], device='cuda:0')\n",
            " 91% 5676/6237 [1:36:38<07:15,  1.29it/s]losses: tensor([0.0861], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-627.7271], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.0753], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-626.7257], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-473.9893], device='cuda:0')\n",
            "logits: tensor([24.0847], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1001], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5086], device='cuda:0')\n",
            " 91% 5677/6237 [1:36:39<07:34,  1.23it/s]losses: tensor([0.1620], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-509.8590], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-327.1648], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-525.8582], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-325.7859], device='cuda:0')\n",
            "logits: tensor([17.3781], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5999], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1379], device='cuda:0')\n",
            " 91% 5678/6237 [1:36:40<08:01,  1.16it/s]losses: tensor([0.0302], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-128.0075], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.5883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-129.0153], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.7401], device='cuda:0')\n",
            "logits: tensor([34.8559], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1008], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3848], device='cuda:0')\n",
            " 91% 5679/6237 [1:36:41<08:19,  1.12it/s]losses: tensor([0.1741], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-197.3634], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.8939], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-197.5727], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-473.5055], device='cuda:0')\n",
            "logits: tensor([16.5977], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0209], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6388], device='cuda:0')\n",
            "{'loss': 0.1228, 'learning_rate': 5.068590771423481e-08, 'rewards/real': 0.3145411014556885, 'rewards/generated': -2.2639811038970947, 'rewards/accuracies': 1.0, 'rewards/margins': 2.578522205352783, 'logps/generated': -450.8067321777344, 'logps/real': -394.02911376953125, 'logits/generated': -1.0479717254638672, 'logits/real': -1.082102656364441, 'epoch': 2.73}\n",
            " 91% 5680/6237 [1:36:42<07:12,  1.29it/s]losses: tensor([0.3629], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1171.7400], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.0072], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1155.3198], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-450.3215], device='cuda:0')\n",
            "logits: tensor([8.2655], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.6420], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4686], device='cuda:0')\n",
            " 91% 5681/6237 [1:36:43<09:14,  1.00it/s]losses: tensor([0.0896], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-277.1035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-411.9207], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-285.7315], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.8704], device='cuda:0')\n",
            "logits: tensor([23.6783], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8628], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5050], device='cuda:0')\n",
            " 91% 5682/6237 [1:36:44<09:38,  1.04s/it]losses: tensor([0.2900], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1542.1843], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.9028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1535.2487], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.0734], device='cuda:0')\n",
            "logits: tensor([10.8938], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6936], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7829], device='cuda:0')\n",
            " 91% 5683/6237 [1:36:46<11:11,  1.21s/it]losses: tensor([0.2316], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-515.9000], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.0424], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-523.4600], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-375.1531], device='cuda:0')\n",
            "logits: tensor([13.4493], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7560], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5889], device='cuda:0')\n",
            " 91% 5684/6237 [1:36:47<09:48,  1.06s/it]losses: tensor([0.0334], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-113.9194], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-599.3046], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-125.2954], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-576.8528], device='cuda:0')\n",
            "logits: tensor([33.8279], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1376], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2452], device='cuda:0')\n",
            " 91% 5685/6237 [1:36:48<09:24,  1.02s/it]losses: tensor([0.0665], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-930.0413], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-453.6148], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-938.6095], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.4053], device='cuda:0')\n",
            "logits: tensor([26.7777], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8568], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8209], device='cuda:0')\n",
            " 91% 5686/6237 [1:36:49<10:31,  1.15s/it]losses: tensor([0.1266], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-201.3164], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.1938], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-199.5287], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-466.3750], device='cuda:0')\n",
            "logits: tensor([20.0311], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1788], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1819], device='cuda:0')\n",
            " 91% 5687/6237 [1:36:50<08:51,  1.04it/s]losses: tensor([0.0115], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-650.5177], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-643.2917], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-659.5988], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-607.7556], device='cuda:0')\n",
            "logits: tensor([44.6172], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9081], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5536], device='cuda:0')\n",
            " 91% 5688/6237 [1:36:51<10:18,  1.13s/it]losses: tensor([0.1505], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-618.3373], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-305.5965], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-630.3732], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-299.4554], device='cuda:0')\n",
            "logits: tensor([18.1770], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2036], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6141], device='cuda:0')\n",
            " 91% 5689/6237 [1:36:52<10:34,  1.16s/it]losses: tensor([0.0265], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-145.8345], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.7810], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-158.6565], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.4476], device='cuda:0')\n",
            "logits: tensor([36.1555], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2822], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3333], device='cuda:0')\n",
            "{'loss': 0.1389, 'learning_rate': 4.9795118474968816e-08, 'rewards/real': 0.4492782652378082, 'rewards/generated': -1.9094552993774414, 'rewards/accuracies': 1.0, 'rewards/margins': 2.358733654022217, 'logps/generated': -469.1656188964844, 'logps/real': -616.689453125, 'logits/generated': -1.3572235107421875, 'logits/real': -1.2675917148590088, 'epoch': 2.74}\n",
            " 91% 5690/6237 [1:36:54<12:20,  1.35s/it]losses: tensor([0.0109], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-143.7799], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.3523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-154.7990], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.2818], device='cuda:0')\n",
            "logits: tensor([45.0895], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1019], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4070], device='cuda:0')\n",
            " 91% 5691/6237 [1:36:56<13:25,  1.47s/it]losses: tensor([0.4829], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-773.5624], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.2404], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-767.7310], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.6406], device='cuda:0')\n",
            "logits: tensor([4.7682], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5831], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0600], device='cuda:0')\n",
            " 91% 5692/6237 [1:36:57<11:50,  1.30s/it]losses: tensor([0.1218], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-982.8560], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-541.1046], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-972.2627], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-510.0750], device='cuda:0')\n",
            "logits: tensor([20.4362], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0593], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1030], device='cuda:0')\n",
            " 91% 5693/6237 [1:36:58<11:49,  1.30s/it]losses: tensor([0.4363], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-214.3989], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-230.8762], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-220.1784], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-230.6217], device='cuda:0')\n",
            "logits: tensor([6.0341], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5780], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0255], device='cuda:0')\n",
            " 91% 5694/6237 [1:36:59<09:48,  1.08s/it]losses: tensor([0.1158], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-305.3235], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.5801], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-307.3223], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-346.6010], device='cuda:0')\n",
            "logits: tensor([20.9779], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1999], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8979], device='cuda:0')\n",
            " 91% 5695/6237 [1:36:59<07:57,  1.13it/s]losses: tensor([0.0643], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-241.7716], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-620.0883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-231.4944], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-582.6970], device='cuda:0')\n",
            "logits: tensor([27.1140], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0277], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7391], device='cuda:0')\n",
            " 91% 5696/6237 [1:37:01<09:34,  1.06s/it]losses: tensor([0.0158], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-208.8132], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.5410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-202.2636], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.5910], device='cuda:0')\n",
            "logits: tensor([41.4005], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6550], device='cuda:0')\n",
            "generated_rewards: tensor([-4.7950], device='cuda:0')\n",
            " 91% 5697/6237 [1:37:02<10:23,  1.16s/it]losses: tensor([0.2771], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-457.8847], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-370.7040], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-453.5260], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-354.9271], device='cuda:0')\n",
            "logits: tensor([11.4182], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4359], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5777], device='cuda:0')\n",
            " 91% 5698/6237 [1:37:03<09:55,  1.11s/it]losses: tensor([0.1474], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-891.9481], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-552.9210], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-884.6709], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-527.2455], device='cuda:0')\n",
            "logits: tensor([18.3984], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7277], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5676], device='cuda:0')\n",
            " 91% 5699/6237 [1:37:04<09:50,  1.10s/it]losses: tensor([0.1091], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-487.7231], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.3448], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-486.2750], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-466.2940], device='cuda:0')\n",
            "logits: tensor([21.6027], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1448], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3051], device='cuda:0')\n",
            "{'loss': 0.1781, 'learning_rate': 4.8904329235702834e-08, 'rewards/real': -0.2753821015357971, 'rewards/generated': -2.4477787017822266, 'rewards/accuracies': 1.0, 'rewards/margins': 2.172396659851074, 'logps/generated': -451.7752990722656, 'logps/real': -470.80615234375, 'logits/generated': -1.4756217002868652, 'logits/real': -1.4167077541351318, 'epoch': 2.74}\n",
            " 91% 5700/6237 [1:37:05<08:36,  1.04it/s]losses: tensor([0.0616], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-278.1530], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-326.4857], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-285.6019], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-306.3690], device='cuda:0')\n",
            "logits: tensor([27.5655], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7449], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0117], device='cuda:0')\n",
            " 91% 5701/6237 [1:37:05<07:40,  1.16it/s]losses: tensor([0.0509], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-548.9772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-470.4803], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-540.3536], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.3326], device='cuda:0')\n",
            "logits: tensor([29.5241], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8624], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8148], device='cuda:0')\n",
            " 91% 5702/6237 [1:37:06<07:48,  1.14it/s]losses: tensor([0.1321], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-246.3292], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.8516], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-244.9413], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.8933], device='cuda:0')\n",
            "logits: tensor([19.5704], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1388], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0958], device='cuda:0')\n",
            " 91% 5703/6237 [1:37:07<06:47,  1.31it/s]losses: tensor([5.9178e-06], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-571.5913], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-3083.7556], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-560.4304], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-2952.2192], device='cuda:0')\n",
            "logits: tensor([120.3755], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1161], device='cuda:0')\n",
            "generated_rewards: tensor([-13.1536], device='cuda:0')\n",
            " 91% 5704/6237 [1:37:07<06:38,  1.34it/s]losses: tensor([0.0187], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-567.7081], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.7062], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-560.5824], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-433.8694], device='cuda:0')\n",
            "logits: tensor([39.7111], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7126], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6837], device='cuda:0')\n",
            " 91% 5705/6237 [1:37:08<06:47,  1.31it/s]losses: tensor([0.4015], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-183.4738], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-229.5635], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-195.5457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-234.5853], device='cuda:0')\n",
            "logits: tensor([7.0501], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2072], device='cuda:0')\n",
            "generated_rewards: tensor([0.5022], device='cuda:0')\n",
            " 91% 5706/6237 [1:37:09<06:47,  1.30it/s]losses: tensor([0.2836], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-302.1832], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.2108], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-313.6413], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.5190], device='cuda:0')\n",
            "logits: tensor([11.1500], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1458], device='cuda:0')\n",
            "generated_rewards: tensor([0.0308], device='cuda:0')\n",
            " 92% 5707/6237 [1:37:10<07:32,  1.17it/s]losses: tensor([0.2312], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-727.5919], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.8561], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-723.8456], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-456.6442], device='cuda:0')\n",
            "logits: tensor([13.4657], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3746], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7212], device='cuda:0')\n",
            " 92% 5708/6237 [1:37:11<07:12,  1.22it/s]losses: tensor([0.0146], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-402.6099], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.9000], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-400.1969], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.3253], device='cuda:0')\n",
            "logits: tensor([42.1618], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2413], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4575], device='cuda:0')\n",
            " 92% 5709/6237 [1:37:11<06:44,  1.30it/s]losses: tensor([0.1178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1147.2092], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-516.2422], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1144.2151], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.4592], device='cuda:0')\n",
            "logits: tensor([20.7889], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2994], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3783], device='cuda:0')\n",
            "{'loss': 0.1312, 'learning_rate': 4.8013539996436845e-08, 'rewards/real': -0.06472577899694443, 'rewards/generated': -3.3783555030822754, 'rewards/accuracies': 1.0, 'rewards/margins': 3.313629627227783, 'logps/generated': -691.6051635742188, 'logps/real': -497.5826721191406, 'logits/generated': -1.2832837104797363, 'logits/real': -1.426811695098877, 'epoch': 2.75}\n",
            " 92% 5710/6237 [1:37:13<08:02,  1.09it/s]losses: tensor([0.0019], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-142.1214], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-575.3983], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-153.2047], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-523.9613], device='cuda:0')\n",
            "logits: tensor([62.5203], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1083], device='cuda:0')\n",
            "generated_rewards: tensor([-5.1437], device='cuda:0')\n",
            " 92% 5711/6237 [1:37:14<09:50,  1.12s/it]losses: tensor([0.0174], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-415.1124], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.6845], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-418.5616], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.7148], device='cuda:0')\n",
            "logits: tensor([40.4188], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3449], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6970], device='cuda:0')\n",
            " 92% 5712/6237 [1:37:15<08:14,  1.06it/s]losses: tensor([0.2383], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-838.0165], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-350.4786], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-834.9476], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-334.2806], device='cuda:0')\n",
            "logits: tensor([13.1291], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3069], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6198], device='cuda:0')\n",
            " 92% 5713/6237 [1:37:16<08:57,  1.03s/it]losses: tensor([0.0216], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-286.7584], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.9989], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-278.3434], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.3625], device='cuda:0')\n",
            "logits: tensor([38.2214], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8415], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6636], device='cuda:0')\n",
            " 92% 5714/6237 [1:37:17<07:53,  1.11it/s]losses: tensor([0.0097], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-474.8004], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-505.3333], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-468.0218], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.2465], device='cuda:0')\n",
            "logits: tensor([46.3082], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6779], device='cuda:0')\n",
            "generated_rewards: tensor([-5.3087], device='cuda:0')\n",
            " 92% 5715/6237 [1:37:17<07:18,  1.19it/s]losses: tensor([0.2286], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-346.0819], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.2394], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-350.2073], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.7736], device='cuda:0')\n",
            "logits: tensor([13.5912], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4125], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9466], device='cuda:0')\n",
            " 92% 5716/6237 [1:37:18<07:26,  1.17it/s]losses: tensor([6.5064e-05], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-148.8314], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1269.6423], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-151.3764], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1175.7864], device='cuda:0')\n",
            "logits: tensor([96.4010], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2545], device='cuda:0')\n",
            "generated_rewards: tensor([-9.3856], device='cuda:0')\n",
            " 92% 5717/6237 [1:37:19<07:18,  1.19it/s]losses: tensor([0.0777], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-381.2815], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-523.2375], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-376.1642], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.9601], device='cuda:0')\n",
            "logits: tensor([25.1601], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5117], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0277], device='cuda:0')\n",
            " 92% 5718/6237 [1:37:20<06:42,  1.29it/s]losses: tensor([0.1898], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-675.0296], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.8521], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-673.7908], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.9604], device='cuda:0')\n",
            "logits: tensor([15.6529], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1239], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6892], device='cuda:0')\n",
            " 92% 5719/6237 [1:37:21<07:36,  1.13it/s]losses: tensor([0.0679], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-945.7003], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.6164], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-944.1542], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-343.5212], device='cuda:0')\n",
            "logits: tensor([26.5491], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1546], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8095], device='cuda:0')\n",
            "{'loss': 0.0853, 'learning_rate': 4.712275075717085e-08, 'rewards/real': -0.0496186837553978, 'rewards/generated': -3.8291401863098145, 'rewards/accuracies': 1.0, 'rewards/margins': 3.7795214653015137, 'logps/generated': -539.9481201171875, 'logps/real': -465.37335205078125, 'logits/generated': -1.170285940170288, 'logits/real': -1.5902822017669678, 'epoch': 2.75}\n",
            " 92% 5720/6237 [1:37:22<08:02,  1.07it/s]losses: tensor([0.2301], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-917.5892], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-479.2002], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-909.8927], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.9843], device='cuda:0')\n",
            "logits: tensor([13.5195], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7696], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1216], device='cuda:0')\n",
            " 92% 5721/6237 [1:37:23<08:30,  1.01it/s]losses: tensor([0.1342], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-805.3883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.2155], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-808.8427], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.2609], device='cuda:0')\n",
            "logits: tensor([19.4090], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3454], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5955], device='cuda:0')\n",
            " 92% 5722/6237 [1:37:24<08:51,  1.03s/it]losses: tensor([0.0570], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-767.9152], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-492.0931], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-766.7760], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.5940], device='cuda:0')\n",
            "logits: tensor([28.3599], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1139], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9499], device='cuda:0')\n",
            " 92% 5723/6237 [1:37:25<08:45,  1.02s/it]losses: tensor([0.2051], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-787.6456], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.7699], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-783.8748], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.1981], device='cuda:0')\n",
            "logits: tensor([14.8010], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3771], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8572], device='cuda:0')\n",
            " 92% 5724/6237 [1:37:26<09:14,  1.08s/it]losses: tensor([0.1827], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1046.8179], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.0372], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1035.6028], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.7530], device='cuda:0')\n",
            "logits: tensor([16.0691], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1215], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7284], device='cuda:0')\n",
            " 92% 5725/6237 [1:37:28<10:18,  1.21s/it]losses: tensor([0.0024], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-130.5559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.2568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-146.2952], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.8623], device='cuda:0')\n",
            "logits: tensor([60.1338], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5739], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4394], device='cuda:0')\n",
            " 92% 5726/6237 [1:37:29<10:07,  1.19s/it]losses: tensor([0.0235], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.7175], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.8628], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-756.5144], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.2779], device='cuda:0')\n",
            "logits: tensor([37.3818], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0797], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6585], device='cuda:0')\n",
            " 92% 5727/6237 [1:37:30<08:54,  1.05s/it]losses: tensor([0.1545], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-620.6849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-377.8640], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-622.1329], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-361.4159], device='cuda:0')\n",
            "logits: tensor([17.8961], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1448], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6448], device='cuda:0')\n",
            " 92% 5728/6237 [1:37:31<08:31,  1.01s/it]losses: tensor([0.5860], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-209.8226], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-511.8668], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-208.0952], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-507.8676], device='cuda:0')\n",
            "logits: tensor([2.2717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1727], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3999], device='cuda:0')\n",
            " 92% 5729/6237 [1:37:32<09:41,  1.14s/it]losses: tensor([0.4292], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-758.0733], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-444.2242], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-757.0925], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.0074], device='cuda:0')\n",
            "logits: tensor([6.2360], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0981], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7217], device='cuda:0')\n",
            "{'loss': 0.2005, 'learning_rate': 4.6231961517904866e-08, 'rewards/real': -0.05091064050793648, 'rewards/generated': -2.2116904258728027, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1607799530029297, 'logps/generated': -460.63897705078125, 'logps/real': -680.0210571289062, 'logits/generated': -1.7688086032867432, 'logits/real': -1.806976079940796, 'epoch': 2.76}\n",
            " 92% 5730/6237 [1:37:33<09:34,  1.13s/it]losses: tensor([0.0357], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1020.3477], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-539.5766], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1014.3845], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-500.4558], device='cuda:0')\n",
            "logits: tensor([33.1576], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5963], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9121], device='cuda:0')\n",
            " 92% 5731/6237 [1:37:34<09:21,  1.11s/it]losses: tensor([0.1672], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-529.0157], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.9268], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-538.0869], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.9601], device='cuda:0')\n",
            "logits: tensor([17.0378], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9071], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7967], device='cuda:0')\n",
            " 92% 5732/6237 [1:37:35<09:01,  1.07s/it]losses: tensor([0.0227], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-303.7387], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-557.7385], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-308.2103], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-524.4908], device='cuda:0')\n",
            "logits: tensor([37.7193], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4472], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3248], device='cuda:0')\n",
            " 92% 5733/6237 [1:37:37<10:02,  1.19s/it]losses: tensor([0.0420], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-437.1694], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.4423], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-446.1784], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.9579], device='cuda:0')\n",
            "logits: tensor([31.4933], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9009], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2484], device='cuda:0')\n",
            " 92% 5734/6237 [1:37:37<08:43,  1.04s/it]losses: tensor([0.0489], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-373.9380], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-517.8508], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-385.9689], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-499.9526], device='cuda:0')\n",
            "logits: tensor([29.9291], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2031], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7898], device='cuda:0')\n",
            " 92% 5735/6237 [1:37:39<09:44,  1.16s/it]losses: tensor([0.0044], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-333.9770], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-453.2861], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-345.9924], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.9780], device='cuda:0')\n",
            "logits: tensor([54.3235], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2015], device='cuda:0')\n",
            "generated_rewards: tensor([-4.2308], device='cuda:0')\n",
            " 92% 5736/6237 [1:37:39<08:03,  1.04it/s]losses: tensor([0.0451], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-104.2695], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-382.0387], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-113.7319], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-360.7401], device='cuda:0')\n",
            "logits: tensor([30.7610], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9462], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1299], device='cuda:0')\n",
            " 92% 5737/6237 [1:37:40<08:09,  1.02it/s]losses: tensor([0.1017], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-193.4366], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.9781], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-194.9779], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.1745], device='cuda:0')\n",
            "logits: tensor([22.3450], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1541], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0804], device='cuda:0')\n",
            " 92% 5738/6237 [1:37:42<08:47,  1.06s/it]losses: tensor([0.4846], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-453.0843], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-309.4991], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-452.3372], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-304.0276], device='cuda:0')\n",
            "logits: tensor([4.7244], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0747], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5471], device='cuda:0')\n",
            " 92% 5739/6237 [1:37:42<08:09,  1.02it/s]losses: tensor([0.0391], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-319.4913], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-512.6161], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-327.5013], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-488.4044], device='cuda:0')\n",
            "logits: tensor([32.2218], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8010], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4212], device='cuda:0')\n",
            "{'loss': 0.0991, 'learning_rate': 4.534117227863887e-08, 'rewards/real': 0.5890149474143982, 'rewards/generated': -2.3481125831604004, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9371275901794434, 'logps/generated': -455.89532470703125, 'logps/real': -406.8468322753906, 'logits/generated': -1.2736846208572388, 'logits/real': -1.291323184967041, 'epoch': 2.76}\n",
            " 92% 5740/6237 [1:37:44<08:59,  1.09s/it]losses: tensor([0.0333], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-266.7662], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-533.2100], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-259.3040], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-491.9003], device='cuda:0')\n",
            "logits: tensor([33.8475], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7462], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1310], device='cuda:0')\n",
            " 92% 5741/6237 [1:37:45<10:15,  1.24s/it]losses: tensor([0.0700], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-615.5701], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.7042], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-618.0378], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.9364], device='cuda:0')\n",
            "logits: tensor([26.2355], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2468], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3768], device='cuda:0')\n",
            " 92% 5742/6237 [1:37:46<10:11,  1.24s/it]losses: tensor([0.3501], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-686.0356], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-332.6774], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-685.0709], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-323.0193], device='cuda:0')\n",
            "logits: tensor([8.6934], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0965], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9658], device='cuda:0')\n",
            " 92% 5743/6237 [1:37:48<10:07,  1.23s/it]losses: tensor([0.0347], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-189.8873], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.0421], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-195.4310], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.1636], device='cuda:0')\n",
            "logits: tensor([33.4221], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5544], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7878], device='cuda:0')\n",
            " 92% 5744/6237 [1:37:49<09:46,  1.19s/it]losses: tensor([0.1328], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-162.4492], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-313.8957], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-170.2488], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-302.1808], device='cuda:0')\n",
            "logits: tensor([19.5144], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7800], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1715], device='cuda:0')\n",
            " 92% 5745/6237 [1:37:49<08:16,  1.01s/it]losses: tensor([0.1221], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-382.1627], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-339.1199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-390.3009], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-326.8476], device='cuda:0')\n",
            "logits: tensor([20.4106], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8138], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2272], device='cuda:0')\n",
            " 92% 5746/6237 [1:37:50<07:55,  1.03it/s]losses: tensor([0.0455], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-326.3145], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.3516], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-328.3217], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.6844], device='cuda:0')\n",
            "logits: tensor([30.6744], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2007], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8667], device='cuda:0')\n",
            " 92% 5747/6237 [1:37:51<07:37,  1.07it/s]losses: tensor([0.1492], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-869.8731], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.4908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-858.4268], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.7751], device='cuda:0')\n",
            "logits: tensor([18.2693], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1446], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9716], device='cuda:0')\n",
            " 92% 5748/6237 [1:37:52<08:17,  1.02s/it]losses: tensor([1.0193e-07], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-171.5376], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-3880.8284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.2455], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-3724.5466], device='cuda:0')\n",
            "logits: tensor([160.9895], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4708], device='cuda:0')\n",
            "generated_rewards: tensor([-15.6282], device='cuda:0')\n",
            " 92% 5749/6237 [1:37:53<07:41,  1.06it/s]losses: tensor([0.1626], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-901.4651], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-394.7106], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-902.4100], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.3123], device='cuda:0')\n",
            "logits: tensor([17.3432], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0945], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6398], device='cuda:0')\n",
            "{'loss': 0.11, 'learning_rate': 4.445038303937288e-08, 'rewards/real': 0.11736084520816803, 'rewards/generated': -3.5766403675079346, 'rewards/accuracies': 1.0, 'rewards/margins': 3.694000720977783, 'logps/generated': -765.2030029296875, 'logps/real': -457.20611572265625, 'logits/generated': -1.008184790611267, 'logits/real': -0.9894625544548035, 'epoch': 2.77}\n",
            " 92% 5750/6237 [1:37:54<08:18,  1.02s/it]losses: tensor([0.0511], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-286.9808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.8889], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-282.4131], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.8447], device='cuda:0')\n",
            "logits: tensor([29.4765], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4568], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4044], device='cuda:0')\n",
            " 92% 5751/6237 [1:37:56<09:23,  1.16s/it]losses: tensor([0.1383], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1062.7836], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.7801], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1058.9021], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-418.8164], device='cuda:0')\n",
            "logits: tensor([19.0823], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3881], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2964], device='cuda:0')\n",
            " 92% 5752/6237 [1:37:57<09:42,  1.20s/it]losses: tensor([0.0708], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-416.5998], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-492.8116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-411.6354], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-461.7197], device='cuda:0')\n",
            "logits: tensor([26.1276], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4964], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1092], device='cuda:0')\n",
            " 92% 5753/6237 [1:37:58<08:24,  1.04s/it]losses: tensor([0.1430], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-933.4120], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-515.2261], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-925.6564], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-488.7416], device='cuda:0')\n",
            "logits: tensor([18.7289], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7756], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6485], device='cuda:0')\n",
            " 92% 5754/6237 [1:37:59<08:39,  1.08s/it]losses: tensor([0.0604], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-180.9270], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-497.2058], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-179.7704], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.2900], device='cuda:0')\n",
            "logits: tensor([27.7592], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1157], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8916], device='cuda:0')\n",
            " 92% 5755/6237 [1:38:01<10:18,  1.28s/it]losses: tensor([0.0615], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-930.5341], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.0776], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-932.6877], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.6492], device='cuda:0')\n",
            "logits: tensor([27.5820], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2154], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5428], device='cuda:0')\n",
            " 92% 5756/6237 [1:38:02<09:51,  1.23s/it]losses: tensor([0.2136], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-570.4232], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-538.6525], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-561.3087], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-515.1894], device='cuda:0')\n",
            "logits: tensor([14.3486], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9114], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3463], device='cuda:0')\n",
            " 92% 5757/6237 [1:38:02<08:15,  1.03s/it]losses: tensor([0.0123], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-102.8556], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.0609], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-112.4716], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-461.7753], device='cuda:0')\n",
            "logits: tensor([43.9016], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9616], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4286], device='cuda:0')\n",
            " 92% 5758/6237 [1:38:04<08:39,  1.08s/it]losses: tensor([0.0992], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-414.2426], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.1934], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-415.5716], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.9160], device='cuda:0')\n",
            "logits: tensor([22.6064], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1329], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1277], device='cuda:0')\n",
            " 92% 5759/6237 [1:38:04<07:43,  1.03it/s]losses: tensor([0.0491], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-105.2876], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.7840], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-106.8605], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.4692], device='cuda:0')\n",
            "logits: tensor([29.8877], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1573], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8315], device='cuda:0')\n",
            "{'loss': 0.0899, 'learning_rate': 4.35595938001069e-08, 'rewards/real': -0.16768860816955566, 'rewards/generated': -2.762695074081421, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5950064659118652, 'logps/generated': -482.36810302734375, 'logps/real': -500.4046325683594, 'logits/generated': -1.2206891775131226, 'logits/real': -1.1143429279327393, 'epoch': 2.77}\n",
            " 92% 5760/6237 [1:38:06<08:29,  1.07s/it]losses: tensor([0.0070], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-306.9471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.2377], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-303.8285], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.5934], device='cuda:0')\n",
            "logits: tensor([49.5257], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3119], device='cuda:0')\n",
            "generated_rewards: tensor([-5.2644], device='cuda:0')\n",
            " 92% 5761/6237 [1:38:07<09:24,  1.19s/it]losses: tensor([0.0971], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-500.0337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.8204], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-502.8989], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-419.8575], device='cuda:0')\n",
            "logits: tensor([22.8281], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2865], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9963], device='cuda:0')\n",
            " 92% 5762/6237 [1:38:08<07:57,  1.01s/it]losses: tensor([0.0306], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-379.5109], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.6700], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-386.0920], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-356.5328], device='cuda:0')\n",
            "logits: tensor([34.7184], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6581], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8137], device='cuda:0')\n",
            " 92% 5763/6237 [1:38:08<07:13,  1.09it/s]losses: tensor([0.0360], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-244.7400], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-426.8664], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-242.7437], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.7973], device='cuda:0')\n",
            "logits: tensor([33.0728], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1996], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5069], device='cuda:0')\n",
            " 92% 5764/6237 [1:38:09<06:19,  1.25it/s]losses: tensor([0.3008], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-941.6387], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-362.4662], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-943.4518], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.8075], device='cuda:0')\n",
            "logits: tensor([10.4718], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1813], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8659], device='cuda:0')\n",
            " 92% 5765/6237 [1:38:10<07:24,  1.06it/s]losses: tensor([0.0400], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-463.5787], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.5240], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-474.7937], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-382.7623], device='cuda:0')\n",
            "logits: tensor([31.9768], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1215], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0762], device='cuda:0')\n",
            " 92% 5766/6237 [1:38:11<08:01,  1.02s/it]losses: tensor([0.1363], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1136.6145], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-380.6289], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1134.3611], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-359.1388], device='cuda:0')\n",
            "logits: tensor([19.2367], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2253], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1490], device='cuda:0')\n",
            " 92% 5767/6237 [1:38:13<09:57,  1.27s/it]losses: tensor([0.0068], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-94.0598], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.7437], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-98.3620], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.2193], device='cuda:0')\n",
            "logits: tensor([49.8265], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4302], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5524], device='cuda:0')\n",
            " 92% 5768/6237 [1:38:14<09:34,  1.23s/it]losses: tensor([0.0906], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-557.4879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.7449], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-569.5909], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.2962], device='cuda:0')\n",
            "logits: tensor([23.5517], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2103], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1449], device='cuda:0')\n",
            " 92% 5769/6237 [1:38:15<08:44,  1.12s/it]losses: tensor([0.0655], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-289.8966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.6735], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-275.0238], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.8680], device='cuda:0')\n",
            "logits: tensor([26.9326], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4873], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1805], device='cuda:0')\n",
            "{'loss': 0.0811, 'learning_rate': 4.26688045608409e-08, 'rewards/real': 0.1663835048675537, 'rewards/generated': -2.8550267219543457, 'rewards/accuracies': 1.0, 'rewards/margins': 3.0214104652404785, 'logps/generated': -418.3375549316406, 'logps/real': -491.4508361816406, 'logits/generated': -1.4569947719573975, 'logits/real': -1.4195469617843628, 'epoch': 2.78}\n",
            " 93% 5770/6237 [1:38:16<07:53,  1.01s/it]losses: tensor([0.2222], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-272.9022], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-241.4978], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-279.7001], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-234.3847], device='cuda:0')\n",
            "logits: tensor([13.9111], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6798], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7113], device='cuda:0')\n",
            " 93% 5771/6237 [1:38:17<06:53,  1.13it/s]losses: tensor([0.0282], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-222.9435], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.1096], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-221.9950], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.6263], device='cuda:0')\n",
            "logits: tensor([35.5349], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0948], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6483], device='cuda:0')\n",
            " 93% 5772/6237 [1:38:17<05:44,  1.35it/s]losses: tensor([0.0195], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-226.6702], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-354.3756], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-231.3835], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-319.7885], device='cuda:0')\n",
            "logits: tensor([39.3004], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4713], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4587], device='cuda:0')\n",
            " 93% 5773/6237 [1:38:18<05:52,  1.32it/s]losses: tensor([0.0070], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-259.1332], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-528.4351], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-256.4841], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.1512], device='cuda:0')\n",
            "logits: tensor([49.6347], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2649], device='cuda:0')\n",
            "generated_rewards: tensor([-5.2284], device='cuda:0')\n",
            " 93% 5774/6237 [1:38:20<08:20,  1.08s/it]losses: tensor([0.2609], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-533.0942], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.3273], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.9371], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.0677], device='cuda:0')\n",
            "logits: tensor([12.1024], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1157], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3260], device='cuda:0')\n",
            " 93% 5775/6237 [1:38:20<07:58,  1.04s/it]losses: tensor([0.3892], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-718.4386], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-409.7182], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-706.5730], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.4257], device='cuda:0')\n",
            "logits: tensor([7.4269], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1866], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9293], device='cuda:0')\n",
            " 93% 5776/6237 [1:38:22<08:23,  1.09s/it]losses: tensor([0.0099], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-189.7354], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-591.7719], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-207.3970], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-563.3313], device='cuda:0')\n",
            "logits: tensor([46.1021], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7662], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8441], device='cuda:0')\n",
            " 93% 5777/6237 [1:38:23<09:16,  1.21s/it]losses: tensor([0.0685], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-340.8499], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-477.8098], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-340.9544], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.4542], device='cuda:0')\n",
            "logits: tensor([26.4602], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0105], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6356], device='cuda:0')\n",
            " 93% 5778/6237 [1:38:25<10:30,  1.37s/it]losses: tensor([0.0065], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-261.0703], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-582.9886], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-276.2999], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-547.8224], device='cuda:0')\n",
            "logits: tensor([50.3959], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5230], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5166], device='cuda:0')\n",
            " 93% 5779/6237 [1:38:26<10:22,  1.36s/it]losses: tensor([0.1052], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-566.0137], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.0829], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-570.1168], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.1961], device='cuda:0')\n",
            "logits: tensor([21.9899], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4103], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7887], device='cuda:0')\n",
            "{'loss': 0.1117, 'learning_rate': 4.1778015321574914e-08, 'rewards/real': 0.21989718079566956, 'rewards/generated': -2.8086867332458496, 'rewards/accuracies': 1.0, 'rewards/margins': 3.0285840034484863, 'logps/generated': -447.51171875, 'logps/real': -359.0850830078125, 'logits/generated': -1.1936110258102417, 'logits/real': -1.355238437652588, 'epoch': 2.78}\n",
            " 93% 5780/6237 [1:38:27<09:20,  1.23s/it]losses: tensor([0.0117], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-389.5789], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-598.4531], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-385.1016], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-549.5637], device='cuda:0')\n",
            "logits: tensor([44.4121], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4477], device='cuda:0')\n",
            "generated_rewards: tensor([-4.8889], device='cuda:0')\n",
            " 93% 5781/6237 [1:38:29<09:53,  1.30s/it]losses: tensor([0.6361], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-902.6360], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.6069], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-890.9215], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.7179], device='cuda:0')\n",
            "logits: tensor([1.1745], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1714], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2889], device='cuda:0')\n",
            " 93% 5782/6237 [1:38:30<09:56,  1.31s/it]losses: tensor([0.3872], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-923.0420], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.0606], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-904.9682], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.4983], device='cuda:0')\n",
            "logits: tensor([7.4886], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.8074], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5562], device='cuda:0')\n",
            " 93% 5783/6237 [1:38:32<10:42,  1.41s/it]losses: tensor([0.2172], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-472.1742], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.8890], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-455.3260], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.8748], device='cuda:0')\n",
            "logits: tensor([14.1660], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.6848], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1014], device='cuda:0')\n",
            " 93% 5784/6237 [1:38:32<08:41,  1.15s/it]losses: tensor([0.0077], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-659.4445], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.0107], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-652.4597], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.4229], device='cuda:0')\n",
            "logits: tensor([48.6031], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6985], device='cuda:0')\n",
            "generated_rewards: tensor([-5.5588], device='cuda:0')\n",
            " 93% 5785/6237 [1:38:33<07:38,  1.01s/it]losses: tensor([0.0362], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-98.0119], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-479.5596], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-95.6546], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.2019], device='cuda:0')\n",
            "logits: tensor([33.0005], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2357], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5358], device='cuda:0')\n",
            " 93% 5786/6237 [1:38:34<07:38,  1.02s/it]losses: tensor([0.0612], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-118.7581], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-632.5752], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-135.8511], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-622.0353], device='cuda:0')\n",
            "logits: tensor([27.6329], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7093], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0540], device='cuda:0')\n",
            " 93% 5787/6237 [1:38:35<08:40,  1.16s/it]losses: tensor([0.0819], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-595.5605], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-526.5503], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-586.9022], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-493.2816], device='cuda:0')\n",
            "logits: tensor([24.6104], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8658], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3269], device='cuda:0')\n",
            " 93% 5788/6237 [1:38:36<08:05,  1.08s/it]losses: tensor([0.1315], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1070.2195], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.8810], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1059.6160], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.6583], device='cuda:0')\n",
            "logits: tensor([19.6191], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0604], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0223], device='cuda:0')\n",
            " 93% 5789/6237 [1:38:38<08:30,  1.14s/it]losses: tensor([0.0039], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-161.1891], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-517.8253], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-170.6876], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.9557], device='cuda:0')\n",
            "logits: tensor([55.3682], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9499], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5870], device='cuda:0')\n",
            "{'loss': 0.1575, 'learning_rate': 4.088722608230892e-08, 'rewards/real': -0.5312608480453491, 'rewards/generated': -3.292013168334961, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7607522010803223, 'logps/generated': -500.441162109375, 'logps/real': -539.0614624023438, 'logits/generated': -1.4509843587875366, 'logits/real': -1.5568065643310547, 'epoch': 2.78}\n",
            " 93% 5790/6237 [1:38:39<08:02,  1.08s/it]losses: tensor([0.1596], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-734.6279], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.3643], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-728.4220], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.6171], device='cuda:0')\n",
            "logits: tensor([17.5414], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6206], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3747], device='cuda:0')\n",
            " 93% 5791/6237 [1:38:40<08:06,  1.09s/it]losses: tensor([0.0667], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-284.2261], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.7137], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-279.8646], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.6136], device='cuda:0')\n",
            "logits: tensor([26.7386], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4361], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1100], device='cuda:0')\n",
            " 93% 5792/6237 [1:38:40<07:11,  1.03it/s]losses: tensor([0.0263], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-203.7210], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.4320], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-195.0992], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.5436], device='cuda:0')\n",
            "logits: tensor([36.2666], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8622], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4888], device='cuda:0')\n",
            " 93% 5793/6237 [1:38:41<06:17,  1.18it/s]losses: tensor([0.1267], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-333.1852], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.0495], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-321.6139], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.4624], device='cuda:0')\n",
            "logits: tensor([20.0158], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1571], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1587], device='cuda:0')\n",
            " 93% 5794/6237 [1:38:42<06:46,  1.09it/s]losses: tensor([0.1203], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-892.1065], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-445.4908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-881.1090], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.9206], device='cuda:0')\n",
            "logits: tensor([20.5727], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0997], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1570], device='cuda:0')\n",
            " 93% 5795/6237 [1:38:43<07:01,  1.05it/s]losses: tensor([0.0860], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1250.3124], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-442.6772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1245.0167], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.2831], device='cuda:0')\n",
            "logits: tensor([24.0984], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5296], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9394], device='cuda:0')\n",
            " 93% 5796/6237 [1:38:45<08:59,  1.22s/it]losses: tensor([0.2129], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-166.6366], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-201.1568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-175.2865], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-195.4200], device='cuda:0')\n",
            "logits: tensor([14.3867], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8650], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5737], device='cuda:0')\n",
            " 93% 5797/6237 [1:38:46<09:16,  1.26s/it]losses: tensor([0.1959], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-636.9580], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.3392], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-621.1001], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-472.1746], device='cuda:0')\n",
            "logits: tensor([15.3067], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5858], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1165], device='cuda:0')\n",
            " 93% 5798/6237 [1:38:47<08:39,  1.18s/it]losses: tensor([0.0179], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-179.3665], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-523.4342], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-181.9685], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-485.9219], device='cuda:0')\n",
            "logits: tensor([40.1143], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2602], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7512], device='cuda:0')\n",
            " 93% 5799/6237 [1:38:48<07:50,  1.07s/it]losses: tensor([0.0747], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-247.9966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.1879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-248.2175], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.8400], device='cuda:0')\n",
            "logits: tensor([25.5688], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0221], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5348], device='cuda:0')\n",
            "{'loss': 0.1087, 'learning_rate': 3.9996436843042935e-08, 'rewards/real': -0.514386773109436, 'rewards/generated': -2.9204869270324707, 'rewards/accuracies': 1.0, 'rewards/margins': 2.406100034713745, 'logps/generated': -433.6845703125, 'logps/real': -492.9136657714844, 'logits/generated': -1.0099729299545288, 'logits/real': -1.1611982583999634, 'epoch': 2.79}\n",
            " 93% 5800/6237 [1:38:50<08:44,  1.20s/it]losses: tensor([0.0052], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-322.9492], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.5322], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-338.8555], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-419.7871], device='cuda:0')\n",
            "logits: tensor([52.6513], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5906], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6745], device='cuda:0')\n",
            " 93% 5801/6237 [1:38:50<07:12,  1.01it/s]losses: tensor([0.1591], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-250.7951], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.8434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-252.9335], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-358.4083], device='cuda:0')\n",
            "logits: tensor([17.5735], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2138], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5435], device='cuda:0')\n",
            " 93% 5802/6237 [1:38:51<06:06,  1.19it/s]losses: tensor([0.0289], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-929.7799], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.0633], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-925.7823], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.7642], device='cuda:0')\n",
            "logits: tensor([35.3015], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3998], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9299], device='cuda:0')\n",
            " 93% 5803/6237 [1:38:52<06:38,  1.09it/s]losses: tensor([0.0291], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-105.6800], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-403.2211], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-113.4276], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-375.7273], device='cuda:0')\n",
            "logits: tensor([35.2414], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7748], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7494], device='cuda:0')\n",
            " 93% 5804/6237 [1:38:52<06:21,  1.13it/s]losses: tensor([0.1961], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-712.3894], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.3891], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-705.8282], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.5306], device='cuda:0')\n",
            "logits: tensor([15.2973], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6561], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1859], device='cuda:0')\n",
            " 93% 5805/6237 [1:38:53<06:11,  1.16it/s]losses: tensor([0.2937], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-402.2414], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.0641], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-397.4030], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.4802], device='cuda:0')\n",
            "logits: tensor([10.7456], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4838], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5584], device='cuda:0')\n",
            " 93% 5806/6237 [1:38:54<05:38,  1.28it/s]losses: tensor([0.0336], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-472.7717], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-479.0069], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-476.0917], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-448.5484], device='cuda:0')\n",
            "logits: tensor([33.7785], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3320], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0458], device='cuda:0')\n",
            " 93% 5807/6237 [1:38:55<07:15,  1.01s/it]losses: tensor([0.0859], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-422.2149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.7184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-417.4584], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.8465], device='cuda:0')\n",
            "logits: tensor([24.1155], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4756], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8872], device='cuda:0')\n",
            " 93% 5808/6237 [1:38:56<06:21,  1.12it/s]losses: tensor([0.0213], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-612.0398], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-490.8863], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-614.0466], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.4892], device='cuda:0')\n",
            "logits: tensor([38.4040], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2007], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6397], device='cuda:0')\n",
            " 93% 5809/6237 [1:38:57<06:02,  1.18it/s]losses: tensor([0.0268], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-254.8041], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-534.4095], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-259.4235], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-502.9821], device='cuda:0')\n",
            "logits: tensor([36.0468], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4619], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1427], device='cuda:0')\n",
            "{'loss': 0.088, 'learning_rate': 3.9105647603776946e-08, 'rewards/real': 0.15584921836853027, 'rewards/generated': -2.835704803466797, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9915542602539062, 'logps/generated': -456.013427734375, 'logps/real': -448.5665588378906, 'logits/generated': -1.0464136600494385, 'logits/real': -1.0033185482025146, 'epoch': 2.79}\n",
            " 93% 5810/6237 [1:38:57<05:39,  1.26it/s]losses: tensor([0.0561], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-682.0533], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.6180], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-680.8770], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.9214], device='cuda:0')\n",
            "logits: tensor([28.5203], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1176], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9697], device='cuda:0')\n",
            " 93% 5811/6237 [1:38:58<05:44,  1.24it/s]losses: tensor([0.0369], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-91.3149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-505.4721], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-101.3276], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.6777], device='cuda:0')\n",
            "logits: tensor([32.8070], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0013], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2794], device='cuda:0')\n",
            " 93% 5812/6237 [1:38:59<04:51,  1.46it/s]losses: tensor([0.3738], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1278.7356], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.0339], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1277.3257], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-413.7102], device='cuda:0')\n",
            "logits: tensor([7.9138], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1410], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9324], device='cuda:0')\n",
            " 93% 5813/6237 [1:39:00<07:05,  1.00s/it]losses: tensor([0.0577], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-274.9866], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-325.4225], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-284.7933], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-306.9985], device='cuda:0')\n",
            "logits: tensor([28.2306], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9807], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8424], device='cuda:0')\n",
            " 93% 5814/6237 [1:39:01<06:13,  1.13it/s]losses: tensor([0.0630], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-289.2198], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.8349], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-288.2238], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.5131], device='cuda:0')\n",
            "logits: tensor([27.3259], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0996], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8322], device='cuda:0')\n",
            " 93% 5815/6237 [1:39:02<05:56,  1.18it/s]losses: tensor([0.0083], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-195.7200], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-598.8425], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-198.6143], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-553.9133], device='cuda:0')\n",
            "logits: tensor([47.8235], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2894], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4929], device='cuda:0')\n",
            " 93% 5816/6237 [1:39:02<05:35,  1.26it/s]losses: tensor([0.0073], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-325.5649], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-885.0159], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-332.6142], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-842.9473], device='cuda:0')\n",
            "logits: tensor([49.1179], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7049], device='cuda:0')\n",
            "generated_rewards: tensor([-4.2069], device='cuda:0')\n",
            " 93% 5817/6237 [1:39:04<06:29,  1.08it/s]losses: tensor([0.0022], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-115.5976], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.4376], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-122.3358], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.7768], device='cuda:0')\n",
            "logits: tensor([61.3989], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6738], device='cuda:0')\n",
            "generated_rewards: tensor([-5.4661], device='cuda:0')\n",
            " 93% 5818/6237 [1:39:04<05:58,  1.17it/s]losses: tensor([0.2337], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-406.4530], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-507.3775], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-403.2584], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-490.8352], device='cuda:0')\n",
            "logits: tensor([13.3477], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3195], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6542], device='cuda:0')\n",
            " 93% 5819/6237 [1:39:05<05:25,  1.28it/s]losses: tensor([0.0304], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1489.8077], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-511.4601], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1493.8049], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.6857], device='cuda:0')\n",
            "logits: tensor([34.7715], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3997], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0774], device='cuda:0')\n",
            "{'loss': 0.0869, 'learning_rate': 3.821485836451095e-08, 'rewards/real': 0.33721262216567993, 'rewards/generated': -2.9753577709198, 'rewards/accuracies': 1.0, 'rewards/margins': 3.312570571899414, 'logps/generated': -518.1514892578125, 'logps/real': -514.9453735351562, 'logits/generated': -1.5142183303833008, 'logits/real': -1.3878742456436157, 'epoch': 2.8}\n",
            " 93% 5820/6237 [1:39:06<06:37,  1.05it/s]losses: tensor([0.1646], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-630.9167], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.7119], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-635.0682], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.6542], device='cuda:0')\n",
            "logits: tensor([17.2093], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4151], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3058], device='cuda:0')\n",
            " 93% 5821/6237 [1:39:07<06:30,  1.06it/s]losses: tensor([0.1099], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-979.7274], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.7957], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-967.2681], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.8134], device='cuda:0')\n",
            "logits: tensor([21.5229], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.2459], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3982], device='cuda:0')\n",
            " 93% 5822/6237 [1:39:08<06:40,  1.04it/s]losses: tensor([0.3899], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1416.2502], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.3821], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1403.1898], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.9151], device='cuda:0')\n",
            "logits: tensor([7.4066], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3060], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0467], device='cuda:0')\n",
            " 93% 5823/6237 [1:39:10<08:09,  1.18s/it]losses: tensor([0.0111], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-211.7813], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.7730], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-205.8061], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.8280], device='cuda:0')\n",
            "logits: tensor([44.9698], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5975], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0945], device='cuda:0')\n",
            " 93% 5824/6237 [1:39:11<07:05,  1.03s/it]losses: tensor([0.0736], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-490.7812], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-492.1270], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-477.3175], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.9384], device='cuda:0')\n",
            "logits: tensor([25.7249], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3464], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9189], device='cuda:0')\n",
            " 93% 5825/6237 [1:39:11<06:11,  1.11it/s]losses: tensor([0.0037], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-126.9002], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-446.3771], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-148.7560], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.2687], device='cuda:0')\n",
            "logits: tensor([55.9643], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.1856], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4108], device='cuda:0')\n",
            " 93% 5826/6237 [1:39:13<07:20,  1.07s/it]losses: tensor([0.0190], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-119.5217], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.4041], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-139.4068], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.7443], device='cuda:0')\n",
            "logits: tensor([39.5450], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.9885], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9660], device='cuda:0')\n",
            " 93% 5827/6237 [1:39:13<06:11,  1.10it/s]losses: tensor([0.0167], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-462.7452], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-523.7477], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-448.7755], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.9547], device='cuda:0')\n",
            "logits: tensor([40.8233], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3970], device='cuda:0')\n",
            "generated_rewards: tensor([-5.4793], device='cuda:0')\n",
            " 93% 5828/6237 [1:39:14<05:22,  1.27it/s]losses: tensor([0.0341], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-351.7961], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.8159], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-357.1158], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.5193], device='cuda:0')\n",
            "logits: tensor([33.6164], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5320], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8297], device='cuda:0')\n",
            " 93% 5829/6237 [1:39:14<05:17,  1.29it/s]losses: tensor([0.3154], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1011.5735], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.1868], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1008.9753], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.6690], device='cuda:0')\n",
            "logits: tensor([9.9197], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2598], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2518], device='cuda:0')\n",
            "{'loss': 0.1138, 'learning_rate': 3.732406912524497e-08, 'rewards/real': -0.10314370691776276, 'rewards/generated': -3.070164442062378, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9670205116271973, 'logps/generated': -451.93212890625, 'logps/real': -580.1993408203125, 'logits/generated': -1.3605321645736694, 'logits/real': -1.3333467245101929, 'epoch': 2.8}\n",
            " 93% 5830/6237 [1:39:16<07:25,  1.10s/it]losses: tensor([0.0356], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-631.6569], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.6497], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-644.5883], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.4169], device='cuda:0')\n",
            "logits: tensor([33.1642], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2931], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0233], device='cuda:0')\n",
            " 93% 5831/6237 [1:39:17<06:19,  1.07it/s]losses: tensor([0.0559], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1068.7031], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-498.4616], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1075.3914], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.5858], device='cuda:0')\n",
            "logits: tensor([28.5641], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6688], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1876], device='cuda:0')\n",
            " 94% 5832/6237 [1:39:18<07:05,  1.05s/it]losses: tensor([0.3381], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1477.3669], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-387.8351], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1472.6792], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-374.0405], device='cuda:0')\n",
            "logits: tensor([9.1069], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4688], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3795], device='cuda:0')\n",
            " 94% 5833/6237 [1:39:20<07:57,  1.18s/it]losses: tensor([0.1182], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-409.8420], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-506.2986], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-402.7279], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-478.4290], device='cuda:0')\n",
            "logits: tensor([20.7555], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7114], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7870], device='cuda:0')\n",
            " 94% 5834/6237 [1:39:20<06:33,  1.02it/s]losses: tensor([0.0766], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-717.4598], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.5023], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-734.6677], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.3994], device='cuda:0')\n",
            "logits: tensor([25.3107], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7208], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8103], device='cuda:0')\n",
            " 94% 5835/6237 [1:39:21<06:38,  1.01it/s]losses: tensor([0.0331], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-107.6385], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.0044], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-113.1835], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.6462], device='cuda:0')\n",
            "logits: tensor([33.9031], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5545], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8358], device='cuda:0')\n",
            " 94% 5836/6237 [1:39:22<06:35,  1.01it/s]losses: tensor([0.0189], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-473.5718], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.0359], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-484.9982], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.8952], device='cuda:0')\n",
            "logits: tensor([39.5671], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1426], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8141], device='cuda:0')\n",
            " 94% 5837/6237 [1:39:23<05:55,  1.13it/s]losses: tensor([0.0027], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-245.6526], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-460.4306], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-247.6427], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.4410], device='cuda:0')\n",
            "logits: tensor([58.9797], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1990], device='cuda:0')\n",
            "generated_rewards: tensor([-5.6990], device='cuda:0')\n",
            " 94% 5838/6237 [1:39:24<06:10,  1.08it/s]losses: tensor([0.0036], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-121.5669], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-558.8966], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-120.7018], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-501.7580], device='cuda:0')\n",
            "logits: tensor([56.2735], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0865], device='cuda:0')\n",
            "generated_rewards: tensor([-5.7139], device='cuda:0')\n",
            " 94% 5839/6237 [1:39:25<06:30,  1.02it/s]losses: tensor([0.1030], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-849.9626], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-522.8371], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-846.2819], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-496.9485], device='cuda:0')\n",
            "logits: tensor([22.2078], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3681], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5889], device='cuda:0')\n",
            "{'loss': 0.0786, 'learning_rate': 3.643327988597897e-08, 'rewards/real': 0.39441192150115967, 'rewards/generated': -2.8839142322540283, 'rewards/accuracies': 1.0, 'rewards/margins': 3.2783265113830566, 'logps/generated': -467.09521484375, 'logps/real': -610.3421630859375, 'logits/generated': -1.3456041812896729, 'logits/real': -1.3385088443756104, 'epoch': 2.81}\n",
            " 94% 5840/6237 [1:39:26<06:57,  1.05s/it]losses: tensor([8.0265e-07], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-136.5730], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1941.4231], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-152.6490], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1817.1455], device='cuda:0')\n",
            "logits: tensor([140.3535], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.6076], device='cuda:0')\n",
            "generated_rewards: tensor([-12.4278], device='cuda:0')\n",
            " 94% 5841/6237 [1:39:27<06:54,  1.05s/it]losses: tensor([0.1074], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-180.1931], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-506.4102], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-189.6451], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-494.0936], device='cuda:0')\n",
            "logits: tensor([21.7686], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9452], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2317], device='cuda:0')\n",
            " 94% 5842/6237 [1:39:28<06:16,  1.05it/s]losses: tensor([0.4844], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-685.2814], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-366.9380], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-673.5767], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-350.5046], device='cuda:0')\n",
            "logits: tensor([4.7288], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1705], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6433], device='cuda:0')\n",
            " 94% 5843/6237 [1:39:29<06:33,  1.00it/s]losses: tensor([0.3271], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-301.4263], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-545.3053], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-298.0980], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-532.4835], device='cuda:0')\n",
            "logits: tensor([9.4935], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3328], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2822], device='cuda:0')\n",
            " 94% 5844/6237 [1:39:30<06:30,  1.01it/s]losses: tensor([0.1544], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-518.9827], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.8658], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-515.7321], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.7148], device='cuda:0')\n",
            "logits: tensor([17.9005], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3251], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1151], device='cuda:0')\n",
            " 94% 5845/6237 [1:39:31<05:46,  1.13it/s]losses: tensor([0.1809], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-614.0349], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-399.8011], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-621.0615], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.6450], device='cuda:0')\n",
            "logits: tensor([16.1827], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7027], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9156], device='cuda:0')\n",
            " 94% 5846/6237 [1:39:31<05:31,  1.18it/s]losses: tensor([0.0262], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-434.6642], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-495.5879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-441.0734], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.7034], device='cuda:0')\n",
            "logits: tensor([36.2936], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6409], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9884], device='cuda:0')\n",
            " 94% 5847/6237 [1:39:32<04:50,  1.34it/s]losses: tensor([0.1718], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-188.3299], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.0278], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-191.3284], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.2809], device='cuda:0')\n",
            "logits: tensor([16.7453], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2998], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3747], device='cuda:0')\n",
            " 94% 5848/6237 [1:39:32<04:21,  1.49it/s]losses: tensor([0.1168], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1126.1506], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-547.1261], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1112.0674], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-512.1564], device='cuda:0')\n",
            "logits: tensor([20.8865], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4083], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4970], device='cuda:0')\n",
            " 94% 5849/6237 [1:39:34<05:50,  1.11it/s]losses: tensor([0.0377], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1111.9760], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.3719], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1117.9060], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.7230], device='cuda:0')\n",
            "logits: tensor([32.5790], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5930], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6649], device='cuda:0')\n",
            "{'loss': 0.1607, 'learning_rate': 3.554249064671298e-08, 'rewards/real': 0.15525375306606293, 'rewards/generated': -3.014066219329834, 'rewards/accuracies': 1.0, 'rewards/margins': 3.1693203449249268, 'logps/generated': -608.3857421875, 'logps/real': -529.7611694335938, 'logits/generated': -1.7460012435913086, 'logits/real': -1.7769701480865479, 'epoch': 2.81}\n",
            " 94% 5850/6237 [1:39:35<06:39,  1.03s/it]losses: tensor([0.0495], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-568.6792], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.9770], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-558.4304], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.9109], device='cuda:0')\n",
            "logits: tensor([29.8173], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0249], device='cuda:0')\n",
            "generated_rewards: tensor([-4.0066], device='cuda:0')\n",
            " 94% 5851/6237 [1:39:36<06:01,  1.07it/s]losses: tensor([0.9161], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-743.4357], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.2539], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-725.8202], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.6901], device='cuda:0')\n",
            "logits: tensor([-4.0517], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7615], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3564], device='cuda:0')\n",
            " 94% 5852/6237 [1:39:37<06:51,  1.07s/it]losses: tensor([0.0045], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-129.6718], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.9341], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-126.7036], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.0107], device='cuda:0')\n",
            "logits: tensor([53.9552], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2968], device='cuda:0')\n",
            "generated_rewards: tensor([-5.6923], device='cuda:0')\n",
            " 94% 5853/6237 [1:39:38<05:59,  1.07it/s]losses: tensor([0.3344], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-904.9889], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.4028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-896.9460], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.1242], device='cuda:0')\n",
            "logits: tensor([9.2357], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8043], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7279], device='cuda:0')\n",
            " 94% 5854/6237 [1:39:39<06:31,  1.02s/it]losses: tensor([0.0445], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-621.9880], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.7157], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-619.0924], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-428.9213], device='cuda:0')\n",
            "logits: tensor([30.8988], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2896], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3794], device='cuda:0')\n",
            " 94% 5855/6237 [1:39:40<06:19,  1.01it/s]losses: tensor([0.1458], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.0118], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.9963], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-474.3073], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-450.7753], device='cuda:0')\n",
            "logits: tensor([18.5165], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0296], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8221], device='cuda:0')\n",
            " 94% 5856/6237 [1:39:41<05:31,  1.15it/s]losses: tensor([0.3660], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-297.9352], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-211.9458], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-302.8965], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-208.7407], device='cuda:0')\n",
            "logits: tensor([8.1665], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4961], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3205], device='cuda:0')\n",
            " 94% 5857/6237 [1:39:41<05:25,  1.17it/s]losses: tensor([0.1491], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-731.6251], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.3018], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-730.5220], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.9195], device='cuda:0')\n",
            "logits: tensor([18.2791], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1103], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9382], device='cuda:0')\n",
            " 94% 5858/6237 [1:39:43<06:01,  1.05it/s]losses: tensor([0.0060], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-401.3889], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.7383], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-413.2066], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.4665], device='cuda:0')\n",
            "logits: tensor([51.0895], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1818], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9272], device='cuda:0')\n",
            " 94% 5859/6237 [1:39:44<06:58,  1.11s/it]losses: tensor([0.0479], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-240.6820], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.8033], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-243.2852], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.2678], device='cuda:0')\n",
            "logits: tensor([30.1388], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2603], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7536], device='cuda:0')\n",
            "{'loss': 0.2064, 'learning_rate': 3.4651701407447e-08, 'rewards/real': -0.13196291029453278, 'rewards/generated': -2.592421293258667, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.460458755493164, 'logps/generated': -426.60687255859375, 'logps/real': -510.44061279296875, 'logits/generated': -0.8877593874931335, 'logits/real': -0.9155350923538208, 'epoch': 2.82}\n",
            " 94% 5860/6237 [1:39:45<06:34,  1.05s/it]losses: tensor([0.6739], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-245.6114], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-535.8876], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-241.6832], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-531.5707], device='cuda:0')\n",
            "logits: tensor([0.3887], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3928], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4317], device='cuda:0')\n",
            " 94% 5861/6237 [1:39:46<06:13,  1.01it/s]losses: tensor([0.3324], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-530.1227], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.7881], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.0176], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.3770], device='cuda:0')\n",
            "logits: tensor([9.3061], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9105], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8411], device='cuda:0')\n",
            " 94% 5862/6237 [1:39:46<05:26,  1.15it/s]losses: tensor([0.0045], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-98.5860], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-523.9896], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-102.4433], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-473.7437], device='cuda:0')\n",
            "logits: tensor([54.1032], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3857], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0246], device='cuda:0')\n",
            " 94% 5863/6237 [1:39:47<04:52,  1.28it/s]losses: tensor([0.0080], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-139.2718], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.0117], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-145.6712], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.1078], device='cuda:0')\n",
            "logits: tensor([48.3033], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6399], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1904], device='cuda:0')\n",
            " 94% 5864/6237 [1:39:48<04:51,  1.28it/s]losses: tensor([0.4996], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-645.5592], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-243.0935], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-640.9852], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-234.1808], device='cuda:0')\n",
            "logits: tensor([4.3386], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4574], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8913], device='cuda:0')\n",
            " 94% 5865/6237 [1:39:49<06:10,  1.00it/s]losses: tensor([0.0019], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-120.0667], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1136.2120], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-132.8640], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1086.3079], device='cuda:0')\n",
            "logits: tensor([62.7014], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2797], device='cuda:0')\n",
            "generated_rewards: tensor([-4.9904], device='cuda:0')\n",
            " 94% 5866/6237 [1:39:50<05:20,  1.16it/s]losses: tensor([0.1429], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-833.6036], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.9149], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-832.7961], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.3770], device='cuda:0')\n",
            "logits: tensor([18.7304], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0807], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9538], device='cuda:0')\n",
            " 94% 5867/6237 [1:39:51<05:49,  1.06it/s]losses: tensor([0.2526], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.7661], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-252.4353], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-294.6779], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-245.8781], device='cuda:0')\n",
            "logits: tensor([12.4691], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5912], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6557], device='cuda:0')\n",
            " 94% 5868/6237 [1:39:52<06:04,  1.01it/s]losses: tensor([0.1634], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-658.7253], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.6635], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-656.1418], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.7944], device='cuda:0')\n",
            "logits: tensor([17.2855], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2584], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9869], device='cuda:0')\n",
            " 94% 5869/6237 [1:39:53<06:05,  1.01it/s]losses: tensor([0.5632], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-602.4315], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-521.0547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-596.1038], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-511.9341], device='cuda:0')\n",
            "logits: tensor([2.7929], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6328], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9121], device='cuda:0')\n",
            "{'loss': 0.2642, 'learning_rate': 3.3760912168181004e-08, 'rewards/real': 0.016397934406995773, 'rewards/generated': -2.2877936363220215, 'rewards/accuracies': 1.0, 'rewards/margins': 2.304191827774048, 'logps/generated': -498.20513916015625, 'logps/real': -416.2744140625, 'logits/generated': -1.0106759071350098, 'logits/real': -1.1533360481262207, 'epoch': 2.82}\n",
            " 94% 5870/6237 [1:39:54<05:50,  1.05it/s]losses: tensor([0.0265], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-261.6133], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-593.4119], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-275.0317], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-570.6533], device='cuda:0')\n",
            "logits: tensor([36.1770], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3418], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2759], device='cuda:0')\n",
            " 94% 5871/6237 [1:39:55<06:45,  1.11s/it]losses: tensor([0.0740], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-151.3602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-381.8174], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-148.1512], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-352.9504], device='cuda:0')\n",
            "logits: tensor([25.6581], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3209], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8867], device='cuda:0')\n",
            " 94% 5872/6237 [1:39:57<06:46,  1.11s/it]losses: tensor([0.3153], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-208.7507], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-400.4976], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-214.7593], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.5833], device='cuda:0')\n",
            "logits: tensor([9.9229], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6009], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3914], device='cuda:0')\n",
            " 94% 5873/6237 [1:39:58<07:23,  1.22s/it]losses: tensor([0.0955], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-482.1533], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-569.9284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-488.6747], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-553.4394], device='cuda:0')\n",
            "logits: tensor([23.0104], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6521], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6489], device='cuda:0')\n",
            " 94% 5874/6237 [1:39:59<07:48,  1.29s/it]losses: tensor([0.2279], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-883.6821], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-401.6492], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-893.2739], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.6118], device='cuda:0')\n",
            "logits: tensor([13.6292], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9592], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4037], device='cuda:0')\n",
            " 94% 5875/6237 [1:40:01<07:19,  1.21s/it]losses: tensor([0.1604], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-740.9672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.4101], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-729.2260], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-408.1792], device='cuda:0')\n",
            "logits: tensor([17.4897], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1741], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9231], device='cuda:0')\n",
            " 94% 5876/6237 [1:40:02<07:03,  1.17s/it]losses: tensor([0.1789], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-530.8348], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-345.7927], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-528.2042], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-326.8621], device='cuda:0')\n",
            "logits: tensor([16.2999], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2631], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8931], device='cuda:0')\n",
            " 94% 5877/6237 [1:40:03<07:07,  1.19s/it]losses: tensor([0.0542], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-937.5013], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.2826], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-932.3292], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.2343], device='cuda:0')\n",
            "logits: tensor([28.8762], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5172], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4048], device='cuda:0')\n",
            " 94% 5878/6237 [1:40:04<07:25,  1.24s/it]losses: tensor([0.0112], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-487.8181], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.7781], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-483.7778], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-403.9198], device='cuda:0')\n",
            "logits: tensor([44.8180], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4040], device='cuda:0')\n",
            "generated_rewards: tensor([-4.8858], device='cuda:0')\n",
            " 94% 5879/6237 [1:40:05<06:09,  1.03s/it]losses: tensor([0.0787], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1273.9336], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-520.7301], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1271.7926], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-493.5667], device='cuda:0')\n",
            "logits: tensor([25.0224], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2141], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7163], device='cuda:0')\n",
            "{'loss': 0.1223, 'learning_rate': 3.2870122928915015e-08, 'rewards/real': 0.06605850160121918, 'rewards/generated': -2.3429791927337646, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4090375900268555, 'logps/generated': -456.829833984375, 'logps/real': -595.8614501953125, 'logits/generated': -1.505021572113037, 'logits/real': -1.431382656097412, 'epoch': 2.83}\n",
            " 94% 5880/6237 [1:40:06<06:58,  1.17s/it]losses: tensor([0.2178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-385.6745], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.3095], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-378.1692], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.6713], device='cuda:0')\n",
            "logits: tensor([14.1329], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7505], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1638], device='cuda:0')\n",
            " 94% 5881/6237 [1:40:07<05:52,  1.01it/s]losses: tensor([0.0079], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-169.5615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-533.4197], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.4378], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-491.8634], device='cuda:0')\n",
            "logits: tensor([48.4326], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6876], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1556], device='cuda:0')\n",
            " 94% 5882/6237 [1:40:08<06:15,  1.06s/it]losses: tensor([0.1431], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-595.4915], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.6131], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-590.8388], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.2453], device='cuda:0')\n",
            "logits: tensor([18.7151], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4653], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3368], device='cuda:0')\n",
            " 94% 5883/6237 [1:40:09<05:44,  1.03it/s]losses: tensor([0.0020], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-538.3562], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-557.3518], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-532.6535], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-489.3826], device='cuda:0')\n",
            "logits: tensor([62.2665], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5703], device='cuda:0')\n",
            "generated_rewards: tensor([-6.7969], device='cuda:0')\n",
            " 94% 5884/6237 [1:40:10<05:21,  1.10it/s]losses: tensor([0.0003], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1073.7178], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-3861.7534], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1060.0809], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-3766.8943], device='cuda:0')\n",
            "logits: tensor([81.2222], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3637], device='cuda:0')\n",
            "generated_rewards: tensor([-9.4859], device='cuda:0')\n",
            " 94% 5885/6237 [1:40:11<06:14,  1.06s/it]losses: tensor([0.0337], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-308.3860], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.3385], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-331.1893], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-417.4124], device='cuda:0')\n",
            "logits: tensor([33.7295], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.2803], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0926], device='cuda:0')\n",
            " 94% 5886/6237 [1:40:12<06:56,  1.19s/it]losses: tensor([0.0049], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-177.6480], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-509.1994], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-182.9695], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-461.2922], device='cuda:0')\n",
            "logits: tensor([53.2287], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5322], device='cuda:0')\n",
            "generated_rewards: tensor([-4.7907], device='cuda:0')\n",
            " 94% 5887/6237 [1:40:14<06:44,  1.16s/it]losses: tensor([0.1314], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-372.0898], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-593.7515], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-372.1955], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-574.2234], device='cuda:0')\n",
            "logits: tensor([19.6338], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0106], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9528], device='cuda:0')\n",
            " 94% 5888/6237 [1:40:15<07:16,  1.25s/it]losses: tensor([0.0501], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1077.8298], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.5883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1091.5833], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.6521], device='cuda:0')\n",
            "logits: tensor([29.6896], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3753], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5936], device='cuda:0')\n",
            " 94% 5889/6237 [1:40:16<07:05,  1.22s/it]losses: tensor([0.1323], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-478.6090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.3535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-472.9118], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-359.0963], device='cuda:0')\n",
            "logits: tensor([19.5599], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5697], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5257], device='cuda:0')\n",
            "{'loss': 0.0723, 'learning_rate': 3.197933368964903e-08, 'rewards/real': 0.11665511131286621, 'rewards/generated': -3.6894538402557373, 'rewards/accuracies': 1.0, 'rewards/margins': 3.8061089515686035, 'logps/generated': -820.2678833007812, 'logps/real': -517.7363891601562, 'logits/generated': -1.3319427967071533, 'logits/real': -1.4605786800384521, 'epoch': 2.83}\n",
            " 94% 5890/6237 [1:40:17<06:22,  1.10s/it]losses: tensor([0.0145], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-202.1104], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-435.6879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-213.2702], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.6085], device='cuda:0')\n",
            "logits: tensor([42.2392], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1160], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1079], device='cuda:0')\n",
            " 94% 5891/6237 [1:40:18<05:59,  1.04s/it]losses: tensor([0.1750], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-737.7816], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-501.7945], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-720.4356], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.9060], device='cuda:0')\n",
            "logits: tensor([16.5425], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7346], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3888], device='cuda:0')\n",
            " 94% 5892/6237 [1:40:19<05:41,  1.01it/s]losses: tensor([0.0539], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-252.8824], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-454.1397], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-257.9188], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.2370], device='cuda:0')\n",
            "logits: tensor([28.9391], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5036], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3903], device='cuda:0')\n",
            " 94% 5893/6237 [1:40:19<05:05,  1.12it/s]losses: tensor([0.3276], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1349.7389], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.2284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1334.7739], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.7864], device='cuda:0')\n",
            "logits: tensor([9.4771], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4965], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4442], device='cuda:0')\n",
            " 95% 5894/6237 [1:40:21<06:40,  1.17s/it]losses: tensor([0.0921], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-807.8417], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.3659], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-795.9929], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.1285], device='cuda:0')\n",
            "logits: tensor([23.3887], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1849], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5237], device='cuda:0')\n",
            " 95% 5895/6237 [1:40:22<06:23,  1.12s/it]losses: tensor([0.0337], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-89.5982], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.9761], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-99.0862], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-423.7251], device='cuda:0')\n",
            "logits: tensor([33.7391], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9488], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4251], device='cuda:0')\n",
            " 95% 5896/6237 [1:40:23<06:18,  1.11s/it]losses: tensor([0.3163], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-517.8518], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-383.6980], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-517.8253], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.7858], device='cuda:0')\n",
            "logits: tensor([9.8857], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0027], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9912], device='cuda:0')\n",
            " 95% 5897/6237 [1:40:24<05:47,  1.02s/it]losses: tensor([0.1004], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-863.8309], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-395.7382], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-866.6191], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-376.0474], device='cuda:0')\n",
            "logits: tensor([22.4790], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2788], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9691], device='cuda:0')\n",
            " 95% 5898/6237 [1:40:26<06:41,  1.19s/it]losses: tensor([0.1181], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-276.7942], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-405.7979], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-273.3362], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-381.5737], device='cuda:0')\n",
            "logits: tensor([20.7662], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3458], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4224], device='cuda:0')\n",
            " 95% 5899/6237 [1:40:27<07:39,  1.36s/it]losses: tensor([0.1746], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1236.4734], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-444.3276], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1227.1945], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-418.4808], device='cuda:0')\n",
            "logits: tensor([16.5678], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9279], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5847], device='cuda:0')\n",
            "{'loss': 0.1406, 'learning_rate': 3.108854445038304e-08, 'rewards/real': -0.28450655937194824, 'rewards/generated': -2.524749279022217, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2402429580688477, 'logps/generated': -439.8753967285156, 'logps/real': -633.4903564453125, 'logits/generated': -1.4846948385238647, 'logits/real': -1.5490608215332031, 'epoch': 2.84}\n",
            " 95% 5900/6237 [1:40:29<08:27,  1.51s/it]losses: tensor([0.0357], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-347.1035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.6723], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-356.0428], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.4541], device='cuda:0')\n",
            "logits: tensor([33.1575], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8939], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4218], device='cuda:0')\n",
            " 95% 5901/6237 [1:40:30<06:52,  1.23s/it]losses: tensor([1.1898e-05], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-115.9895], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-3313.4673], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-124.3113], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-3208.3975], device='cuda:0')\n",
            "logits: tensor([113.3916], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8322], device='cuda:0')\n",
            "generated_rewards: tensor([-10.5070], device='cuda:0')\n",
            " 95% 5902/6237 [1:40:31<06:00,  1.08s/it]losses: tensor([0.1252], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1022.6245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.5568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1015.0594], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.8471], device='cuda:0')\n",
            "logits: tensor([20.1446], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7565], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7710], device='cuda:0')\n",
            " 95% 5903/6237 [1:40:32<06:04,  1.09s/it]losses: tensor([0.0165], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-570.7846], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-497.9299], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-557.7108], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.9160], device='cuda:0')\n",
            "logits: tensor([40.9402], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3074], device='cuda:0')\n",
            "generated_rewards: tensor([-5.4014], device='cuda:0')\n",
            " 95% 5904/6237 [1:40:33<05:34,  1.00s/it]losses: tensor([0.1181], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-772.9330], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.9714], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-768.3743], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.6431], device='cuda:0')\n",
            "logits: tensor([20.7695], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4559], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5328], device='cuda:0')\n",
            " 95% 5905/6237 [1:40:34<05:47,  1.05s/it]losses: tensor([0.2130], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-989.0007], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.6423], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-986.2838], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.5464], device='cuda:0')\n",
            "logits: tensor([14.3789], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2717], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7096], device='cuda:0')\n",
            " 95% 5906/6237 [1:40:35<05:53,  1.07s/it]losses: tensor([0.0440], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-884.1675], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.1599], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-893.2191], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.2053], device='cuda:0')\n",
            "logits: tensor([31.0062], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9052], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1955], device='cuda:0')\n",
            " 95% 5907/6237 [1:40:36<05:55,  1.08s/it]losses: tensor([0.0849], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-514.1409], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-450.8052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.7308], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.1590], device='cuda:0')\n",
            "logits: tensor([24.2361], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7590], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6646], device='cuda:0')\n",
            " 95% 5908/6237 [1:40:37<05:20,  1.03it/s]losses: tensor([0.1338], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-802.2053], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-451.2742], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-802.0053], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.6380], device='cuda:0')\n",
            "logits: tensor([19.4362], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0200], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9636], device='cuda:0')\n",
            " 95% 5909/6237 [1:40:38<05:28,  1.00s/it]losses: tensor([0.0406], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-559.5059], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.7166], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-557.2094], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.5759], device='cuda:0')\n",
            "logits: tensor([31.8442], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2297], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4141], device='cuda:0')\n",
            "{'loss': 0.0812, 'learning_rate': 3.019775521111705e-08, 'rewards/real': 0.03491386026144028, 'rewards/generated': -3.4581356048583984, 'rewards/accuracies': 1.0, 'rewards/margins': 3.493049144744873, 'logps/generated': -738.1195678710938, 'logps/real': -657.8455810546875, 'logits/generated': -1.0784391164779663, 'logits/real': -0.9613167643547058, 'epoch': 2.84}\n",
            " 95% 5910/6237 [1:40:38<04:41,  1.16it/s]losses: tensor([0.1704], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1788.0878], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-542.6595], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1783.6517], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-521.3931], device='cuda:0')\n",
            "logits: tensor([16.8304], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4436], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1266], device='cuda:0')\n",
            " 95% 5911/6237 [1:40:40<05:51,  1.08s/it]losses: tensor([0.2288], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1201.0120], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-451.0883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1193.3857], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.8789], device='cuda:0')\n",
            "logits: tensor([13.5831], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7626], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1209], device='cuda:0')\n",
            " 95% 5912/6237 [1:40:41<06:18,  1.16s/it]losses: tensor([0.3742], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-931.3394], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.8032], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-907.5851], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-432.1494], device='cuda:0')\n",
            "logits: tensor([7.8996], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.3754], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1654], device='cuda:0')\n",
            " 95% 5913/6237 [1:40:43<06:36,  1.22s/it]losses: tensor([0.1509], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-816.5116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.9850], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-810.3764], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-389.7016], device='cuda:0')\n",
            "logits: tensor([18.1482], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6135], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4283], device='cuda:0')\n",
            " 95% 5914/6237 [1:40:44<06:33,  1.22s/it]losses: tensor([0.1311], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1139.0046], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-512.0184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1127.9146], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-481.2717], device='cuda:0')\n",
            "logits: tensor([19.6566], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1090], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0747], device='cuda:0')\n",
            " 95% 5915/6237 [1:40:45<06:48,  1.27s/it]losses: tensor([0.0026], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-277.3015], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-830.2978], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-273.7217], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-767.1759], device='cuda:0')\n",
            "logits: tensor([59.5420], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3580], device='cuda:0')\n",
            "generated_rewards: tensor([-6.3122], device='cuda:0')\n",
            " 95% 5916/6237 [1:40:47<07:03,  1.32s/it]losses: tensor([0.1164], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-887.2258], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-390.1426], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-880.9416], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-362.9361], device='cuda:0')\n",
            "logits: tensor([20.9222], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6284], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7206], device='cuda:0')\n",
            " 95% 5917/6237 [1:40:48<07:07,  1.34s/it]losses: tensor([0.1379], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-644.0225], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-449.1890], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-644.4362], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.4854], device='cuda:0')\n",
            "logits: tensor([19.1173], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0414], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8704], device='cuda:0')\n",
            " 95% 5918/6237 [1:40:49<06:00,  1.13s/it]losses: tensor([0.0120], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.0174], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.7357], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-468.5107], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.1006], device='cuda:0')\n",
            "logits: tensor([44.1284], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4493], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9635], device='cuda:0')\n",
            " 95% 5919/6237 [1:40:49<05:00,  1.06it/s]losses: tensor([0.0282], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-415.7339], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-554.4086], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-414.0178], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-517.1488], device='cuda:0')\n",
            "logits: tensor([35.5437], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1716], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7260], device='cuda:0')\n",
            "{'loss': 0.1352, 'learning_rate': 2.930696597185106e-08, 'rewards/real': -0.5971499681472778, 'rewards/generated': -3.150866985321045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5537168979644775, 'logps/generated': -502.7328186035156, 'logps/real': -856.4256591796875, 'logits/generated': -1.4412260055541992, 'logits/real': -1.2327711582183838, 'epoch': 2.85}\n",
            " 95% 5920/6237 [1:40:50<04:34,  1.16it/s]losses: tensor([0.3908], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1005.7289], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-423.0202], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-983.5012], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-393.4144], device='cuda:0')\n",
            "logits: tensor([7.3782], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.2228], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9606], device='cuda:0')\n",
            " 95% 5921/6237 [1:40:52<05:55,  1.13s/it]losses: tensor([0.0833], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-362.8787], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-537.0262], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-354.5046], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-504.2139], device='cuda:0')\n",
            "logits: tensor([24.4382], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8374], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2812], device='cuda:0')\n",
            " 95% 5922/6237 [1:40:52<05:11,  1.01it/s]losses: tensor([0.0777], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-893.7542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.3345], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-884.4960], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.9172], device='cuda:0')\n",
            "logits: tensor([25.1591], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9258], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4417], device='cuda:0')\n",
            " 95% 5923/6237 [1:40:53<05:25,  1.04s/it]losses: tensor([0.1312], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-106.0457], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-333.5238], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-107.3311], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-315.1592], device='cuda:0')\n",
            "logits: tensor([19.6500], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1285], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8365], device='cuda:0')\n",
            " 95% 5924/6237 [1:40:55<05:36,  1.07s/it]losses: tensor([0.0139], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-717.0472], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-521.2924], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-719.4125], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.9361], device='cuda:0')\n",
            "logits: tensor([42.7216], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2365], device='cuda:0')\n",
            "generated_rewards: tensor([-4.0356], device='cuda:0')\n",
            " 95% 5925/6237 [1:40:55<04:53,  1.06it/s]losses: tensor([0.0230], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-216.7874], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.6937], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-225.8155], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-475.1042], device='cuda:0')\n",
            "logits: tensor([37.6176], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9028], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8589], device='cuda:0')\n",
            " 95% 5926/6237 [1:40:56<04:44,  1.09it/s]losses: tensor([0.2006], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-857.4230], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-400.6246], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-854.6286], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-382.7836], device='cuda:0')\n",
            "logits: tensor([15.0466], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2794], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7841], device='cuda:0')\n",
            " 95% 5927/6237 [1:40:57<04:36,  1.12it/s]losses: tensor([0.0610], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-726.2797], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.2850], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-726.8893], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.2277], device='cuda:0')\n",
            "logits: tensor([27.6670], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0610], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7057], device='cuda:0')\n",
            " 95% 5928/6237 [1:40:58<04:27,  1.15it/s]losses: tensor([0.2340], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-451.8434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-350.6389], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-455.5174], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-340.9818], device='cuda:0')\n",
            "logits: tensor([13.3312], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3674], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9657], device='cuda:0')\n",
            " 95% 5929/6237 [1:40:59<04:39,  1.10it/s]losses: tensor([0.3748], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1014.8159], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.3486], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1003.7656], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-469.4167], device='cuda:0')\n",
            "logits: tensor([7.8817], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1050], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8932], device='cuda:0')\n",
            "{'loss': 0.159, 'learning_rate': 2.841617673258507e-08, 'rewards/real': -0.36742162704467773, 'rewards/generated': -2.576333522796631, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2089121341705322, 'logps/generated': -449.77880859375, 'logps/real': -635.2603759765625, 'logits/generated': -1.6901848316192627, 'logits/real': -1.581136703491211, 'epoch': 2.85}\n",
            " 95% 5930/6237 [1:41:00<05:08,  1.00s/it]losses: tensor([0.0167], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-286.3559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.2076], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-276.8843], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.9171], device='cuda:0')\n",
            "logits: tensor([40.8189], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9472], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0290], device='cuda:0')\n",
            " 95% 5931/6237 [1:41:00<04:20,  1.17it/s]losses: tensor([0.0141], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-436.7158], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-542.8664], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-428.6168], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-492.1895], device='cuda:0')\n",
            "logits: tensor([42.5780], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8099], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0677], device='cuda:0')\n",
            " 95% 5932/6237 [1:41:01<04:14,  1.20it/s]losses: tensor([0.4102], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-614.8683], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-551.4662], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-607.5349], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-537.3419], device='cuda:0')\n",
            "logits: tensor([6.7909], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7333], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4124], device='cuda:0')\n",
            " 95% 5933/6237 [1:41:02<04:17,  1.18it/s]losses: tensor([0.2096], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-393.4391], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-342.9621], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-396.0397], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-331.0030], device='cuda:0')\n",
            "logits: tensor([14.5597], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2601], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1959], device='cuda:0')\n",
            " 95% 5934/6237 [1:41:03<04:12,  1.20it/s]losses: tensor([0.0339], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1154.0206], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.2885], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1156.3914], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-411.9901], device='cuda:0')\n",
            "logits: tensor([33.6691], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2371], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1298], device='cuda:0')\n",
            " 95% 5935/6237 [1:41:04<04:40,  1.08it/s]losses: tensor([0.1825], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-468.9493], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.7759], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-460.5246], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.2699], device='cuda:0')\n",
            "logits: tensor([16.0812], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8425], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4506], device='cuda:0')\n",
            " 95% 5936/6237 [1:41:05<05:09,  1.03s/it]losses: tensor([0.1633], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-694.9771], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.3659], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-686.3435], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.4359], device='cuda:0')\n",
            "logits: tensor([17.2964], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8634], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5930], device='cuda:0')\n",
            " 95% 5937/6237 [1:41:07<05:29,  1.10s/it]losses: tensor([0.0709], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-834.2073], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.2035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-831.9503], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.8320], device='cuda:0')\n",
            "logits: tensor([26.1144], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2257], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8372], device='cuda:0')\n",
            " 95% 5938/6237 [1:41:08<05:31,  1.11s/it]losses: tensor([0.0427], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-433.8666], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-664.3596], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-431.5677], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-630.7467], device='cuda:0')\n",
            "logits: tensor([31.3140], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2299], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3613], device='cuda:0')\n",
            " 95% 5939/6237 [1:41:09<06:02,  1.21s/it]losses: tensor([0.0099], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-330.5177], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-475.8338], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-345.6938], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.8740], device='cuda:0')\n",
            "logits: tensor([46.1359], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5176], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0960], device='cuda:0')\n",
            "{'loss': 0.1154, 'learning_rate': 2.752538749331908e-08, 'rewards/real': -0.2637081742286682, 'rewards/generated': -3.0172924995422363, 'rewards/accuracies': 1.0, 'rewards/margins': 2.753584384918213, 'logps/generated': -482.6329040527344, 'logps/real': -564.791748046875, 'logits/generated': -1.1101096868515015, 'logits/real': -1.095463752746582, 'epoch': 2.86}\n",
            " 95% 5940/6237 [1:41:10<05:23,  1.09s/it]losses: tensor([0.2844], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1198.8668], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.8308], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1197.1382], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.9847], device='cuda:0')\n",
            "logits: tensor([11.1175], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1729], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2846], device='cuda:0')\n",
            " 95% 5941/6237 [1:41:11<05:48,  1.18s/it]losses: tensor([0.2979], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-836.9640], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.3948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-833.9161], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.7650], device='cuda:0')\n",
            "logits: tensor([10.5819], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3048], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3630], device='cuda:0')\n",
            " 95% 5942/6237 [1:41:12<05:37,  1.14s/it]losses: tensor([0.0145], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-117.0820], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-385.8809], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-130.7916], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-357.3100], device='cuda:0')\n",
            "logits: tensor([42.2805], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3710], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8571], device='cuda:0')\n",
            " 95% 5943/6237 [1:41:13<04:56,  1.01s/it]losses: tensor([0.2854], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-345.3866], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.1359], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-334.5392], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.2112], device='cuda:0')\n",
            "logits: tensor([11.0773], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0847], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1925], device='cuda:0')\n",
            " 95% 5944/6237 [1:41:14<04:13,  1.16it/s]losses: tensor([0.0310], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-310.2889], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.8549], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-313.4656], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.4638], device='cuda:0')\n",
            "logits: tensor([34.5678], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3177], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1391], device='cuda:0')\n",
            " 95% 5945/6237 [1:41:15<04:56,  1.01s/it]losses: tensor([0.1320], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-857.1729], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.4517], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-854.7679], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.4640], device='cuda:0')\n",
            "logits: tensor([19.5827], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2405], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1988], device='cuda:0')\n",
            " 95% 5946/6237 [1:41:16<04:45,  1.02it/s]losses: tensor([0.5278], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-917.4620], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-443.6827], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-899.8918], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.4771], device='cuda:0')\n",
            "logits: tensor([3.6355], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7570], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1206], device='cuda:0')\n",
            " 95% 5947/6237 [1:41:17<04:58,  1.03s/it]losses: tensor([0.0330], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-263.4886], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-548.4639], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-261.2163], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-512.2427], device='cuda:0')\n",
            "logits: tensor([33.9488], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2272], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6221], device='cuda:0')\n",
            " 95% 5948/6237 [1:41:18<04:26,  1.09it/s]losses: tensor([0.0212], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-590.6050], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.3461], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-600.0583], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.3518], device='cuda:0')\n",
            "logits: tensor([38.4477], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9453], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8994], device='cuda:0')\n",
            " 95% 5949/6237 [1:41:18<03:49,  1.26it/s]losses: tensor([0.0494], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-958.3918], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-568.9984], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-948.6831], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-529.4568], device='cuda:0')\n",
            "logits: tensor([29.8329], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9709], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9542], device='cuda:0')\n",
            "{'loss': 0.1677, 'learning_rate': 2.6634598254053087e-08, 'rewards/real': -0.2124031037092209, 'rewards/generated': -2.5631308555603027, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3507275581359863, 'logps/generated': -475.90399169921875, 'logps/real': -639.5709228515625, 'logits/generated': -1.3472154140472412, 'logits/real': -1.4892313480377197, 'epoch': 2.86}\n",
            " 95% 5950/6237 [1:41:20<04:43,  1.01it/s]losses: tensor([0.0199], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1126.3337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.3116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1131.4487], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.3444], device='cuda:0')\n",
            "logits: tensor([39.0822], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5115], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3967], device='cuda:0')\n",
            " 95% 5951/6237 [1:41:21<04:54,  1.03s/it]losses: tensor([0.1441], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-201.9473], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.3019], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-208.8828], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-353.5930], device='cuda:0')\n",
            "logits: tensor([18.6444], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6936], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1709], device='cuda:0')\n",
            " 95% 5952/6237 [1:41:21<04:14,  1.12it/s]losses: tensor([0.2385], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-957.9965], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-655.6028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-958.9736], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-643.4630], device='cuda:0')\n",
            "logits: tensor([13.1170], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0977], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2140], device='cuda:0')\n",
            " 95% 5953/6237 [1:41:23<05:35,  1.18s/it]losses: tensor([0.1666], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-782.0889], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.6922], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-766.7514], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-434.2787], device='cuda:0')\n",
            "logits: tensor([17.0760], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5337], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2414], device='cuda:0')\n",
            " 95% 5954/6237 [1:41:24<05:25,  1.15s/it]losses: tensor([0.0601], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-215.3953], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-531.1602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-209.7676], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-497.7085], device='cuda:0')\n",
            "logits: tensor([27.8239], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5628], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3452], device='cuda:0')\n",
            " 95% 5955/6237 [1:41:25<05:02,  1.07s/it]losses: tensor([0.2065], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-247.2546], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-227.6712], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-255.5543], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-221.2470], device='cuda:0')\n",
            "logits: tensor([14.7239], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8300], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6424], device='cuda:0')\n",
            " 95% 5956/6237 [1:41:26<04:31,  1.03it/s]losses: tensor([0.0243], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-251.5337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.0543], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-246.6853], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-419.1385], device='cuda:0')\n",
            "logits: tensor([37.0674], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4848], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1916], device='cuda:0')\n",
            " 96% 5957/6237 [1:41:26<03:52,  1.21it/s]losses: tensor([0.4215], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-976.9576], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-391.2343], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-975.6768], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.4949], device='cuda:0')\n",
            "logits: tensor([6.4585], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1281], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7739], device='cuda:0')\n",
            " 96% 5958/6237 [1:41:28<04:31,  1.03it/s]losses: tensor([0.0183], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-195.8548], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-408.0587], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-213.6908], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.9530], device='cuda:0')\n",
            "logits: tensor([39.9417], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7836], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2106], device='cuda:0')\n",
            " 96% 5959/6237 [1:41:28<03:51,  1.20it/s]losses: tensor([0.0046], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-189.9805], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1246.0752], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-202.4439], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1204.8323], device='cuda:0')\n",
            "logits: tensor([53.7064], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2463], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1243], device='cuda:0')\n",
            "{'loss': 0.1304, 'learning_rate': 2.57438090147871e-08, 'rewards/real': 0.24532237648963928, 'rewards/generated': -2.4310927391052246, 'rewards/accuracies': 1.0, 'rewards/margins': 2.676415205001831, 'logps/generated': -521.7162475585938, 'logps/real': -514.5343017578125, 'logits/generated': -1.006530523300171, 'logits/real': -1.0458307266235352, 'epoch': 2.87}\n",
            " 96% 5960/6237 [1:41:29<03:23,  1.36it/s]losses: tensor([0.0064], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-426.2504], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.8519], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-430.1607], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-430.3226], device='cuda:0')\n",
            "logits: tensor([50.4395], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3910], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6529], device='cuda:0')\n",
            " 96% 5961/6237 [1:41:29<03:10,  1.45it/s]losses: tensor([0.0822], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-307.6035], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.8167], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-304.5487], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.1919], device='cuda:0')\n",
            "logits: tensor([24.5700], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3055], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7625], device='cuda:0')\n",
            " 96% 5962/6237 [1:41:30<03:00,  1.52it/s]losses: tensor([0.1710], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-244.9237], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-514.4771], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-246.2175], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-498.9798], device='cuda:0')\n",
            "logits: tensor([16.7910], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1294], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5497], device='cuda:0')\n",
            " 96% 5963/6237 [1:41:31<03:46,  1.21it/s]losses: tensor([0.0108], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-309.2568], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-662.6184], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-315.7712], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-623.9366], device='cuda:0')\n",
            "logits: tensor([45.1963], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6514], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8682], device='cuda:0')\n",
            " 96% 5964/6237 [1:41:32<03:20,  1.36it/s]losses: tensor([0.0125], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-592.8883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-506.0625], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-597.3146], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-466.7587], device='cuda:0')\n",
            "logits: tensor([43.7300], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4426], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9304], device='cuda:0')\n",
            " 96% 5965/6237 [1:41:32<03:18,  1.37it/s]losses: tensor([0.0298], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-380.1580], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-520.5778], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-370.9261], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.3531], device='cuda:0')\n",
            "logits: tensor([34.9929], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9232], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4225], device='cuda:0')\n",
            " 96% 5966/6237 [1:41:33<02:50,  1.59it/s]losses: tensor([0.0526], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-223.5659], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-473.6815], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-220.0953], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.0223], device='cuda:0')\n",
            "logits: tensor([29.1886], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3471], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2659], device='cuda:0')\n",
            " 96% 5967/6237 [1:41:33<03:03,  1.47it/s]losses: tensor([0.0596], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-239.9431], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.0453], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-246.7801], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-385.9803], device='cuda:0')\n",
            "logits: tensor([27.9019], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6837], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1065], device='cuda:0')\n",
            " 96% 5968/6237 [1:41:34<03:03,  1.47it/s]losses: tensor([0.1237], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-362.6519], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.5647], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-358.9816], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.6229], device='cuda:0')\n",
            "logits: tensor([20.2716], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3670], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3942], device='cuda:0')\n",
            " 96% 5969/6237 [1:41:35<03:17,  1.35it/s]losses: tensor([0.5470], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-194.5336], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-504.6310], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-197.1652], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-504.0884], device='cuda:0')\n",
            "logits: tensor([3.1742], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2632], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0543], device='cuda:0')\n",
            "{'loss': 0.1096, 'learning_rate': 2.4853019775521112e-08, 'rewards/real': 0.061858974397182465, 'rewards/generated': -2.9007010459899902, 'rewards/accuracies': 1.0, 'rewards/margins': 2.962559461593628, 'logps/generated': -497.23272705078125, 'logps/real': -328.177490234375, 'logits/generated': -1.0566593408584595, 'logits/real': -1.1387455463409424, 'epoch': 2.87}\n",
            " 96% 5970/6237 [1:41:36<03:10,  1.40it/s]losses: tensor([0.4724], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1051.5085], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.4432], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1037.5177], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-447.4083], device='cuda:0')\n",
            "logits: tensor([5.0441], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3991], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9035], device='cuda:0')\n",
            " 96% 5971/6237 [1:41:37<04:04,  1.09it/s]losses: tensor([0.1486], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1185.0411], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-486.6192], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1172.1260], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-455.3946], device='cuda:0')\n",
            "logits: tensor([18.3095], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.2915], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1225], device='cuda:0')\n",
            " 96% 5972/6237 [1:41:38<04:41,  1.06s/it]losses: tensor([0.0106], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-235.4022], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.2245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-235.3432], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.7453], device='cuda:0')\n",
            "logits: tensor([45.4203], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0059], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5479], device='cuda:0')\n",
            " 96% 5973/6237 [1:41:39<04:26,  1.01s/it]losses: tensor([0.0324], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-290.5261], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-529.5361], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-280.2953], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-485.1768], device='cuda:0')\n",
            "logits: tensor([34.1286], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0231], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4359], device='cuda:0')\n",
            " 96% 5974/6237 [1:41:40<03:45,  1.16it/s]losses: tensor([0.0923], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-746.7211], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-467.5213], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-743.1006], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.5354], device='cuda:0')\n",
            "logits: tensor([23.3654], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3620], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6986], device='cuda:0')\n",
            " 96% 5975/6237 [1:41:41<03:49,  1.14it/s]losses: tensor([0.1858], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1012.5708], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-543.5883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1016.7244], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-531.8529], device='cuda:0')\n",
            "logits: tensor([15.8890], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4154], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1735], device='cuda:0')\n",
            " 96% 5976/6237 [1:41:42<03:57,  1.10it/s]losses: tensor([0.1732], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-181.3608], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.4535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-172.9597], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.3947], device='cuda:0')\n",
            "logits: tensor([16.6576], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8401], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5059], device='cuda:0')\n",
            " 96% 5977/6237 [1:41:43<03:56,  1.10it/s]losses: tensor([0.0809], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-157.5052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-344.7716], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-167.2119], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-329.7367], device='cuda:0')\n",
            "logits: tensor([24.7416], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9707], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5035], device='cuda:0')\n",
            " 96% 5978/6237 [1:41:44<04:27,  1.03s/it]losses: tensor([0.0045], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-110.3019], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.7217], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-121.5692], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-450.8660], device='cuda:0')\n",
            "logits: tensor([54.1229], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1267], device='cuda:0')\n",
            "generated_rewards: tensor([-4.2856], device='cuda:0')\n",
            " 96% 5979/6237 [1:41:45<04:10,  1.03it/s]losses: tensor([0.0027], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-178.1373], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-577.7656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-181.5811], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-522.2375], device='cuda:0')\n",
            "logits: tensor([58.9719], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3444], device='cuda:0')\n",
            "generated_rewards: tensor([-5.5528], device='cuda:0')\n",
            "{'loss': 0.1203, 'learning_rate': 2.396223053625512e-08, 'rewards/real': -0.2064605951309204, 'rewards/generated': -3.172968864440918, 'rewards/accuracies': 1.0, 'rewards/margins': 2.966508388519287, 'logps/generated': -486.2644958496094, 'logps/real': -514.9075317382812, 'logits/generated': -1.2027395963668823, 'logits/real': -1.267960786819458, 'epoch': 2.88}\n",
            " 96% 5980/6237 [1:41:45<03:43,  1.15it/s]losses: tensor([0.0656], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-152.8682], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-435.8094], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-154.0466], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.0789], device='cuda:0')\n",
            "logits: tensor([26.9088], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1178], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5730], device='cuda:0')\n",
            " 96% 5981/6237 [1:41:46<03:14,  1.32it/s]losses: tensor([0.0187], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-134.5410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.3615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-142.3281], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-467.4284], device='cuda:0')\n",
            "logits: tensor([39.7201], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7787], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1933], device='cuda:0')\n",
            " 96% 5982/6237 [1:41:47<03:00,  1.41it/s]losses: tensor([0.2426], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.8096], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-458.2305], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-288.7018], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.1974], device='cuda:0')\n",
            "logits: tensor([12.9253], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0108], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3033], device='cuda:0')\n",
            " 96% 5983/6237 [1:41:47<02:51,  1.48it/s]losses: tensor([0.0508], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-197.2884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-396.5586], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-194.5015], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.2294], device='cuda:0')\n",
            "logits: tensor([29.5424], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2787], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2329], device='cuda:0')\n",
            " 96% 5984/6237 [1:41:48<03:06,  1.36it/s]losses: tensor([0.5325], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-792.7010], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.5113], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-773.8560], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.1460], device='cuda:0')\n",
            "logits: tensor([3.5202], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.8845], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2365], device='cuda:0')\n",
            " 96% 5985/6237 [1:41:49<03:20,  1.26it/s]losses: tensor([0.2023], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-108.8386], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-222.8831], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-118.4490], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-217.5407], device='cuda:0')\n",
            "logits: tensor([14.9528], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9610], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5342], device='cuda:0')\n",
            " 96% 5986/6237 [1:41:50<03:50,  1.09it/s]losses: tensor([0.1529], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-170.9262], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-234.0443], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-180.8459], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-225.9572], device='cuda:0')\n",
            "logits: tensor([18.0068], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9920], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8087], device='cuda:0')\n",
            " 96% 5987/6237 [1:41:51<03:40,  1.13it/s]losses: tensor([0.4920], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-418.2433], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-398.0994], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-403.4457], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-378.7706], device='cuda:0')\n",
            "logits: tensor([4.5312], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4798], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9329], device='cuda:0')\n",
            " 96% 5988/6237 [1:41:52<03:24,  1.22it/s]losses: tensor([0.0541], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-811.8567], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-530.2021], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-811.5718], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-501.0141], device='cuda:0')\n",
            "logits: tensor([28.9031], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0285], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9188], device='cuda:0')\n",
            " 96% 5989/6237 [1:41:53<03:38,  1.14it/s]losses: tensor([0.0360], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-642.5303], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-560.7993], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-638.4442], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-523.6645], device='cuda:0')\n",
            "logits: tensor([33.0487], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4086], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7135], device='cuda:0')\n",
            "{'loss': 0.1848, 'learning_rate': 2.307144129698913e-08, 'rewards/real': -0.12412681430578232, 'rewards/generated': -2.2447214126586914, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1205945014953613, 'logps/generated': -416.44989013671875, 'logps/real': -371.8603210449219, 'logits/generated': -1.3988370895385742, 'logits/real': -1.3123934268951416, 'epoch': 2.88}\n",
            " 96% 5990/6237 [1:41:54<03:41,  1.11it/s]losses: tensor([0.3260], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-755.2883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.4298], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-759.1754], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-367.7816], device='cuda:0')\n",
            "logits: tensor([9.5352], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3887], device='cuda:0')\n",
            "generated_rewards: tensor([-0.5648], device='cuda:0')\n",
            " 96% 5991/6237 [1:41:55<03:56,  1.04it/s]losses: tensor([0.2352], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-967.2432], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.1364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-946.1060], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.7235], device='cuda:0')\n",
            "logits: tensor([13.2756], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.1137], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4413], device='cuda:0')\n",
            " 96% 5992/6237 [1:41:56<04:29,  1.10s/it]losses: tensor([0.0806], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1035.3154], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-427.5541], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1030.3845], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-397.8504], device='cuda:0')\n",
            "logits: tensor([24.7728], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4931], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9704], device='cuda:0')\n",
            " 96% 5993/6237 [1:41:58<04:47,  1.18s/it]losses: tensor([0.0278], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-414.0237], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-533.9253], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-424.0362], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-508.2526], device='cuda:0')\n",
            "logits: tensor([35.6852], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0012], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5673], device='cuda:0')\n",
            " 96% 5994/6237 [1:41:58<04:02,  1.00it/s]losses: tensor([0.0020], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-287.3929], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-501.3587], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-283.9252], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.7396], device='cuda:0')\n",
            "logits: tensor([62.1515], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3468], device='cuda:0')\n",
            "generated_rewards: tensor([-6.5619], device='cuda:0')\n",
            " 96% 5995/6237 [1:41:59<04:29,  1.11s/it]losses: tensor([0.0345], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-499.2797], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.4510], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-519.7646], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.4341], device='cuda:0')\n",
            "logits: tensor([33.5018], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0485], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3017], device='cuda:0')\n",
            " 96% 5996/6237 [1:42:00<03:58,  1.01it/s]losses: tensor([0.3208], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-500.5431], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-427.5096], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-482.5025], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.7453], device='cuda:0')\n",
            "logits: tensor([9.7238], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.8041], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7764], device='cuda:0')\n",
            " 96% 5997/6237 [1:42:01<03:25,  1.17it/s]losses: tensor([0.0301], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-461.2938], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-578.2129], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-445.6308], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-527.6560], device='cuda:0')\n",
            "logits: tensor([34.8939], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5663], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0557], device='cuda:0')\n",
            " 96% 5998/6237 [1:42:02<03:26,  1.16it/s]losses: tensor([0.0100], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-159.9092], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-411.8672], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-165.3889], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-371.3405], device='cuda:0')\n",
            "logits: tensor([46.0063], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5480], device='cuda:0')\n",
            "generated_rewards: tensor([-4.0527], device='cuda:0')\n",
            " 96% 5999/6237 [1:42:02<03:20,  1.19it/s]losses: tensor([0.1822], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-819.6008], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-441.0324], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-806.8704], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.2029], device='cuda:0')\n",
            "logits: tensor([16.0991], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.2730], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8830], device='cuda:0')\n",
            "{'loss': 0.1249, 'learning_rate': 2.2180652057723145e-08, 'rewards/real': -0.36105817556381226, 'rewards/generated': -3.2175095081329346, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8564512729644775, 'logps/generated': -453.5476989746094, 'logps/real': -589.9890747070312, 'logits/generated': -1.046836495399475, 'logits/real': -1.017277717590332, 'epoch': 2.89}\n",
            " 96% 6000/6237 [1:42:04<03:41,  1.07it/s]losses: tensor([0.0800], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-396.7540], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-393.4349], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-411.1062], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-382.9293], device='cuda:0')\n",
            "logits: tensor([24.8578], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4352], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0506], device='cuda:0')\n",
            " 96% 6001/6237 [1:42:04<03:21,  1.17it/s]losses: tensor([0.1129], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-595.9529], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-486.8430], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-587.7431], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.3884], device='cuda:0')\n",
            "logits: tensor([21.2448], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8210], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9455], device='cuda:0')\n",
            " 96% 6002/6237 [1:42:05<03:18,  1.18it/s]losses: tensor([0.3456], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-504.5881], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-309.5173], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-504.0262], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-300.1075], device='cuda:0')\n",
            "logits: tensor([8.8479], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0562], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9410], device='cuda:0')\n",
            " 96% 6003/6237 [1:42:06<03:36,  1.08it/s]losses: tensor([0.0184], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-180.6169], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.6499], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-196.1316], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.3123], device='cuda:0')\n",
            "logits: tensor([39.8524], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5515], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4338], device='cuda:0')\n",
            " 96% 6004/6237 [1:42:07<03:46,  1.03it/s]losses: tensor([0.0116], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-487.0876], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-514.4996], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-499.5865], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.5155], device='cuda:0')\n",
            "logits: tensor([44.4831], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2499], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1984], device='cuda:0')\n",
            " 96% 6005/6237 [1:42:08<03:36,  1.07it/s]losses: tensor([0.0384], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-594.0980], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-582.6930], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-597.7226], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-553.9131], device='cuda:0')\n",
            "logits: tensor([32.4045], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3625], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8780], device='cuda:0')\n",
            " 96% 6006/6237 [1:42:09<03:11,  1.20it/s]losses: tensor([0.0414], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-258.1971], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.6119], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-263.5543], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.3392], device='cuda:0')\n",
            "logits: tensor([31.6299], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5357], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6273], device='cuda:0')\n",
            " 96% 6007/6237 [1:42:10<03:46,  1.02it/s]losses: tensor([0.0666], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-375.0140], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.3008], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-363.8539], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.3902], device='cuda:0')\n",
            "logits: tensor([26.7505], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1160], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7911], device='cuda:0')\n",
            " 96% 6008/6237 [1:42:11<03:12,  1.19it/s]losses: tensor([0.0363], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-719.2657], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.8817], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-720.3551], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-455.9975], device='cuda:0')\n",
            "logits: tensor([32.9736], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1089], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1884], device='cuda:0')\n",
            " 96% 6009/6237 [1:42:12<03:37,  1.05it/s]losses: tensor([0.1261], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-377.6267], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-476.8552], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-363.7090], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.8662], device='cuda:0')\n",
            "logits: tensor([20.0713], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3918], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3989], device='cuda:0')\n",
            "{'loss': 0.0877, 'learning_rate': 2.1289862818457152e-08, 'rewards/real': 0.185874342918396, 'rewards/generated': -2.6452836990356445, 'rewards/accuracies': 1.0, 'rewards/margins': 2.83115816116333, 'logps/generated': -461.62872314453125, 'logps/real': -448.92010498046875, 'logits/generated': -1.1796480417251587, 'logits/real': -1.1812721490859985, 'epoch': 2.89}\n",
            " 96% 6010/6237 [1:42:12<03:05,  1.22it/s]losses: tensor([0.0483], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1632.0233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.1619], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1634.3242], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-429.4026], device='cuda:0')\n",
            "logits: tensor([30.0602], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2301], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7759], device='cuda:0')\n",
            " 96% 6011/6237 [1:42:14<04:14,  1.13s/it]losses: tensor([0.3504], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-859.2579], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.0378], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-841.3252], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-472.4221], device='cuda:0')\n",
            "logits: tensor([8.6830], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7933], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6616], device='cuda:0')\n",
            " 96% 6012/6237 [1:42:15<04:13,  1.13s/it]losses: tensor([0.2366], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-439.6856], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.6532], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-438.7824], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.5444], device='cuda:0')\n",
            "logits: tensor([13.2056], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0903], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4109], device='cuda:0')\n",
            " 96% 6013/6237 [1:42:16<04:10,  1.12s/it]losses: tensor([0.0447], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-425.3893], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-402.7034], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-436.7529], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.2164], device='cuda:0')\n",
            "logits: tensor([30.8506], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1364], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9487], device='cuda:0')\n",
            " 96% 6014/6237 [1:42:17<03:29,  1.06it/s]losses: tensor([0.0064], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-118.2014], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-496.8141], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-123.5247], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.6198], device='cuda:0')\n",
            "logits: tensor([50.5175], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5323], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5194], device='cuda:0')\n",
            " 96% 6015/6237 [1:42:18<03:24,  1.09it/s]losses: tensor([0.0430], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-169.5191], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.7809], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-172.0335], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.0472], device='cuda:0')\n",
            "logits: tensor([31.2482], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2514], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8734], device='cuda:0')\n",
            " 96% 6016/6237 [1:42:19<03:24,  1.08it/s]losses: tensor([0.1464], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-887.0188], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.5490], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-880.1187], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.1748], device='cuda:0')\n",
            "logits: tensor([18.4741], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6900], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5374], device='cuda:0')\n",
            " 96% 6017/6237 [1:42:20<04:00,  1.09s/it]losses: tensor([0.1517], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-420.1046], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-391.4918], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-410.2606], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-363.5549], device='cuda:0')\n",
            "logits: tensor([18.0929], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9844], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7937], device='cuda:0')\n",
            " 96% 6018/6237 [1:42:21<03:29,  1.05it/s]losses: tensor([0.0241], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-285.8167], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-630.5363], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-290.7941], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-598.3982], device='cuda:0')\n",
            "logits: tensor([37.1155], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4977], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2138], device='cuda:0')\n",
            " 97% 6019/6237 [1:42:22<04:03,  1.12s/it]losses: tensor([0.0322], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-949.4693], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-474.4210], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-950.7531], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.5134], device='cuda:0')\n",
            "logits: tensor([34.1914], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1284], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2908], device='cuda:0')\n",
            "{'loss': 0.1084, 'learning_rate': 2.0399073579191163e-08, 'rewards/real': -0.07816505432128906, 'rewards/generated': -2.8025546073913574, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7243895530700684, 'logps/generated': -463.81494140625, 'logps/real': -618.6485595703125, 'logits/generated': -1.5414445400238037, 'logits/real': -1.527816891670227, 'epoch': 2.9}\n",
            " 97% 6020/6237 [1:42:23<03:43,  1.03s/it]losses: tensor([0.0119], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-231.7344], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-539.7028], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-233.1860], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-496.8895], device='cuda:0')\n",
            "logits: tensor([44.2649], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1452], device='cuda:0')\n",
            "generated_rewards: tensor([-4.2813], device='cuda:0')\n",
            " 97% 6021/6237 [1:42:24<03:29,  1.03it/s]losses: tensor([0.2514], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-799.2180], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.5949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-800.9396], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-410.7940], device='cuda:0')\n",
            "logits: tensor([12.5226], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1722], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0801], device='cuda:0')\n",
            " 97% 6022/6237 [1:42:25<03:32,  1.01it/s]losses: tensor([0.0056], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-438.6700], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-518.9172], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-443.7119], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-472.1800], device='cuda:0')\n",
            "logits: tensor([51.7792], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5042], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6737], device='cuda:0')\n",
            " 97% 6023/6237 [1:42:26<03:32,  1.01it/s]losses: tensor([0.0898], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-451.4267], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-295.6113], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-471.4265], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-291.9669], device='cuda:0')\n",
            "logits: tensor([23.6442], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0000], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3644], device='cuda:0')\n",
            " 97% 6024/6237 [1:42:26<03:00,  1.18it/s]losses: tensor([0.0461], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.4055], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.6083], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-296.0221], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.6871], device='cuda:0')\n",
            "logits: tensor([30.5378], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7617], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2921], device='cuda:0')\n",
            " 97% 6025/6237 [1:42:28<03:39,  1.03s/it]losses: tensor([0.3376], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-326.5337], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-311.8501], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-334.4202], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-310.6118], device='cuda:0')\n",
            "logits: tensor([9.1248], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7887], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1238], device='cuda:0')\n",
            " 97% 6026/6237 [1:42:29<03:27,  1.02it/s]losses: tensor([0.1501], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-336.5026], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-588.5304], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-336.2941], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-570.1169], device='cuda:0')\n",
            "logits: tensor([18.2049], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0209], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8413], device='cuda:0')\n",
            " 97% 6027/6237 [1:42:30<03:58,  1.13s/it]losses: tensor([0.0450], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-372.7892], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.2730], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-385.6469], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.3537], device='cuda:0')\n",
            "logits: tensor([30.7771], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2858], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7919], device='cuda:0')\n",
            " 97% 6028/6237 [1:42:32<04:14,  1.22s/it]losses: tensor([0.0914], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-135.1819], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-586.7847], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-134.8156], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-562.9493], device='cuda:0')\n",
            "logits: tensor([23.4690], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0366], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3835], device='cuda:0')\n",
            " 97% 6029/6237 [1:42:33<04:13,  1.22s/it]losses: tensor([0.1146], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-188.5619], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-418.1432], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-188.2986], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-396.7989], device='cuda:0')\n",
            "logits: tensor([21.0811], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0263], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1344], device='cuda:0')\n",
            "{'loss': 0.1144, 'learning_rate': 1.950828433992517e-08, 'rewards/real': 0.557377278804779, 'rewards/generated': -2.0966784954071045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6540558338165283, 'logps/generated': -467.0016174316406, 'logps/real': -356.90240478515625, 'logits/generated': -1.0021871328353882, 'logits/real': -1.050114393234253, 'epoch': 2.9}\n",
            " 97% 6030/6237 [1:42:34<04:19,  1.25s/it]losses: tensor([0.0276], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-562.9551], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-698.2477], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-563.7144], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-663.2554], device='cuda:0')\n",
            "logits: tensor([35.7515], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0759], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4992], device='cuda:0')\n",
            " 97% 6031/6237 [1:42:36<04:31,  1.32s/it]losses: tensor([0.0566], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-145.3366], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-379.8264], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-153.0462], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-359.1089], device='cuda:0')\n",
            "logits: tensor([28.4272], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7710], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0717], device='cuda:0')\n",
            " 97% 6032/6237 [1:42:37<04:40,  1.37s/it]losses: tensor([0.1497], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-752.5983], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-497.8522], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-737.6799], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-464.7022], device='cuda:0')\n",
            "logits: tensor([18.2317], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4918], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3150], device='cuda:0')\n",
            " 97% 6033/6237 [1:42:38<03:57,  1.16s/it]losses: tensor([0.0867], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1065.8325], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-533.2648], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1070.8744], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-514.2919], device='cuda:0')\n",
            "logits: tensor([24.0147], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5042], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8973], device='cuda:0')\n",
            " 97% 6034/6237 [1:42:39<03:51,  1.14s/it]losses: tensor([0.1516], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-363.2027], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.0034], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-342.1334], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.8353], device='cuda:0')\n",
            "logits: tensor([18.0988], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.1069], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9168], device='cuda:0')\n",
            " 97% 6035/6237 [1:42:41<04:26,  1.32s/it]losses: tensor([0.0043], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-97.3093], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.5643], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-105.7216], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-435.5141], device='cuda:0')\n",
            "logits: tensor([54.4625], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8412], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6050], device='cuda:0')\n",
            " 97% 6036/6237 [1:42:42<04:10,  1.24s/it]losses: tensor([0.0217], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-523.9005], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.5535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-535.8580], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.3121], device='cuda:0')\n",
            "logits: tensor([38.1988], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1957], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6241], device='cuda:0')\n",
            " 97% 6037/6237 [1:42:42<03:24,  1.02s/it]losses: tensor([0.3499], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-297.4792], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-226.3808], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-301.4243], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-221.6258], device='cuda:0')\n",
            "logits: tensor([8.7000], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3945], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4755], device='cuda:0')\n",
            " 97% 6038/6237 [1:42:43<03:15,  1.02it/s]losses: tensor([0.1474], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-381.1007], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-397.8100], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-390.5964], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-388.9079], device='cuda:0')\n",
            "logits: tensor([18.3978], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9496], device='cuda:0')\n",
            "generated_rewards: tensor([-0.8902], device='cuda:0')\n",
            " 97% 6039/6237 [1:42:44<02:56,  1.12it/s]losses: tensor([0.1858], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-208.2037], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-413.4637], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-211.6612], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.0353], device='cuda:0')\n",
            "logits: tensor([15.8859], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3458], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2428], device='cuda:0')\n",
            "{'loss': 0.1181, 'learning_rate': 1.861749510065918e-08, 'rewards/real': 0.14791154861450195, 'rewards/generated': -2.453777551651001, 'rewards/accuracies': 1.0, 'rewards/margins': 2.601689100265503, 'logps/generated': -449.89666748046875, 'logps/real': -439.7919006347656, 'logits/generated': -1.1650158166885376, 'logits/real': -1.1571413278579712, 'epoch': 2.91}\n",
            " 97% 6040/6237 [1:42:45<03:35,  1.09s/it]losses: tensor([0.0981], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-478.3895], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.4193], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-473.1956], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-440.5038], device='cuda:0')\n",
            "logits: tensor([22.7216], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5194], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7915], device='cuda:0')\n",
            " 97% 6041/6237 [1:42:46<03:05,  1.06it/s]losses: tensor([0.0581], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-235.6088], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-520.4908], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-236.7176], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-493.4377], device='cuda:0')\n",
            "logits: tensor([28.1619], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1109], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7053], device='cuda:0')\n",
            " 97% 6042/6237 [1:42:48<03:39,  1.13s/it]losses: tensor([0.0405], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-284.0439], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-526.5201], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-270.9915], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-481.6053], device='cuda:0')\n",
            "logits: tensor([31.8624], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3052], device='cuda:0')\n",
            "generated_rewards: tensor([-4.4915], device='cuda:0')\n",
            " 97% 6043/6237 [1:42:48<03:02,  1.06it/s]losses: tensor([0.5433], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-936.1800], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-430.9712], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-913.0771], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.6061], device='cuda:0')\n",
            "logits: tensor([3.2622], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.3103], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6365], device='cuda:0')\n",
            " 97% 6044/6237 [1:42:49<03:22,  1.05s/it]losses: tensor([0.1700], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1005.2858], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.6612], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1007.3286], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.8479], device='cuda:0')\n",
            "logits: tensor([16.8560], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2043], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4813], device='cuda:0')\n",
            " 97% 6045/6237 [1:42:51<03:43,  1.16s/it]losses: tensor([0.0293], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-403.7287], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.6961], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-400.9056], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.7313], device='cuda:0')\n",
            "logits: tensor([35.1418], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2823], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7965], device='cuda:0')\n",
            " 97% 6046/6237 [1:42:51<03:09,  1.01it/s]losses: tensor([0.2411], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-196.1090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-283.3740], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-210.0019], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-284.2690], device='cuda:0')\n",
            "logits: tensor([12.9978], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.3893], device='cuda:0')\n",
            "generated_rewards: tensor([0.0895], device='cuda:0')\n",
            " 97% 6047/6237 [1:42:53<03:34,  1.13s/it]losses: tensor([0.0030], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-288.8879], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-565.4121], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-283.9926], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-502.5162], device='cuda:0')\n",
            "logits: tensor([58.0006], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4895], device='cuda:0')\n",
            "generated_rewards: tensor([-6.2896], device='cuda:0')\n",
            " 97% 6048/6237 [1:42:54<03:12,  1.02s/it]losses: tensor([0.0136], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-236.7701], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-378.0334], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-243.4466], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-341.7894], device='cuda:0')\n",
            "logits: tensor([42.9205], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6677], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6244], device='cuda:0')\n",
            " 97% 6049/6237 [1:42:54<02:59,  1.05it/s]losses: tensor([0.1067], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1143.8849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.8614], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1142.0120], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.1532], device='cuda:0')\n",
            "logits: tensor([21.8352], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1873], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3708], device='cuda:0')\n",
            "{'loss': 0.1304, 'learning_rate': 1.7726705861393196e-08, 'rewards/real': -0.27219483256340027, 'rewards/generated': -3.009795665740967, 'rewards/accuracies': 1.0, 'rewards/margins': 2.737600326538086, 'logps/generated': -453.9439392089844, 'logps/real': -520.8888549804688, 'logits/generated': -1.2327715158462524, 'logits/real': -1.2899249792099, 'epoch': 2.91}\n",
            " 97% 6050/6237 [1:42:56<03:15,  1.05s/it]losses: tensor([0.2800], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-296.6254], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-349.4244], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-297.7346], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-339.2372], device='cuda:0')\n",
            "logits: tensor([11.2964], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1109], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0187], device='cuda:0')\n",
            " 97% 6051/6237 [1:42:56<02:51,  1.08it/s]losses: tensor([0.0062], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-512.1324], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-515.4473], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-510.2344], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.7192], device='cuda:0')\n",
            "logits: tensor([50.8301], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1898], device='cuda:0')\n",
            "generated_rewards: tensor([-5.2728], device='cuda:0')\n",
            " 97% 6052/6237 [1:42:57<02:29,  1.24it/s]losses: tensor([0.0031], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-523.3535], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-549.4565], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-521.0526], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-489.4807], device='cuda:0')\n",
            "logits: tensor([57.6748], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2301], device='cuda:0')\n",
            "generated_rewards: tensor([-5.9976], device='cuda:0')\n",
            " 97% 6053/6237 [1:42:57<02:19,  1.32it/s]losses: tensor([0.0351], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-991.5479], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-544.4717], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-992.6981], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-512.2886], device='cuda:0')\n",
            "logits: tensor([33.3333], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1150], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2183], device='cuda:0')\n",
            " 97% 6054/6237 [1:42:59<02:52,  1.06it/s]losses: tensor([0.1019], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-728.4603], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-451.6707], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-719.2809], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.1649], device='cuda:0')\n",
            "logits: tensor([22.3264], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9179], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1506], device='cuda:0')\n",
            " 97% 6055/6237 [1:43:00<02:53,  1.05it/s]losses: tensor([0.1406], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-449.1016], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-498.1687], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-440.7283], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-470.8901], device='cuda:0')\n",
            "logits: tensor([18.9054], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8373], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7279], device='cuda:0')\n",
            " 97% 6056/6237 [1:43:00<02:27,  1.23it/s]losses: tensor([0.0852], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-947.2725], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.2928], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-943.6571], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-472.4821], device='cuda:0')\n",
            "logits: tensor([24.1954], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3615], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7811], device='cuda:0')\n",
            " 97% 6057/6237 [1:43:02<02:51,  1.05it/s]losses: tensor([0.0672], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-158.8996], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-407.9065], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-155.0263], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-377.3707], device='cuda:0')\n",
            "logits: tensor([26.6625], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3873], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0536], device='cuda:0')\n",
            " 97% 6058/6237 [1:43:03<03:12,  1.08s/it]losses: tensor([0.1837], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-636.6747], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-529.6023], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-633.0651], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-509.9828], device='cuda:0')\n",
            "logits: tensor([16.0099], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3610], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9619], device='cuda:0')\n",
            " 97% 6059/6237 [1:43:04<03:01,  1.02s/it]losses: tensor([0.5630], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-743.3673], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-316.8443], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-736.4104], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-307.0898], device='cuda:0')\n",
            "logits: tensor([2.7976], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6957], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9754], device='cuda:0')\n",
            "{'loss': 0.1466, 'learning_rate': 1.6835916622127203e-08, 'rewards/real': -0.3754730522632599, 'rewards/generated': -3.0157904624938965, 'rewards/accuracies': 1.0, 'rewards/margins': 2.640317440032959, 'logps/generated': -466.3285217285156, 'logps/real': -598.7435302734375, 'logits/generated': -1.3018805980682373, 'logits/real': -1.348048448562622, 'epoch': 2.91}\n",
            " 97% 6060/6237 [1:43:05<03:04,  1.04s/it]losses: tensor([0.0800], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-753.5626], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.9748], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-757.6949], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-436.2575], device='cuda:0')\n",
            "logits: tensor([24.8497], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4132], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0717], device='cuda:0')\n",
            " 97% 6061/6237 [1:43:06<02:57,  1.01s/it]losses: tensor([0.0350], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-589.3755], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-459.0948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-595.0928], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.4607], device='cuda:0')\n",
            "logits: tensor([33.3514], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5717], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7634], device='cuda:0')\n",
            " 97% 6062/6237 [1:43:07<02:54,  1.00it/s]losses: tensor([0.3702], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-517.9280], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.5497], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-493.1139], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-414.7051], device='cuda:0')\n",
            "logits: tensor([8.0306], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-2.4814], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2845], device='cuda:0')\n",
            " 97% 6063/6237 [1:43:07<02:32,  1.14it/s]losses: tensor([0.0616], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-498.7122], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-444.6223], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-490.7384], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.0818], device='cuda:0')\n",
            "logits: tensor([27.5667], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7974], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5540], device='cuda:0')\n",
            " 97% 6064/6237 [1:43:08<02:12,  1.30it/s]losses: tensor([0.0305], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-380.8554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-525.7069], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-381.3955], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-491.4901], device='cuda:0')\n",
            "logits: tensor([34.7570], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0540], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4217], device='cuda:0')\n",
            " 97% 6065/6237 [1:43:09<02:04,  1.38it/s]losses: tensor([0.0117], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-104.1832], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-459.4978], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-101.7115], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.5646], device='cuda:0')\n",
            "logits: tensor([44.4614], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2472], device='cuda:0')\n",
            "generated_rewards: tensor([-4.6933], device='cuda:0')\n",
            " 97% 6066/6237 [1:43:09<01:52,  1.51it/s]losses: tensor([0.0010], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-607.1508], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-531.2886], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-614.2948], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-469.1464], device='cuda:0')\n",
            "logits: tensor([69.2862], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7144], device='cuda:0')\n",
            "generated_rewards: tensor([-6.2142], device='cuda:0')\n",
            " 97% 6067/6237 [1:43:10<01:57,  1.45it/s]losses: tensor([0.5004], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-637.9176], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-267.0438], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-646.0408], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-270.8493], device='cuda:0')\n",
            "logits: tensor([4.3177], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8123], device='cuda:0')\n",
            "generated_rewards: tensor([0.3805], device='cuda:0')\n",
            " 97% 6068/6237 [1:43:11<02:41,  1.05it/s]losses: tensor([0.0459], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1136.6689], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.1656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1139.0198], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-355.9424], device='cuda:0')\n",
            "logits: tensor([30.5740], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2351], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8223], device='cuda:0')\n",
            " 97% 6069/6237 [1:43:13<02:56,  1.05s/it]losses: tensor([0.1129], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-322.7560], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.9501], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-318.9427], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-475.8945], device='cuda:0')\n",
            "logits: tensor([21.2424], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3813], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5056], device='cuda:0')\n",
            "{'loss': 0.1249, 'learning_rate': 1.5945127382861214e-08, 'rewards/real': -0.11064837127923965, 'rewards/generated': -3.0950188636779785, 'rewards/accuracies': 1.0, 'rewards/margins': 2.984370470046997, 'logps/generated': -447.689453125, 'logps/real': -554.9110107421875, 'logits/generated': -1.3077000379562378, 'logits/real': -1.316343903541565, 'epoch': 2.92}\n",
            " 97% 6070/6237 [1:43:13<02:38,  1.05it/s]losses: tensor([0.1797], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-450.5821], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-314.7729], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-453.0175], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-300.9536], device='cuda:0')\n",
            "logits: tensor([16.2547], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2435], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3819], device='cuda:0')\n",
            " 97% 6071/6237 [1:43:14<02:35,  1.07it/s]losses: tensor([0.2669], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-345.9237], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.8655], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-343.8627], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.9613], device='cuda:0')\n",
            "logits: tensor([11.8431], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2061], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3904], device='cuda:0')\n",
            " 97% 6072/6237 [1:43:15<02:12,  1.24it/s]losses: tensor([0.0599], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-480.5233], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-370.1053], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-480.6734], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-342.4029], device='cuda:0')\n",
            "logits: tensor([27.8525], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0150], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7702], device='cuda:0')\n",
            " 97% 6073/6237 [1:43:16<02:12,  1.23it/s]losses: tensor([0.0527], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-810.4695], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-552.9122], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-805.4319], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-518.6987], device='cuda:0')\n",
            "logits: tensor([29.1758], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5038], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4213], device='cuda:0')\n",
            " 97% 6074/6237 [1:43:17<02:25,  1.12it/s]losses: tensor([0.1169], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-584.6581], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-410.7419], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-584.8077], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.0152], device='cuda:0')\n",
            "logits: tensor([20.8763], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0150], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0727], device='cuda:0')\n",
            " 97% 6075/6237 [1:43:18<02:19,  1.16it/s]losses: tensor([0.0120], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-122.2936], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-478.4716], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-124.8543], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-436.8337], device='cuda:0')\n",
            "logits: tensor([44.1986], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2561], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1638], device='cuda:0')\n",
            " 97% 6076/6237 [1:43:18<02:11,  1.23it/s]losses: tensor([0.0107], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-282.9527], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-434.1526], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-306.6475], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.5312], device='cuda:0')\n",
            "logits: tensor([45.3162], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.3695], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1621], device='cuda:0')\n",
            " 97% 6077/6237 [1:43:19<01:55,  1.39it/s]losses: tensor([0.0949], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-567.8350], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-557.3787], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-557.1680], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-523.6425], device='cuda:0')\n",
            "logits: tensor([23.0692], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0667], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3736], device='cuda:0')\n",
            " 97% 6078/6237 [1:43:20<02:12,  1.20it/s]losses: tensor([0.0383], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1021.0402], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-489.1245], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1017.7268], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-453.3814], device='cuda:0')\n",
            "logits: tensor([32.4297], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3313], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5743], device='cuda:0')\n",
            " 97% 6079/6237 [1:43:21<02:18,  1.14it/s]losses: tensor([0.2690], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-681.6479], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-471.0417], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-663.9326], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.5693], device='cuda:0')\n",
            "logits: tensor([11.7570], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7715], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9472], device='cuda:0')\n",
            "{'loss': 0.1101, 'learning_rate': 1.5054338143595225e-08, 'rewards/real': -0.09803684800863266, 'rewards/generated': -2.725769519805908, 'rewards/accuracies': 1.0, 'rewards/margins': 2.627732515335083, 'logps/generated': -449.9566345214844, 'logps/real': -534.7926025390625, 'logits/generated': -1.4505711793899536, 'logits/real': -1.532020092010498, 'epoch': 2.92}\n",
            " 97% 6080/6237 [1:43:22<02:17,  1.15it/s]losses: tensor([0.0195], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-496.3431], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.7461], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-510.8417], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.9466], device='cuda:0')\n",
            "logits: tensor([39.2980], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4499], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4799], device='cuda:0')\n",
            " 97% 6081/6237 [1:43:22<01:54,  1.36it/s]losses: tensor([0.1164], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1382.1777], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-534.2727], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1380.5171], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-511.6880], device='cuda:0')\n",
            "logits: tensor([20.9241], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1661], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2585], device='cuda:0')\n",
            " 98% 6082/6237 [1:43:23<02:11,  1.18it/s]losses: tensor([0.1129], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-158.6143], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.4563], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-156.6099], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-398.2117], device='cuda:0')\n",
            "logits: tensor([21.2403], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2004], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3245], device='cuda:0')\n",
            " 98% 6083/6237 [1:43:24<02:22,  1.08it/s]losses: tensor([0.0720], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-758.9619], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.2076], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-749.5288], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-451.8298], device='cuda:0')\n",
            "logits: tensor([25.9448], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9433], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5378], device='cuda:0')\n",
            " 98% 6084/6237 [1:43:25<02:33,  1.01s/it]losses: tensor([0.0290], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-996.0615], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.1165], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1002.1388], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.9382], device='cuda:0')\n",
            "logits: tensor([35.2555], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6077], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9178], device='cuda:0')\n",
            " 98% 6085/6237 [1:43:27<02:46,  1.09s/it]losses: tensor([0.0563], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-761.1066], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-427.9131], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-757.1327], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-395.4523], device='cuda:0')\n",
            "logits: tensor([28.4869], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3974], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2461], device='cuda:0')\n",
            " 98% 6086/6237 [1:43:28<02:51,  1.13s/it]losses: tensor([0.2830], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-557.3398], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.9500], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-552.2832], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.7176], device='cuda:0')\n",
            "logits: tensor([11.1757], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5057], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6232], device='cuda:0')\n",
            " 98% 6087/6237 [1:43:29<02:33,  1.02s/it]losses: tensor([0.0890], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-219.5699], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.0861], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-223.1356], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-350.9058], device='cuda:0')\n",
            "logits: tensor([23.7460], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3566], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0180], device='cuda:0')\n",
            " 98% 6088/6237 [1:43:29<02:13,  1.12it/s]losses: tensor([0.0192], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-330.5151], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-501.9449], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-323.9810], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-455.9535], device='cuda:0')\n",
            "logits: tensor([39.4572], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6534], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5991], device='cuda:0')\n",
            " 98% 6089/6237 [1:43:30<02:12,  1.12it/s]losses: tensor([0.0060], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-158.3891], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-521.6832], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-159.0346], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.1610], device='cuda:0')\n",
            "logits: tensor([51.1677], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0645], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0522], device='cuda:0')\n",
            "{'loss': 0.0803, 'learning_rate': 1.4163548904329235e-08, 'rewards/real': -0.03875717520713806, 'rewards/generated': -3.0057199001312256, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9669628143310547, 'logps/generated': -453.837646484375, 'logps/real': -581.9078369140625, 'logits/generated': -1.2221266031265259, 'logits/real': -1.1471776962280273, 'epoch': 2.93}\n",
            " 98% 6090/6237 [1:43:31<02:11,  1.12it/s]losses: tensor([0.1375], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-502.6041], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-311.4653], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-509.8727], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-299.5900], device='cuda:0')\n",
            "logits: tensor([19.1438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7269], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1875], device='cuda:0')\n",
            " 98% 6091/6237 [1:43:32<02:14,  1.09it/s]losses: tensor([0.2769], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-953.7379], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.2903], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-955.1394], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.2693], device='cuda:0')\n",
            "logits: tensor([11.4225], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1401], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0021], device='cuda:0')\n",
            " 98% 6092/6237 [1:43:33<02:17,  1.05it/s]losses: tensor([0.0660], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-933.4163], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-530.5769], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-939.0909], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-509.3995], device='cuda:0')\n",
            "logits: tensor([26.8521], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5675], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1177], device='cuda:0')\n",
            " 98% 6093/6237 [1:43:34<02:07,  1.13it/s]losses: tensor([1.3763], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-515.9811], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.7055], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-498.5328], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-409.1092], device='cuda:0')\n",
            "logits: tensor([-10.8521], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7448], device='cuda:0')\n",
            "generated_rewards: tensor([-0.6596], device='cuda:0')\n",
            " 98% 6094/6237 [1:43:34<01:53,  1.26it/s]losses: tensor([0.2296], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-544.3804], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-295.0471], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-543.2775], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-280.3990], device='cuda:0')\n",
            "logits: tensor([13.5452], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1103], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4648], device='cuda:0')\n",
            " 98% 6095/6237 [1:43:36<02:06,  1.12it/s]losses: tensor([0.0266], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-294.6052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-481.9105], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-305.9937], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.1757], device='cuda:0')\n",
            "logits: tensor([36.1232], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1388], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4735], device='cuda:0')\n",
            " 98% 6096/6237 [1:43:36<02:04,  1.13it/s]losses: tensor([0.1192], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-837.2920], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-494.3103], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-830.1431], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-466.4898], device='cuda:0')\n",
            "logits: tensor([20.6717], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7149], device='cuda:0')\n",
            "generated_rewards: tensor([-2.7821], device='cuda:0')\n",
            " 98% 6097/6237 [1:43:38<02:13,  1.05it/s]losses: tensor([0.3383], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-761.9863], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-478.2706], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-751.4313], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-458.6175], device='cuda:0')\n",
            "logits: tensor([9.0981], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0555], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9653], device='cuda:0')\n",
            " 98% 6098/6237 [1:43:39<02:16,  1.02it/s]losses: tensor([0.0659], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-103.2032], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-307.2026], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-110.1607], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-287.3002], device='cuda:0')\n",
            "logits: tensor([26.8600], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6958], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9902], device='cuda:0')\n",
            " 98% 6099/6237 [1:43:39<02:08,  1.07it/s]losses: tensor([0.0335], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-246.3772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-513.6180], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-234.9642], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.4050], device='cuda:0')\n",
            "logits: tensor([33.8000], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1413], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5213], device='cuda:0')\n",
            "{'loss': 0.267, 'learning_rate': 1.3272759665063246e-08, 'rewards/real': -0.14977508783340454, 'rewards/generated': -2.016418933868408, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.866644263267517, 'logps/generated': -426.5397033691406, 'logps/real': -569.3583984375, 'logits/generated': -1.5664246082305908, 'logits/real': -1.4427307844161987, 'epoch': 2.93}\n",
            " 98% 6100/6237 [1:43:40<01:49,  1.25it/s]losses: tensor([0.0440], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-534.3744], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-516.5047], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-526.7336], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-477.8431], device='cuda:0')\n",
            "logits: tensor([31.0208], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7641], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8662], device='cuda:0')\n",
            " 98% 6101/6237 [1:43:41<01:49,  1.24it/s]losses: tensor([0.3818], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-785.0131], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-365.5772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-776.4194], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-349.3246], device='cuda:0')\n",
            "logits: tensor([7.6589], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8594], device='cuda:0')\n",
            "generated_rewards: tensor([-1.6253], device='cuda:0')\n",
            " 98% 6102/6237 [1:43:42<02:02,  1.11it/s]losses: tensor([0.0082], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-280.3720], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-461.8476], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-282.7375], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-416.1940], device='cuda:0')\n",
            "logits: tensor([48.0192], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2366], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5654], device='cuda:0')\n",
            " 98% 6103/6237 [1:43:43<02:14,  1.00s/it]losses: tensor([0.0451], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-419.2395], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.2769], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-421.7141], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.9983], device='cuda:0')\n",
            "logits: tensor([30.7532], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2475], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8279], device='cuda:0')\n",
            " 98% 6104/6237 [1:43:44<01:59,  1.11it/s]losses: tensor([0.2059], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-457.6697], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.6806], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-449.9147], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-399.1704], device='cuda:0')\n",
            "logits: tensor([14.7552], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7755], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2510], device='cuda:0')\n",
            " 98% 6105/6237 [1:43:44<01:49,  1.20it/s]losses: tensor([0.0671], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-324.8804], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-401.5270], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-320.2769], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.2385], device='cuda:0')\n",
            "logits: tensor([26.6851], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4603], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1289], device='cuda:0')\n",
            " 98% 6106/6237 [1:43:45<01:32,  1.41it/s]losses: tensor([0.1536], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-667.4017], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.6562], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-659.6899], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.9861], device='cuda:0')\n",
            "logits: tensor([17.9582], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7712], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5670], device='cuda:0')\n",
            " 98% 6107/6237 [1:43:46<01:49,  1.19it/s]losses: tensor([0.0406], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-214.1257], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-375.4256], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-214.0148], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-343.4664], device='cuda:0')\n",
            "logits: tensor([31.8484], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0111], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1959], device='cuda:0')\n",
            " 98% 6108/6237 [1:43:47<02:06,  1.02it/s]losses: tensor([0.1304], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-719.5015], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-319.4193], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-723.7949], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-304.0008], device='cuda:0')\n",
            "logits: tensor([19.7119], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4293], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5418], device='cuda:0')\n",
            " 98% 6109/6237 [1:43:48<02:12,  1.03s/it]losses: tensor([0.4533], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-349.3987], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-378.9681], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-347.3044], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-371.3132], device='cuda:0')\n",
            "logits: tensor([5.5606], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2094], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7655], device='cuda:0')\n",
            "{'loss': 0.153, 'learning_rate': 1.2381970425797255e-08, 'rewards/real': -0.29376453161239624, 'rewards/generated': -2.633479118347168, 'rewards/accuracies': 1.0, 'rewards/margins': 2.339714527130127, 'logps/generated': -408.68829345703125, 'logps/real': -475.1976623535156, 'logits/generated': -1.3942437171936035, 'logits/real': -1.2860684394836426, 'epoch': 2.94}\n",
            " 98% 6110/6237 [1:43:49<02:05,  1.01it/s]losses: tensor([0.0007], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-267.4128], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-539.8264], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-263.3472], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.5988], device='cuda:0')\n",
            "logits: tensor([73.1620], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4066], device='cuda:0')\n",
            "generated_rewards: tensor([-7.7228], device='cuda:0')\n",
            " 98% 6111/6237 [1:43:50<02:02,  1.03it/s]losses: tensor([0.0111], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-84.4224], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.5905], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-88.1989], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-423.4537], device='cuda:0')\n",
            "logits: tensor([44.9133], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3777], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1137], device='cuda:0')\n",
            " 98% 6112/6237 [1:43:51<02:02,  1.02it/s]losses: tensor([0.1991], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-531.2058], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-349.6368], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-524.3556], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-327.6592], device='cuda:0')\n",
            "logits: tensor([15.1274], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6850], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1978], device='cuda:0')\n",
            " 98% 6113/6237 [1:43:52<01:43,  1.20it/s]losses: tensor([0.2965], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-243.6487], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-482.0161], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-231.6589], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-459.3886], device='cuda:0')\n",
            "logits: tensor([10.6377], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1990], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2627], device='cuda:0')\n",
            " 98% 6114/6237 [1:43:53<02:11,  1.07s/it]losses: tensor([0.1799], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-516.3003], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-390.9833], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-522.3429], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-380.7835], device='cuda:0')\n",
            "logits: tensor([16.2425], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6043], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0200], device='cuda:0')\n",
            " 98% 6115/6237 [1:43:54<02:07,  1.04s/it]losses: tensor([0.0206], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-157.6964], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-488.1174], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-165.7098], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.4308], device='cuda:0')\n",
            "logits: tensor([38.7001], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8013], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0687], device='cuda:0')\n",
            " 98% 6116/6237 [1:43:55<01:55,  1.05it/s]losses: tensor([0.3064], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-941.5499], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-376.2949], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-933.4744], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-357.9623], device='cuda:0')\n",
            "logits: tensor([10.2571], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8076], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8333], device='cuda:0')\n",
            " 98% 6117/6237 [1:43:57<02:30,  1.25s/it]losses: tensor([0.0789], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-448.1118], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-521.3052], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-454.0779], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-502.2731], device='cuda:0')\n",
            "logits: tensor([24.9982], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5966], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9032], device='cuda:0')\n",
            " 98% 6118/6237 [1:43:58<02:13,  1.12s/it]losses: tensor([0.1956], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1240.8964], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-515.6153], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1227.7194], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-487.1138], device='cuda:0')\n",
            "logits: tensor([15.3245], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.3177], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8501], device='cuda:0')\n",
            " 98% 6119/6237 [1:43:59<02:27,  1.25s/it]losses: tensor([0.0631], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-835.0887], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-419.5396], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-842.8857], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.0266], device='cuda:0')\n",
            "logits: tensor([27.3100], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7797], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9513], device='cuda:0')\n",
            "{'loss': 0.1352, 'learning_rate': 1.1491181186531266e-08, 'rewards/real': -0.12562395632266998, 'rewards/generated': -2.8923499584198, 'rewards/accuracies': 1.0, 'rewards/margins': 2.766726016998291, 'logps/generated': -454.7925720214844, 'logps/real': -526.63330078125, 'logits/generated': -1.3813893795013428, 'logits/real': -1.3978698253631592, 'epoch': 2.94}\n",
            " 98% 6120/6237 [1:44:00<02:17,  1.17s/it]losses: tensor([0.0349], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-334.7722], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.7464], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-347.1992], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.7906], device='cuda:0')\n",
            "logits: tensor([33.3828], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2427], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0956], device='cuda:0')\n",
            " 98% 6121/6237 [1:44:01<01:54,  1.02it/s]losses: tensor([0.1445], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-269.0798], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-433.2139], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-276.5728], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.0915], device='cuda:0')\n",
            "logits: tensor([18.6154], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7493], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1122], device='cuda:0')\n",
            " 98% 6122/6237 [1:44:02<01:45,  1.09it/s]losses: tensor([0.0250], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-162.6626], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-491.0150], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-161.2634], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-452.8566], device='cuda:0')\n",
            "logits: tensor([36.7593], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1399], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8158], device='cuda:0')\n",
            " 98% 6123/6237 [1:44:03<02:07,  1.12s/it]losses: tensor([0.0595], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-637.1097], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.2974], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-652.1315], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-480.4003], device='cuda:0')\n",
            "logits: tensor([27.9188], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5022], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2897], device='cuda:0')\n",
            " 98% 6124/6237 [1:44:04<01:56,  1.04s/it]losses: tensor([0.1888], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-623.5523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-354.3468], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-624.9623], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-340.0444], device='cuda:0')\n",
            "logits: tensor([15.7124], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1410], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4302], device='cuda:0')\n",
            " 98% 6125/6237 [1:44:05<01:58,  1.06s/it]losses: tensor([0.0171], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-302.3942], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-469.0733], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-301.1392], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-427.2350], device='cuda:0')\n",
            "logits: tensor([40.5833], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1255], device='cuda:0')\n",
            "generated_rewards: tensor([-4.1838], device='cuda:0')\n",
            " 98% 6126/6237 [1:44:06<01:48,  1.02it/s]losses: tensor([0.2083], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1254.0079], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-465.5656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1247.2155], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-444.1464], device='cuda:0')\n",
            "logits: tensor([14.6267], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6792], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1419], device='cuda:0')\n",
            " 98% 6127/6237 [1:44:07<02:00,  1.10s/it]losses: tensor([0.1874], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-292.7547], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-347.5161], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-294.1097], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-333.0779], device='cuda:0')\n",
            "logits: tensor([15.7932], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1355], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4438], device='cuda:0')\n",
            " 98% 6128/6237 [1:44:09<02:16,  1.25s/it]losses: tensor([0.0326], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-474.8214], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-609.9153], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-471.2594], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-572.2717], device='cuda:0')\n",
            "logits: tensor([34.0815], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3562], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7644], device='cuda:0')\n",
            " 98% 6129/6237 [1:44:11<02:22,  1.32s/it]losses: tensor([0.0313], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-152.7516], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.9523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-152.8056], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-386.5067], device='cuda:0')\n",
            "logits: tensor([34.4997], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0054], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4446], device='cuda:0')\n",
            "{'loss': 0.0929, 'learning_rate': 1.0600391947265277e-08, 'rewards/real': 0.24752089381217957, 'rewards/generated': -2.4722094535827637, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7197303771972656, 'logps/generated': -456.8641662597656, 'logps/real': -450.39068603515625, 'logits/generated': -1.3758594989776611, 'logits/real': -1.3800878524780273, 'epoch': 2.95}\n",
            " 98% 6130/6237 [1:44:12<02:14,  1.26s/it]losses: tensor([0.1692], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-710.2113], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-492.9117], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-711.6194], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-477.4142], device='cuda:0')\n",
            "logits: tensor([16.9056], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1408], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5498], device='cuda:0')\n",
            " 98% 6131/6237 [1:44:13<02:02,  1.16s/it]losses: tensor([0.0804], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-641.2756], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-371.2955], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-651.7266], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-356.9492], device='cuda:0')\n",
            "logits: tensor([24.7972], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0451], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4346], device='cuda:0')\n",
            " 98% 6132/6237 [1:44:13<01:43,  1.01it/s]losses: tensor([0.0458], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-593.6812], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-500.4123], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-598.9231], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-475.0497], device='cuda:0')\n",
            "logits: tensor([30.6045], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5242], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5363], device='cuda:0')\n",
            " 98% 6133/6237 [1:44:14<01:45,  1.02s/it]losses: tensor([0.0426], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1410.3496], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-498.8846], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1419.3154], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.5013], device='cuda:0')\n",
            "logits: tensor([31.3491], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8966], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2383], device='cuda:0')\n",
            " 98% 6134/6237 [1:44:16<02:01,  1.18s/it]losses: tensor([0.0057], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-161.6390], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-428.6393], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-158.1048], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-373.4048], device='cuda:0')\n",
            "logits: tensor([51.7003], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3534], device='cuda:0')\n",
            "generated_rewards: tensor([-5.5234], device='cuda:0')\n",
            " 98% 6135/6237 [1:44:16<01:39,  1.03it/s]losses: tensor([0.1359], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-580.9733], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.3602], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-598.3000], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-332.4120], device='cuda:0')\n",
            "logits: tensor([19.2749], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.7327], device='cuda:0')\n",
            "generated_rewards: tensor([-0.1948], device='cuda:0')\n",
            " 98% 6136/6237 [1:44:17<01:30,  1.12it/s]losses: tensor([0.0209], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-416.5780], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.8491], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-422.7528], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-384.4406], device='cuda:0')\n",
            "logits: tensor([38.5833], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6175], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2408], device='cuda:0')\n",
            " 98% 6137/6237 [1:44:17<01:14,  1.35it/s]losses: tensor([0.0691], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-140.8968], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-260.6256], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-142.7222], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-236.0779], device='cuda:0')\n",
            "logits: tensor([26.3731], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1825], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4548], device='cuda:0')\n",
            " 98% 6138/6237 [1:44:19<01:37,  1.01it/s]losses: tensor([0.1323], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-563.8598], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-490.4624], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-556.6582], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-463.7058], device='cuda:0')\n",
            "logits: tensor([19.5550], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.7202], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6757], device='cuda:0')\n",
            " 98% 6139/6237 [1:44:20<01:30,  1.09it/s]losses: tensor([0.0622], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-145.8683], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-391.4297], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-148.6736], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.7717], device='cuda:0')\n",
            "logits: tensor([27.4634], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2805], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4658], device='cuda:0')\n",
            "{'loss': 0.0764, 'learning_rate': 9.709602707999286e-09, 'rewards/real': 0.4346318244934082, 'rewards/generated': -2.4314308166503906, 'rewards/accuracies': 1.0, 'rewards/margins': 2.866062641143799, 'logps/generated': -418.5870666503906, 'logps/real': -536.5333251953125, 'logits/generated': -1.3710038661956787, 'logits/real': -1.2879635095596313, 'epoch': 2.95}\n",
            " 98% 6140/6237 [1:44:20<01:20,  1.21it/s]losses: tensor([0.1715], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1053.0043], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-503.8249], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1037.6151], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-471.6745], device='cuda:0')\n",
            "logits: tensor([16.7613], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5389], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2150], device='cuda:0')\n",
            " 98% 6141/6237 [1:44:22<01:34,  1.02it/s]losses: tensor([0.0671], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-459.2761], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-501.2353], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-461.4101], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-476.6857], device='cuda:0')\n",
            "logits: tensor([26.6836], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2134], device='cuda:0')\n",
            "generated_rewards: tensor([-2.4550], device='cuda:0')\n",
            " 98% 6142/6237 [1:44:23<01:46,  1.12s/it]losses: tensor([0.0851], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-113.6727], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-432.4756], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-109.8747], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.4680], device='cuda:0')\n",
            "logits: tensor([24.2097], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3798], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8008], device='cuda:0')\n",
            " 98% 6143/6237 [1:44:24<01:50,  1.18s/it]losses: tensor([0.3008], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-840.6436], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-502.1024], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-832.6395], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-483.6271], device='cuda:0')\n",
            "logits: tensor([10.4713], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8004], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8475], device='cuda:0')\n",
            " 99% 6144/6237 [1:44:26<01:47,  1.15s/it]losses: tensor([0.0306], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-119.7733], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-373.6680], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-129.3948], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-348.5710], device='cuda:0')\n",
            "logits: tensor([34.7185], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9621], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5097], device='cuda:0')\n",
            " 99% 6145/6237 [1:44:27<01:51,  1.21s/it]losses: tensor([0.0444], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-438.9003], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.8554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-422.3030], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.3460], device='cuda:0')\n",
            "logits: tensor([30.9121], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.6597], device='cuda:0')\n",
            "generated_rewards: tensor([-4.7509], device='cuda:0')\n",
            " 99% 6146/6237 [1:44:27<01:30,  1.00it/s]losses: tensor([0.0770], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1194.1003], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.7571], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1186.0168], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-460.4163], device='cuda:0')\n",
            "logits: tensor([25.2573], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8083], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3341], device='cuda:0')\n",
            " 99% 6147/6237 [1:44:29<01:36,  1.07s/it]losses: tensor([0.0320], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-383.8045], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-566.0220], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-388.2687], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-536.2139], device='cuda:0')\n",
            "logits: tensor([34.2723], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4464], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9808], device='cuda:0')\n",
            " 99% 6148/6237 [1:44:30<01:45,  1.19s/it]losses: tensor([0.0119], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-157.7962], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-505.5049], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-178.6170], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-482.0379], device='cuda:0')\n",
            "logits: tensor([44.2878], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([2.0821], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3467], device='cuda:0')\n",
            " 99% 6149/6237 [1:44:31<01:32,  1.06s/it]losses: tensor([0.0006], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-347.9094], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-531.3775], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-356.4156], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-465.4935], device='cuda:0')\n",
            "logits: tensor([74.3902], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8506], device='cuda:0')\n",
            "generated_rewards: tensor([-6.5884], device='cuda:0')\n",
            "{'loss': 0.0821, 'learning_rate': 8.818813468733297e-09, 'rewards/real': -0.06325261294841766, 'rewards/generated': -3.282893657684326, 'rewards/accuracies': 1.0, 'rewards/margins': 3.2196414470672607, 'logps/generated': -484.9822692871094, 'logps/real': -510.8880920410156, 'logits/generated': -1.5006353855133057, 'logits/real': -1.5617170333862305, 'epoch': 2.96}\n",
            " 99% 6150/6237 [1:44:31<01:17,  1.13it/s]losses: tensor([0.0104], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-257.9144], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-480.6559], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-260.4907], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-437.6274], device='cuda:0')\n",
            "logits: tensor([45.6048], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2576], device='cuda:0')\n",
            "generated_rewards: tensor([-4.3029], device='cuda:0')\n",
            " 99% 6151/6237 [1:44:32<01:10,  1.22it/s]losses: tensor([0.0058], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-340.1899], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.9395], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-342.4398], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-438.7751], device='cuda:0')\n",
            "logits: tensor([51.4142], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2250], device='cuda:0')\n",
            "generated_rewards: tensor([-4.9164], device='cuda:0')\n",
            " 99% 6152/6237 [1:44:33<01:01,  1.37it/s]losses: tensor([0.0265], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-198.9490], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-621.5662], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-201.3325], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-587.7947], device='cuda:0')\n",
            "logits: tensor([36.1550], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2383], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3771], device='cuda:0')\n",
            " 99% 6153/6237 [1:44:34<01:20,  1.05it/s]losses: tensor([0.0529], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-92.6066], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-302.9873], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-111.6727], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-292.9291], device='cuda:0')\n",
            "logits: tensor([29.1242], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.9066], device='cuda:0')\n",
            "generated_rewards: tensor([-1.0058], device='cuda:0')\n",
            " 99% 6154/6237 [1:44:35<01:10,  1.17it/s]losses: tensor([0.1745], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-187.6563], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-543.5929], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-190.7233], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-530.0869], device='cuda:0')\n",
            "logits: tensor([16.5730], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3067], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3506], device='cuda:0')\n",
            " 99% 6155/6237 [1:44:36<01:25,  1.05s/it]losses: tensor([0.0223], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-320.5109], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-416.8094], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-325.2622], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-383.6307], device='cuda:0')\n",
            "logits: tensor([37.9300], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4751], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3179], device='cuda:0')\n",
            " 99% 6156/6237 [1:44:37<01:14,  1.09it/s]losses: tensor([0.4969], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1104.0940], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-258.0782], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1103.8728], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-253.4495], device='cuda:0')\n",
            "logits: tensor([4.4075], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0221], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4629], device='cuda:0')\n",
            " 99% 6157/6237 [1:44:38<01:18,  1.02it/s]losses: tensor([0.0148], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-292.9744], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-542.8048], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-296.1455], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-503.8853], device='cuda:0')\n",
            "logits: tensor([42.0906], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3171], device='cuda:0')\n",
            "generated_rewards: tensor([-3.8920], device='cuda:0')\n",
            " 99% 6158/6237 [1:44:39<01:28,  1.13s/it]losses: tensor([0.0367], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-126.1420], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-391.5599], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-126.0974], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-358.6432], device='cuda:0')\n",
            "logits: tensor([32.8722], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0045], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2917], device='cuda:0')\n",
            " 99% 6159/6237 [1:44:40<01:27,  1.12s/it]losses: tensor([0.1581], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-404.2268], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-471.5993], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-392.7071], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.4374], device='cuda:0')\n",
            "logits: tensor([17.6422], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1520], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9162], device='cuda:0')\n",
            "{'loss': 0.0999, 'learning_rate': 7.928024229467308e-09, 'rewards/real': 0.2547968626022339, 'rewards/generated': -2.8833401203155518, 'rewards/accuracies': 1.0, 'rewards/margins': 3.138137102127075, 'logps/generated': -451.75933837890625, 'logps/real': -332.52642822265625, 'logits/generated': -1.1675009727478027, 'logits/real': -1.2982499599456787, 'epoch': 2.96}\n",
            " 99% 6160/6237 [1:44:41<01:09,  1.11it/s]losses: tensor([0.0028], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-317.5599], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.0071], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-333.3261], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-420.0198], device='cuda:0')\n",
            "logits: tensor([58.7535], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.5766], device='cuda:0')\n",
            "generated_rewards: tensor([-4.2987], device='cuda:0')\n",
            " 99% 6161/6237 [1:44:41<01:01,  1.23it/s]losses: tensor([0.1007], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1147.3584], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-468.0375], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1151.3687], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-449.6009], device='cuda:0')\n",
            "logits: tensor([22.4468], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4010], device='cuda:0')\n",
            "generated_rewards: tensor([-1.8437], device='cuda:0')\n",
            " 99% 6162/6237 [1:44:43<01:10,  1.06it/s]losses: tensor([0.0455], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-604.9393], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-452.5086], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-614.1655], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-431.0589], device='cuda:0')\n",
            "logits: tensor([30.6759], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9226], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1450], device='cuda:0')\n",
            " 99% 6163/6237 [1:44:43<01:04,  1.15it/s]losses: tensor([0.1014], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-632.1955], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-427.3352], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-627.8176], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.5822], device='cuda:0')\n",
            "logits: tensor([22.3752], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4378], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6753], device='cuda:0')\n",
            " 99% 6164/6237 [1:44:44<01:05,  1.11it/s]losses: tensor([0.0641], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-314.9308], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-425.3241], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-321.3686], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-404.6138], device='cuda:0')\n",
            "logits: tensor([27.1480], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6438], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0710], device='cuda:0')\n",
            " 99% 6165/6237 [1:44:45<00:56,  1.28it/s]losses: tensor([0.1275], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-542.0623], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-437.6278], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-530.2455], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-405.8573], device='cuda:0')\n",
            "logits: tensor([19.9537], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.1817], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1771], device='cuda:0')\n",
            " 99% 6166/6237 [1:44:46<01:00,  1.18it/s]losses: tensor([0.3645], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-374.7455], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-334.1772], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-378.9423], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-330.1591], device='cuda:0')\n",
            "logits: tensor([8.2149], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4197], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4018], device='cuda:0')\n",
            " 99% 6167/6237 [1:44:47<01:02,  1.12it/s]losses: tensor([0.0455], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-638.6800], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-514.5250], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-638.1166], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-483.2860], device='cuda:0')\n",
            "logits: tensor([30.6756], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0563], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1239], device='cuda:0')\n",
            " 99% 6168/6237 [1:44:48<01:00,  1.14it/s]losses: tensor([0.0117], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-118.9047], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-493.4593], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-126.3867], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-456.4865], device='cuda:0')\n",
            "logits: tensor([44.4548], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7482], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6973], device='cuda:0')\n",
            " 99% 6169/6237 [1:44:49<01:16,  1.13s/it]losses: tensor([0.0062], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-267.0094], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-515.6104], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-266.6207], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-464.3759], device='cuda:0')\n",
            "logits: tensor([50.8457], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0389], device='cuda:0')\n",
            "generated_rewards: tensor([-5.1234], device='cuda:0')\n",
            "{'loss': 0.087, 'learning_rate': 7.037234990201318e-09, 'rewards/real': 0.2997235953807831, 'rewards/generated': -2.855717658996582, 'rewards/accuracies': 1.0, 'rewards/margins': 3.1554408073425293, 'logps/generated': -453.1612243652344, 'logps/real': -495.838623046875, 'logits/generated': -0.9627405405044556, 'logits/real': -0.9988352060317993, 'epoch': 2.97}\n",
            " 99% 6170/6237 [1:44:50<01:13,  1.10s/it]losses: tensor([0.2996], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-250.8161], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-239.6070], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.4510], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-236.7256], device='cuda:0')\n",
            "logits: tensor([10.5163], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7635], device='cuda:0')\n",
            "generated_rewards: tensor([-0.2881], device='cuda:0')\n",
            " 99% 6171/6237 [1:44:51<01:04,  1.02it/s]losses: tensor([0.0006], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-131.2656], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-978.5611], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-134.5633], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-907.6756], device='cuda:0')\n",
            "logits: tensor([74.1832], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3298], device='cuda:0')\n",
            "generated_rewards: tensor([-7.0886], device='cuda:0')\n",
            " 99% 6172/6237 [1:44:52<00:55,  1.16it/s]losses: tensor([6.9434e-06], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-141.6446], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-2392.0649], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-148.2189], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-2279.8623], device='cuda:0')\n",
            "logits: tensor([118.7771], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6574], device='cuda:0')\n",
            "generated_rewards: tensor([-11.2203], device='cuda:0')\n",
            " 99% 6173/6237 [1:44:53<00:57,  1.11it/s]losses: tensor([0.1045], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-277.4811], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-528.9542], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-290.3279], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-519.7473], device='cuda:0')\n",
            "logits: tensor([22.0537], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2847], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9207], device='cuda:0')\n",
            " 99% 6174/6237 [1:44:53<00:54,  1.16it/s]losses: tensor([0.0793], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-320.7090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.3309], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-316.5914], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-456.2713], device='cuda:0')\n",
            "logits: tensor([24.9420], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4118], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9060], device='cuda:0')\n",
            " 99% 6175/6237 [1:44:54<00:53,  1.17it/s]losses: tensor([0.2062], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-673.1523], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-538.8022], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-667.5695], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-518.4812], device='cuda:0')\n",
            "logits: tensor([14.7382], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.5583], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0321], device='cuda:0')\n",
            " 99% 6176/6237 [1:44:56<01:07,  1.11s/it]losses: tensor([0.0083], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-167.3398], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-448.0215], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-179.8583], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-412.6387], device='cuda:0')\n",
            "logits: tensor([47.9013], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.2518], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5383], device='cuda:0')\n",
            " 99% 6177/6237 [1:44:58<01:15,  1.26s/it]losses: tensor([0.0658], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-821.5078], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-384.1457], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-829.2171], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-364.9719], device='cuda:0')\n",
            "logits: tensor([26.8831], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7709], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9174], device='cuda:0')\n",
            " 99% 6178/6237 [1:44:59<01:13,  1.24s/it]losses: tensor([0.0144], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-324.3531], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-578.3550], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-321.2612], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-532.8995], device='cuda:0')\n",
            "logits: tensor([42.3635], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.3092], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5455], device='cuda:0')\n",
            " 99% 6179/6237 [1:45:00<01:16,  1.31s/it]losses: tensor([0.1940], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-980.2709], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.3726], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-983.7682], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-445.4551], device='cuda:0')\n",
            "logits: tensor([15.4148], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3497], device='cuda:0')\n",
            "generated_rewards: tensor([-1.1918], device='cuda:0')\n",
            "{'loss': 0.0973, 'learning_rate': 6.1464457509353286e-09, 'rewards/real': 0.412863165140152, 'rewards/generated': -3.5648677349090576, 'rewards/accuracies': 1.0, 'rewards/margins': 3.9777309894561768, 'logps/generated': -703.1214599609375, 'logps/real': -408.8540344238281, 'logits/generated': -1.1103051900863647, 'logits/real': -1.3808963298797607, 'epoch': 2.97}\n",
            " 99% 6180/6237 [1:45:01<01:10,  1.24s/it]losses: tensor([0.0873], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-361.7408], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-318.5888], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-373.5203], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-306.4271], device='cuda:0')\n",
            "logits: tensor([23.9413], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1780], device='cuda:0')\n",
            "generated_rewards: tensor([-1.2162], device='cuda:0')\n",
            " 99% 6181/6237 [1:45:02<01:00,  1.08s/it]losses: tensor([0.1093], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-791.0278], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-463.0202], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-792.0759], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-442.4804], device='cuda:0')\n",
            "logits: tensor([21.5878], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1048], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0540], device='cuda:0')\n",
            " 99% 6182/6237 [1:45:03<01:00,  1.10s/it]losses: tensor([0.0916], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-596.9536], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-400.8170], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-590.1007], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-370.5203], device='cuda:0')\n",
            "logits: tensor([23.4438], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.6853], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0297], device='cuda:0')\n",
            " 99% 6183/6237 [1:45:04<00:55,  1.04s/it]losses: tensor([0.0065], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-151.2509], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-495.2002], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-165.5719], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-459.2426], device='cuda:0')\n",
            "logits: tensor([50.2787], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.4321], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5958], device='cuda:0')\n",
            " 99% 6184/6237 [1:45:05<00:58,  1.11s/it]losses: tensor([0.0277], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-234.3802], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-447.8099], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-243.3932], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-421.1088], device='cuda:0')\n",
            "logits: tensor([35.7141], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9013], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6701], device='cuda:0')\n",
            " 99% 6185/6237 [1:45:07<00:57,  1.11s/it]losses: tensor([0.0541], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-354.6506], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-508.0483], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-338.3658], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-462.8620], device='cuda:0')\n",
            "logits: tensor([28.9015], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.6285], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5186], device='cuda:0')\n",
            " 99% 6186/6237 [1:45:07<00:50,  1.00it/s]losses: tensor([0.3240], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-544.6701], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-192.0265], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-553.9376], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-191.6891], device='cuda:0')\n",
            "logits: tensor([9.6049], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9268], device='cuda:0')\n",
            "generated_rewards: tensor([-0.0337], device='cuda:0')\n",
            " 99% 6187/6237 [1:45:08<00:44,  1.11it/s]losses: tensor([0.0593], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-904.7605], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-472.5199], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-899.8301], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.6313], device='cuda:0')\n",
            "logits: tensor([27.9582], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4930], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2889], device='cuda:0')\n",
            " 99% 6188/6237 [1:45:09<00:50,  1.04s/it]losses: tensor([0.5402], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-253.6943], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-270.1447], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-253.8426], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-266.9582], device='cuda:0')\n",
            "logits: tensor([3.3347], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0148], device='cuda:0')\n",
            "generated_rewards: tensor([-0.3186], device='cuda:0')\n",
            " 99% 6189/6237 [1:45:11<00:56,  1.18s/it]losses: tensor([0.0165], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-203.1372], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-499.2361], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-212.8955], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-468.0071], device='cuda:0')\n",
            "logits: tensor([40.9872], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9758], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1229], device='cuda:0')\n",
            "{'loss': 0.1317, 'learning_rate': 5.2556565116693386e-09, 'rewards/real': 0.2726762294769287, 'rewards/generated': -2.3848471641540527, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6575236320495605, 'logps/generated': -406.74114990234375, 'logps/real': -439.6266174316406, 'logits/generated': -1.2754663228988647, 'logits/real': -1.2244871854782104, 'epoch': 2.98}\n",
            " 99% 6190/6237 [1:45:11<00:45,  1.02it/s]losses: tensor([0.0481], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-517.8735], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-363.6010], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-525.7739], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-341.3923], device='cuda:0')\n",
            "logits: tensor([30.1089], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7900], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2209], device='cuda:0')\n",
            " 99% 6191/6237 [1:45:12<00:40,  1.12it/s]losses: tensor([0.0322], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-133.5453], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-485.6625], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-138.4642], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-456.3694], device='cuda:0')\n",
            "logits: tensor([34.2120], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4919], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9293], device='cuda:0')\n",
            " 99% 6192/6237 [1:45:13<00:40,  1.11it/s]losses: tensor([0.1352], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-491.1733], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-455.4284], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-474.9966], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-419.9243], device='cuda:0')\n",
            "logits: tensor([19.3275], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.6177], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5504], device='cuda:0')\n",
            " 99% 6193/6237 [1:45:14<00:36,  1.20it/s]losses: tensor([0.0694], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-533.9768], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-431.7839], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-534.6979], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-406.1690], device='cuda:0')\n",
            "logits: tensor([26.3359], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.0721], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5615], device='cuda:0')\n",
            " 99% 6194/6237 [1:45:14<00:36,  1.16it/s]losses: tensor([0.1664], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-946.3357], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-521.4290], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-948.8115], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-506.8120], device='cuda:0')\n",
            "logits: tensor([17.0928], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2476], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4617], device='cuda:0')\n",
            " 99% 6195/6237 [1:45:16<00:38,  1.09it/s]losses: tensor([0.0110], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-235.8314], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-464.2594], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-243.6121], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-426.9633], device='cuda:0')\n",
            "logits: tensor([45.0768], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7781], device='cuda:0')\n",
            "generated_rewards: tensor([-3.7296], device='cuda:0')\n",
            " 99% 6196/6237 [1:45:16<00:33,  1.23it/s]losses: tensor([0.0152], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-460.0395], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-421.6410], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-471.4937], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-391.3000], device='cuda:0')\n",
            "logits: tensor([41.7952], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1454], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0341], device='cuda:0')\n",
            " 99% 6197/6237 [1:45:17<00:29,  1.37it/s]losses: tensor([0.1352], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-262.7999], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-330.9407], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-258.2319], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-307.0501], device='cuda:0')\n",
            "logits: tensor([19.3225], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4568], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3891], device='cuda:0')\n",
            " 99% 6198/6237 [1:45:17<00:28,  1.35it/s]losses: tensor([0.0578], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-998.1434], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-487.0428], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-997.6437], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-458.3306], device='cuda:0')\n",
            "logits: tensor([28.2126], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0500], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8712], device='cuda:0')\n",
            " 99% 6199/6237 [1:45:18<00:31,  1.19it/s]losses: tensor([0.0287], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-422.2200], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-424.7874], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-423.6287], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-390.8402], device='cuda:0')\n",
            "logits: tensor([35.3559], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1409], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3947], device='cuda:0')\n",
            "{'loss': 0.0699, 'learning_rate': 4.364867272403349e-09, 'rewards/real': 0.15415343642234802, 'rewards/generated': -2.814246654510498, 'rewards/accuracies': 1.0, 'rewards/margins': 2.968400239944458, 'logps/generated': -438.6576232910156, 'logps/real': -500.19390869140625, 'logits/generated': -1.1830308437347412, 'logits/real': -1.1656513214111328, 'epoch': 2.98}\n",
            " 99% 6200/6237 [1:45:19<00:31,  1.19it/s]losses: tensor([0.0265], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-108.5578], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.9857], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-116.5008], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.7649], device='cuda:0')\n",
            "logits: tensor([36.1638], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.7943], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8221], device='cuda:0')\n",
            " 99% 6201/6237 [1:45:21<00:39,  1.10s/it]losses: tensor([0.1425], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-464.3546], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-490.4373], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-450.1353], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-457.4555], device='cuda:0')\n",
            "logits: tensor([18.7625], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4219], device='cuda:0')\n",
            "generated_rewards: tensor([-3.2982], device='cuda:0')\n",
            " 99% 6202/6237 [1:45:22<00:34,  1.01it/s]losses: tensor([0.0197], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-212.1278], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-517.8691], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-211.6479], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-478.2283], device='cuda:0')\n",
            "logits: tensor([39.1610], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0480], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9641], device='cuda:0')\n",
            " 99% 6203/6237 [1:45:23<00:36,  1.06s/it]losses: tensor([5.5923e-07], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-88.7774], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-1923.1091], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-92.5602], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-1782.9249], device='cuda:0')\n",
            "logits: tensor([143.9670], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3783], device='cuda:0')\n",
            "generated_rewards: tensor([-14.0184], device='cuda:0')\n",
            " 99% 6204/6237 [1:45:24<00:33,  1.02s/it]losses: tensor([0.0154], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-120.8198], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.2219], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-126.6236], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-400.3419], device='cuda:0')\n",
            "logits: tensor([41.6837], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.5804], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5880], device='cuda:0')\n",
            " 99% 6205/6237 [1:45:25<00:31,  1.00it/s]losses: tensor([0.4937], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1147.7192], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-415.1198], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1129.8461], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-392.7573], device='cuda:0')\n",
            "logits: tensor([4.4893], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7873], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2362], device='cuda:0')\n",
            "100% 6206/6237 [1:45:27<00:39,  1.26s/it]losses: tensor([0.0249], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-754.5171], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-462.6834], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-752.3010], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-423.6465], device='cuda:0')\n",
            "logits: tensor([36.8209], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.2216], device='cuda:0')\n",
            "generated_rewards: tensor([-3.9037], device='cuda:0')\n",
            "100% 6207/6237 [1:45:28<00:35,  1.18s/it]losses: tensor([0.1207], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-669.6593], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-356.9853], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-668.5638], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-335.3557], device='cuda:0')\n",
            "logits: tensor([20.5341], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1095], device='cuda:0')\n",
            "generated_rewards: tensor([-2.1630], device='cuda:0')\n",
            "100% 6208/6237 [1:45:29<00:33,  1.16s/it]losses: tensor([0.0983], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1509.6282], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-466.4369], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1512.1530], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-446.2636], device='cuda:0')\n",
            "logits: tensor([22.6980], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2525], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0173], device='cuda:0')\n",
            "100% 6209/6237 [1:45:31<00:36,  1.32s/it]losses: tensor([0.0689], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1086.8569], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-486.5633], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1089.8170], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-463.1261], device='cuda:0')\n",
            "logits: tensor([26.3972], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2960], device='cuda:0')\n",
            "generated_rewards: tensor([-2.3437], device='cuda:0')\n",
            "{'loss': 0.1011, 'learning_rate': 3.4740780331373598e-09, 'rewards/real': -0.12869355082511902, 'rewards/generated': -4.035470485687256, 'rewards/accuracies': 1.0, 'rewards/margins': 3.9067771434783936, 'logps/generated': -597.6411743164062, 'logps/real': -616.3018188476562, 'logits/generated': -1.343992829322815, 'logits/real': -1.3900463581085205, 'epoch': 2.99}\n",
            "100% 6210/6237 [1:45:32<00:34,  1.26s/it]losses: tensor([0.5990], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-766.9849], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-513.6624], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-751.5095], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-496.2067], device='cuda:0')\n",
            "logits: tensor([1.9803], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.5475], device='cuda:0')\n",
            "generated_rewards: tensor([-1.7456], device='cuda:0')\n",
            "100% 6211/6237 [1:45:33<00:31,  1.20s/it]losses: tensor([0.1063], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1533.4263], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-549.1364], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1529.3085], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-523.1443], device='cuda:0')\n",
            "logits: tensor([21.8743], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.4118], device='cuda:0')\n",
            "generated_rewards: tensor([-2.5992], device='cuda:0')\n",
            "100% 6212/6237 [1:45:34<00:32,  1.32s/it]losses: tensor([0.0868], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-851.7474], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-457.8884], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-842.6315], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-424.7718], device='cuda:0')\n",
            "logits: tensor([24.0007], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.9116], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3117], device='cuda:0')\n",
            "100% 6213/6237 [1:45:35<00:30,  1.25s/it]losses: tensor([0.0110], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-133.5466], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-484.6713], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-135.3809], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-441.4631], device='cuda:0')\n",
            "logits: tensor([45.0425], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1834], device='cuda:0')\n",
            "generated_rewards: tensor([-4.3208], device='cuda:0')\n",
            "100% 6214/6237 [1:45:36<00:27,  1.18s/it]losses: tensor([0.1014], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-272.2090], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-420.7610], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-281.0520], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-407.2304], device='cuda:0')\n",
            "logits: tensor([22.3735], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8843], device='cuda:0')\n",
            "generated_rewards: tensor([-1.3531], device='cuda:0')\n",
            "100% 6215/6237 [1:45:38<00:27,  1.27s/it]losses: tensor([0.1878], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1011.3883], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-519.9873], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1000.6836], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-493.5135], device='cuda:0')\n",
            "logits: tensor([15.7691], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.0705], device='cuda:0')\n",
            "generated_rewards: tensor([-2.6474], device='cuda:0')\n",
            "100% 6216/6237 [1:45:39<00:25,  1.21s/it]losses: tensor([0.3387], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-289.6431], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-446.2743], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-291.6423], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-439.1890], device='cuda:0')\n",
            "logits: tensor([9.0845], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1999], device='cuda:0')\n",
            "generated_rewards: tensor([-0.7085], device='cuda:0')\n",
            "100% 6217/6237 [1:45:40<00:20,  1.01s/it]losses: tensor([0.0106], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-249.5187], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-412.0950], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-249.4545], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-366.6371], device='cuda:0')\n",
            "logits: tensor([45.3937], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.0064], device='cuda:0')\n",
            "generated_rewards: tensor([-4.5458], device='cuda:0')\n",
            "100% 6218/6237 [1:45:41<00:18,  1.00it/s]losses: tensor([0.0324], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-166.7571], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-356.2725], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-170.7660], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-326.1378], device='cuda:0')\n",
            "logits: tensor([34.1436], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.4009], device='cuda:0')\n",
            "generated_rewards: tensor([-3.0135], device='cuda:0')\n",
            "100% 6219/6237 [1:45:42<00:18,  1.01s/it]losses: tensor([0.6509], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1592.6575], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-459.7400], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1577.7750], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.9946], device='cuda:0')\n",
            "logits: tensor([0.8629], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.4882], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5745], device='cuda:0')\n",
            "{'loss': 0.2125, 'learning_rate': 2.58328879387137e-09, 'rewards/real': -0.3767501711845398, 'rewards/generated': -2.5820000171661377, 'rewards/accuracies': 1.0, 'rewards/margins': 2.205249547958374, 'logps/generated': -462.048828125, 'logps/real': -686.787841796875, 'logits/generated': -1.2255386114120483, 'logits/real': -1.293806791305542, 'epoch': 2.99}\n",
            "100% 6220/6237 [1:45:43<00:20,  1.23s/it]losses: tensor([0.1797], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-543.1086], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-406.9182], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-554.7148], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.2692], device='cuda:0')\n",
            "logits: tensor([16.2552], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.1606], device='cuda:0')\n",
            "generated_rewards: tensor([-0.4649], device='cuda:0')\n",
            "100% 6221/6237 [1:45:44<00:17,  1.12s/it]losses: tensor([0.0720], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-434.9093], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-359.6584], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-441.0548], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-339.8585], device='cuda:0')\n",
            "logits: tensor([25.9455], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6145], device='cuda:0')\n",
            "generated_rewards: tensor([-1.9800], device='cuda:0')\n",
            "100% 6222/6237 [1:45:45<00:14,  1.03it/s]losses: tensor([0.0136], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-257.5972], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-456.5507], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-266.5069], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-422.5679], device='cuda:0')\n",
            "logits: tensor([42.8925], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8910], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3983], device='cuda:0')\n",
            "100% 6223/6237 [1:45:45<00:12,  1.17it/s]losses: tensor([0.1285], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-780.6355], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-439.8740], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-763.6054], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-402.9756], device='cuda:0')\n",
            "logits: tensor([19.8683], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-1.7030], device='cuda:0')\n",
            "generated_rewards: tensor([-3.6898], device='cuda:0')\n",
            "100% 6224/6237 [1:45:47<00:14,  1.11s/it]losses: tensor([0.2478], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-315.0810], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-392.6422], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-306.8892], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-371.7621], device='cuda:0')\n",
            "logits: tensor([12.6883], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.8192], device='cuda:0')\n",
            "generated_rewards: tensor([-2.0880], device='cuda:0')\n",
            "100% 6225/6237 [1:45:48<00:11,  1.07it/s]losses: tensor([0.0855], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-872.8997], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-438.3885], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-874.2543], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-415.5843], device='cuda:0')\n",
            "logits: tensor([24.1589], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1355], device='cuda:0')\n",
            "generated_rewards: tensor([-2.2804], device='cuda:0')\n",
            "100% 6226/6237 [1:45:49<00:11,  1.02s/it]losses: tensor([0.0026], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-231.4872], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-541.0827], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-240.6859], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-490.7624], device='cuda:0')\n",
            "logits: tensor([59.5189], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9199], device='cuda:0')\n",
            "generated_rewards: tensor([-5.0320], device='cuda:0')\n",
            "100% 6227/6237 [1:45:50<00:11,  1.14s/it]losses: tensor([0.0126], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-204.0123], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-429.4341], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-212.3095], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-394.0312], device='cuda:0')\n",
            "logits: tensor([43.7001], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8297], device='cuda:0')\n",
            "generated_rewards: tensor([-3.5403], device='cuda:0')\n",
            "100% 6228/6237 [1:45:51<00:09,  1.09s/it]losses: tensor([0.0140], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-117.3304], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-544.2684], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-126.6085], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-510.9258], device='cuda:0')\n",
            "logits: tensor([42.6207], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.9278], device='cuda:0')\n",
            "generated_rewards: tensor([-3.3343], device='cuda:0')\n",
            "100% 6229/6237 [1:45:53<00:10,  1.32s/it]losses: tensor([0.2178], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-1119.4009], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-339.1136], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-1118.1963], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-323.7763], device='cuda:0')\n",
            "logits: tensor([14.1328], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([-0.1205], device='cuda:0')\n",
            "generated_rewards: tensor([-1.5337], device='cuda:0')\n",
            "{'loss': 0.0974, 'learning_rate': 1.6924995546053803e-09, 'rewards/real': 0.28363484144210815, 'rewards/generated': -2.7341747283935547, 'rewards/accuracies': 1.0, 'rewards/margins': 3.0178096294403076, 'logps/generated': -434.7930603027344, 'logps/real': -487.646240234375, 'logits/generated': -1.3221794366836548, 'logits/real': -1.3645983934402466, 'epoch': 3.0}\n",
            "100% 6230/6237 [1:45:55<00:09,  1.40s/it]losses: tensor([0.0172], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-165.3133], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-417.4071], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-176.1180], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-387.6689], device='cuda:0')\n",
            "logits: tensor([40.5429], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0805], device='cuda:0')\n",
            "generated_rewards: tensor([-2.9738], device='cuda:0')\n",
            "100% 6231/6237 [1:45:56<00:08,  1.42s/it]losses: tensor([0.2617], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-561.7622], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-297.0858], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-564.7904], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-288.0436], device='cuda:0')\n",
            "logits: tensor([12.0704], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.3028], device='cuda:0')\n",
            "generated_rewards: tensor([-0.9042], device='cuda:0')\n",
            "100% 6232/6237 [1:45:57<00:06,  1.35s/it]losses: tensor([0.0434], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-586.9116], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-483.3082], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-589.1609], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-454.4098], device='cuda:0')\n",
            "logits: tensor([31.1478], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.2249], device='cuda:0')\n",
            "generated_rewards: tensor([-2.8898], device='cuda:0')\n",
            "100% 6233/6237 [1:45:58<00:04,  1.12s/it]losses: tensor([0.0136], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-492.1206], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-436.0948], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-500.3671], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-401.4504], device='cuda:0')\n",
            "logits: tensor([42.8908], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.8247], device='cuda:0')\n",
            "generated_rewards: tensor([-3.4644], device='cuda:0')\n",
            "100% 6234/6237 [1:45:59<00:03,  1.00s/it]losses: tensor([0.0117], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-157.4554], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-551.0629], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-158.8335], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-508.0043], device='cuda:0')\n",
            "logits: tensor([44.4367], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.1378], device='cuda:0')\n",
            "generated_rewards: tensor([-4.3059], device='cuda:0')\n",
            "100% 6235/6237 [1:46:00<00:02,  1.18s/it]losses: tensor([0.0797], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-680.7922], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-360.3229], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-691.2039], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-345.8444], device='cuda:0')\n",
            "logits: tensor([24.8902], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([1.0412], device='cuda:0')\n",
            "generated_rewards: tensor([-1.4479], device='cuda:0')\n",
            "100% 6236/6237 [1:46:01<00:01,  1.06s/it]losses: tensor([0.0230], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "policy_real_logps: tensor([-275.6505], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "policy_generated_logps: tensor([-474.2937], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "opponent_real_logps: tensor([-282.1986], device='cuda:0')\n",
            "opponent_generated_logps: tensor([-443.2431], device='cuda:0')\n",
            "logits: tensor([37.5988], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "real_rewards: tensor([0.6548], device='cuda:0')\n",
            "generated_rewards: tensor([-3.1051], device='cuda:0')\n",
            "100% 6237/6237 [1:46:02<00:00,  1.17s/it][INFO|trainer.py:2926] 2025-05-13 18:05:10,412 >> Saving model checkpoint to outputs/tmp-checkpoint-6237\n",
            "[INFO|tokenization_utils_base.py:2433] 2025-05-13 18:05:10,467 >> tokenizer config file saved in outputs/tmp-checkpoint-6237/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2442] 2025-05-13 18:05:10,468 >> Special tokens file saved in outputs/tmp-checkpoint-6237/special_tokens_map.json\n",
            "[INFO|trainer.py:1962] 2025-05-13 18:05:10,743 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 6365.0175, 'train_samples_per_second': 0.98, 'train_steps_per_second': 0.98, 'train_loss': 0.29217964564165627, 'epoch': 3.0}\n",
            "100% 6237/6237 [1:46:03<00:00,  1.02s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.2922\n",
            "  train_runtime            = 1:46:05.01\n",
            "  train_samples            =       2079\n",
            "  train_samples_per_second =       0.98\n",
            "  train_steps_per_second   =       0.98\n",
            "2025-05-13 18:05:10 - INFO - __main__ - *** Training complete ***\n",
            "[INFO|trainer.py:2926] 2025-05-13 18:05:10,779 >> Saving model checkpoint to outputs\n",
            "[INFO|tokenization_utils_base.py:2433] 2025-05-13 18:05:10,814 >> tokenizer config file saved in outputs/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2442] 2025-05-13 18:05:10,815 >> Special tokens file saved in outputs/special_tokens_map.json\n",
            "[INFO|modelcard.py:452] 2025-05-13 18:05:11,030 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'dataset': {'name': './qwen2.5/datasets/iter1', 'type': './qwen2.5/datasets/iter1', 'config': None, 'split': 'None'}}\n",
            "[INFO|configuration_utils.py:473] 2025-05-13 18:05:11,033 >> Configuration saved in outputs/config.json\n",
            "2025-05-13 18:05:11 - INFO - __main__ - *** Waiting for all processes to finish ***\n",
            "2025-05-13 18:05:11 - INFO - __main__ - *** Run complete! ***\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33msuper-monkey-49\u001b[0m at: \u001b[34mhttps://wandb.ai/mu_qianyu-mipt/huggingface/runs/d9h0mwzp\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250513_161906-d9h0mwzp/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем датасет для итерации 2 для дальнейшей оценки качества разных итераций модели"
      ],
      "metadata": {
        "id": "CRGBmpy54at0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "-5cWcx3K0p9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"./qwen2.5/spin_iter2/checkpoint-6237\")\n",
        "model = PeftModel.from_pretrained(\n",
        "    AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\"),\n",
        "    './qwen2.5/spin_iter2/checkpoint-6237',\n",
        "    config=lora_config\n",
        ").base_model.merge_and_unload()"
      ],
      "metadata": {
        "id": "28qo7lVv4Z5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://medium.com/@geronimo7/llms-multi-gpu-inference-with-accelerate-5a8333e4c5db\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import gather_object\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "import argparse\n",
        "import torch, time, json, os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "from accelerate.utils import InitProcessGroupKwargs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "kwargs = InitProcessGroupKwargs(timeout=timedelta(seconds=36000))\n",
        "accelerator = Accelerator(kwargs_handlers=[kwargs])\n",
        "\n",
        "def prepare_prompts(prompts, tokenizer, batch_size=4):\n",
        "    \"\"\"Prepare prompts for tokenization.\"\"\"\n",
        "    batches=[prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)]\n",
        "    batches_tok=[]\n",
        "    tokenizer.padding_side=\"left\"\n",
        "    for prompt_batch in batches:\n",
        "        batches_tok.append(\n",
        "            tokenizer(\n",
        "                prompt_batch,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='longest',\n",
        "                truncation=False,\n",
        "                pad_to_multiple_of=8,\n",
        "                add_special_tokens=False).to(\"cuda\")\n",
        "            )\n",
        "    tokenizer.padding_side=\"right\"\n",
        "    return batches_tok\n",
        "\n",
        "model_path = './qwen2.5/models/iter2/checkpoint-6237'\n",
        "data_frac = 0\n",
        "frac_len = 0\n",
        "batch_size = 4\n",
        "output_dir = './qwen2.5/generated/iter2'\n",
        "split = 'test'\n",
        "\n",
        "# load a base model and tokenizer\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(\n",
        "    AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\"),\n",
        "    model_path,\n",
        "    config=lora_config\n",
        ").base_model.merge_and_unload().to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# load data\n",
        "data = load_dataset('./qwen2.5/reformatted', split=split + '[:1%]')\n",
        "data = data.shuffle(seed=42)\n",
        "if frac_len > 0:\n",
        "    sub_len = frac_len\n",
        "    if sub_len*(data_frac+1) > len(data):\n",
        "        data = data[sub_len*data_frac:]['real']\n",
        "    else:\n",
        "        data = data[sub_len*data_frac:sub_len*(data_frac+1)]['real']\n",
        "else:\n",
        "    data = data[:]['real']\n",
        "\n",
        "prompts_all = [\"### Instruction: \" + data[idx][0]['content'] + \"\\n\\n### Response: \" for idx in range(len(data))]\n",
        "prompts_old = [data[idx][0]['content'] for idx in range(len(data))]\n",
        "corrects_all = [data[idx][1]['content'] for idx in range(len(data))]\n",
        "\n",
        "# sync GPUs and start the timer\n",
        "accelerator.wait_for_everyone()\n",
        "start=time.time()\n",
        "\n",
        "# divide the prompt list onto the available GPUs\n",
        "with accelerator.split_between_processes(prompts_all) as prompts:\n",
        "    results = []\n",
        "    prompt_batches=prepare_prompts(prompts, tokenizer, batch_size=batch_size)\n",
        "\n",
        "    for prompts_tokenized in tqdm(prompt_batches):\n",
        "        # set max_new_tokens smaller for faster inference\n",
        "        outputs_tokenized=model.generate(**prompts_tokenized, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        # remove prompt from gen. tokens\n",
        "        outputs_tokenized=[ tok_out[len(tok_in):]\n",
        "            for tok_in, tok_out in zip(prompts_tokenized[\"input_ids\"], outputs_tokenized) ]\n",
        "        # decode gen. tokens\n",
        "        outputs=tokenizer.batch_decode(outputs_tokenized)\n",
        "        results.extend(outputs)\n",
        "\n",
        "# collect results from all the GPUs and remove paddings\n",
        "results_gathered=gather_object(results)\n",
        "results = [r.replace(\"</s>\",\"\").lstrip() for r in results_gathered]\n",
        "\n",
        "if accelerator.is_local_main_process:\n",
        "    timediff=time.time()-start\n",
        "    print(f\"time elapsed: {timediff}\")\n",
        "\n",
        "    # collecting data\n",
        "    for idx in range(len(corrects_all)):\n",
        "        d = {\"real\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": corrects_all[idx]}], \"generated\": [{\"role\": \"user\", \"content\": prompts_old[idx]}, {\"role\": \"assistant\", \"content\": results[idx]}]}\n",
        "        if split == 'test':\n",
        "            filename = f\"{output_dir}/loser_{data_frac}_test.jsonl\"\n",
        "        else:\n",
        "            filename = f\"{output_dir}/loser_{data_frac}.jsonl\"\n",
        "        with open(filename, 'a') as f:\n",
        "            json.dump(d, f)\n",
        "            f.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLkZsmNZ9CEE",
        "outputId": "31e2d132-7fd5-4d96-c46f-3a63454a48f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [08:13<00:00,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time elapsed: 493.1723692417145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ./qwen2.5/datasets/iter2\n",
        "! python3 SPIN/spin/convert_data.py --num_fracs=5 --input_dir=./qwen2.5/generated/iter2 --output_dir=./qwen2.5/datasets/iter2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWLl-ArWRuVD",
        "outputId": "fc655346-b008-4545-f983-30b14512dd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘./qwen2.5/datasets/iter2’: File exists\n",
            "2079\n",
            "231\n",
            "Generating train split: 2079 examples [00:00, 16659.90 examples/s]\n",
            "Generating train split: 231 examples [00:00, 18169.76 examples/s]\n",
            "2079\n",
            "231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ./drive/MyDrive/qwen2.5/datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1px3P6avR_Nk",
        "outputId": "4e6a5a99-2b50-4bbb-d9f6-05e469f68919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter0  iter1  iter2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Скорректированная версия SPINTrainer"
      ],
      "metadata": {
        "id": "eTP_iaN60XHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from https://github.com/huggingface/alignment-handbook\n",
        "\n",
        "import inspect\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from accelerate import init_empty_weights, load_checkpoint_and_dispatch\n",
        "from accelerate.utils import is_deepspeed_available\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollator,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizerBase,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from transformers.trainer_callback import TrainerCallback\n",
        "from transformers.trainer_utils import EvalLoopOutput\n",
        "\n",
        "# from trl.import_utils import is_peft_available, is_wandb_available\n",
        "# from trl.models import PreTrainedModelWrapper, create_reference_model\n",
        "# from trl.trainer.utils import disable_dropout_in_model, pad_to_length\n",
        "\n",
        "from .utils import DataCollatorWithPadding\n",
        "from contextlib import contextmanager, nullcontext\n",
        "\n",
        "def is_peft_available():\n",
        "    return True\n",
        "\n",
        "def is_wandb_available():\n",
        "    return True\n",
        "\n",
        "def pad_to_length(tensor: torch.Tensor, length: int, pad_value: Union[int, float], dim: int = -1) -> torch.Tensor:\n",
        "    if tensor.size(dim) >= length:\n",
        "        return tensor\n",
        "    else:\n",
        "        pad_size = list(tensor.shape)\n",
        "        pad_size[dim] = length - tensor.size(dim)\n",
        "        return torch.cat(\n",
        "            [\n",
        "                tensor,\n",
        "                pad_value * torch.ones(*pad_size, dtype=tensor.dtype, device=tensor.device),\n",
        "            ],\n",
        "            dim=dim,\n",
        "        )\n",
        "\n",
        "\n",
        "def disable_dropout_in_model(model: torch.nn.Module) -> None:\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, torch.nn.Dropout):\n",
        "            module.p = 0\n",
        "\n",
        "\n",
        "# if is_peft_available():\n",
        "from peft import PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "\n",
        "# if is_wandb_available():\n",
        "import wandb\n",
        "\n",
        "if is_deepspeed_available():\n",
        "    import deepspeed\n",
        "\n",
        "\n",
        "class SPINTrainer(Trainer):\n",
        "    r\"\"\"\n",
        "    Initialize SPINTrainer.\n",
        "\n",
        "    Args:\n",
        "        model (`transformers.PreTrainedModel`):\n",
        "            The model to train, preferably an `AutoModelForSequenceClassification`.\n",
        "        ref_model (`PreTrainedModelWrapper`):\n",
        "            Hugging Face transformer model with a casual language modelling head. Used for implicit reward computation and loss. If no\n",
        "            reference model is provided, the trainer will create a reference model with the same architecture as the model to be optimized.\n",
        "        beta (`float`, defaults to 0.1):\n",
        "            The beta factor in SPIN loss. Higher beta means less divergence from the initial policy.\n",
        "        loss_type (`str`, defaults to `\"sigmoid\"`):\n",
        "            The type of SPIN loss to use. Either `\"sigmoid\"` the default SPIN loss or `\"hinge\"` loss from SLiC paper.\n",
        "        args (`transformers.TrainingArguments`):\n",
        "            The arguments to use for training.\n",
        "        data_collator (`transformers.DataCollator`):\n",
        "            The data collator to use for training. If None is specified, the default data collator (`SPINDataCollatorWithPadding`) will be used\n",
        "            which will pad the sequences to the maximum length of the sequences in the batch, given a dataset of paired sequences.\n",
        "        label_pad_token_id (`int`, defaults to `-100`):\n",
        "            The label pad token id. This argument is required if you want to use the default data collator.\n",
        "        padding_value (`int`, defaults to `0`):\n",
        "            The padding value. This argument is required if you want to use the default data collator.\n",
        "        truncation_mode (`str`, defaults to `keep_end`):\n",
        "            The truncation mode to use, either `keep_end` or `keep_start`. This argument is required if you want to use the default data collator.\n",
        "        train_dataset (`datasets.Dataset`):\n",
        "            The dataset to use for training.\n",
        "        eval_dataset (`datasets.Dataset`):\n",
        "            The dataset to use for evaluation.\n",
        "        tokenizer (`transformers.PreTrainedTokenizerBase`):\n",
        "            The tokenizer to use for training. This argument is required if you want to use the default data collator.\n",
        "        model_init (`Callable[[], transformers.PreTrainedModel]`):\n",
        "            The model initializer to use for training. If None is specified, the default model initializer will be used.\n",
        "        callbacks (`List[transformers.TrainerCallback]`):\n",
        "            The callbacks to use for training.\n",
        "        optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`):\n",
        "            The optimizer and scheduler to use for training.\n",
        "        preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`):\n",
        "            The function to use to preprocess the logits before computing the metrics.\n",
        "        max_length (`int`, defaults to `None`):\n",
        "            The maximum length of the sequences in the batch. This argument is required if you want to use the default data collator.\n",
        "        max_prompt_length (`int`, defaults to `None`):\n",
        "            The maximum length of the prompt. This argument is required if you want to use the default data collator.\n",
        "        max_target_length (`int`, defaults to `None`):\n",
        "            The maximum length of the target. This argument is required if you want to use the default data collator and your model is an encoder-decoder.\n",
        "        peft_config (`Dict`, defaults to `None`):\n",
        "            The PEFT configuration to use for training. If you pass a PEFT configuration, the model will be wrapped in a PEFT model.\n",
        "        is_encoder_decoder (`Optional[bool]`, `optional`, defaults to `None`):\n",
        "            If no model is provided, we need to know if the model_init returns an encoder-decoder.\n",
        "        disable_dropout (`bool`, defaults to `True`):\n",
        "            Whether or not to disable dropouts in `model` and `ref_model`.\n",
        "        generate_during_eval (`bool`, defaults to `False`):\n",
        "            Whether to sample and log generations during evaluation step.\n",
        "        compute_metrics (`Callable[[EvalPrediction], Dict]`, *optional*):\n",
        "            The function to use to compute the metrics. Must take an `EvalPrediction` and return\n",
        "            a dictionary string to metric values.\n",
        "        model_init_kwargs: (`Optional[Dict]`, *optional*):\n",
        "            Dict of Optional kwargs to pass when instantiating the model from a string\n",
        "        ref_model_init_kwargs: (`Optional[Dict]`, *optional*):\n",
        "            Dict of Optional kwargs to pass when instantiating the ref model from a string\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Union[PreTrainedModel, nn.Module, str] = None,\n",
        "        ref_model: Optional[Union[PreTrainedModel, nn.Module, str]] = None,\n",
        "        beta: float = 0.1,\n",
        "        loss_type: Literal[\"sigmoid\", \"hinge\"] = \"sigmoid\",\n",
        "        args: TrainingArguments = None,\n",
        "        data_collator: Optional[DataCollator] = None,\n",
        "        label_pad_token_id: int = -100,\n",
        "        padding_value: int = 0,\n",
        "        truncation_mode: str = \"keep_end\",\n",
        "        train_dataset: Optional[Dataset] = None,\n",
        "        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,\n",
        "        tokenizer: Optional[PreTrainedTokenizerBase] = None,\n",
        "        model_init: Optional[Callable[[], PreTrainedModel]] = None,\n",
        "        callbacks: Optional[List[TrainerCallback]] = None,\n",
        "        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (\n",
        "            None,\n",
        "            None,\n",
        "        ),\n",
        "        preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n",
        "        max_length: Optional[int] = None,\n",
        "        max_prompt_length: Optional[int] = None,\n",
        "        max_target_length: Optional[int] = None,\n",
        "        peft_config: Optional[Dict] = None,\n",
        "        is_encoder_decoder: Optional[bool] = None,\n",
        "        disable_dropout: bool = True,\n",
        "        generate_during_eval: bool = False,\n",
        "        compute_metrics: Optional[Callable[[EvalLoopOutput], Dict]] = None,\n",
        "        model_init_kwargs: Optional[Dict] = None,\n",
        "        ref_model_init_kwargs: Optional[Dict] = None,\n",
        "        model_adapter_name: Optional[str] = None,\n",
        "        ref_adapter_name: Optional[str] = None,\n",
        "    ):\n",
        "        if model_init_kwargs is None:\n",
        "            model_init_kwargs = {}\n",
        "        elif not isinstance(model, str):\n",
        "            raise ValueError(\"You passed model_kwargs to the SPINTrainer. But your model is already instantiated.\")\n",
        "\n",
        "        if ref_model_init_kwargs is None:\n",
        "            ref_model_init_kwargs = {}\n",
        "        elif not isinstance(ref_model, str):\n",
        "            raise ValueError(\n",
        "                \"You passed ref_model_kwargs to the SPINTrainer. But your ref_model is already instantiated.\"\n",
        "            )\n",
        "\n",
        "        if isinstance(model, str):\n",
        "            warnings.warn(\n",
        "                \"You passed a model_id to the SPINTrainer. This will automatically create an \"\n",
        "                \"`AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\"\n",
        "            )\n",
        "            model = AutoModelForCausalLM.from_pretrained(model, **model_init_kwargs)\n",
        "\n",
        "        if isinstance(ref_model, str):\n",
        "            warnings.warn(\n",
        "                \"You passed a ref model_id to the SPINTrainer. This will automatically create an \"\n",
        "                \"`AutoModelForCausalLM`\"\n",
        "            )\n",
        "            ref_model = AutoModelForCausalLM.from_pretrained(ref_model, **ref_model_init_kwargs)\n",
        "\n",
        "        if not is_peft_available() and peft_config is not None:\n",
        "            raise ValueError(\n",
        "                \"PEFT is not installed and you passed a `peft_config` in the trainer's kwargs, please install it to use the PEFT models\"\n",
        "            )\n",
        "        elif is_peft_available() and peft_config is not None:\n",
        "            # if model is a peft model and we have a peft_config, we merge and unload it first\n",
        "            if isinstance(model, PeftModel):\n",
        "                model = model.merge_and_unload()\n",
        "\n",
        "            if getattr(model, \"is_loaded_in_8bit\", False) or getattr(model, \"is_loaded_in_4bit\", False):\n",
        "                _support_gc_kwargs = hasattr(\n",
        "                    args, \"gradient_checkpointing_kwargs\"\n",
        "                ) and \"gradient_checkpointing_kwargs\" in list(\n",
        "                    inspect.signature(prepare_model_for_kbit_training).parameters\n",
        "                )\n",
        "\n",
        "                preprare_model_kwargs = {\"use_gradient_checkpointing\": args.gradient_checkpointing}\n",
        "\n",
        "                if _support_gc_kwargs:\n",
        "                    preprare_model_kwargs[\"gradient_checkpointing_kwargs\"] = args.gradient_checkpointing_kwargs\n",
        "\n",
        "                model = prepare_model_for_kbit_training(model, **preprare_model_kwargs)\n",
        "            elif getattr(args, \"gradient_checkpointing\", False):\n",
        "                # For backward compatibility with older versions of transformers\n",
        "                if hasattr(model, \"enable_input_require_grads\"):\n",
        "                    model.enable_input_require_grads()\n",
        "                else:\n",
        "\n",
        "                    def make_inputs_require_grad(module, input, output):\n",
        "                        output.requires_grad_(True)\n",
        "\n",
        "                    model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)\n",
        "\n",
        "            # get peft model with the given config\n",
        "            model = get_peft_model(model, peft_config)\n",
        "\n",
        "        # For models that use gradient_checkpointing, we need to attach a hook that enables input\n",
        "        # to explicitly have `requires_grad=True`, otherwise training will either silently\n",
        "        # fail or completely fail.\n",
        "        elif getattr(args, \"gradient_checkpointing\", False):\n",
        "            # For backward compatibility with older versions of transformers\n",
        "            if hasattr(model, \"enable_input_require_grads\"):\n",
        "                model.enable_input_require_grads()\n",
        "            else:\n",
        "\n",
        "                def make_inputs_require_grad(module, input, output):\n",
        "                    output.requires_grad_(True)\n",
        "\n",
        "                model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)\n",
        "\n",
        "        if generate_during_eval and not is_wandb_available():\n",
        "            raise ValueError(\n",
        "                \"`generate_during_eval=True` requires Weights and Biases to be installed.\"\n",
        "                \" Please install `wandb` to resolve.\"\n",
        "            )\n",
        "\n",
        "        if model is not None:\n",
        "            self.is_encoder_decoder = model.config.is_encoder_decoder\n",
        "        elif is_encoder_decoder is None:\n",
        "            raise ValueError(\"When no model is provided, you need to pass the parameter is_encoder_decoder.\")\n",
        "        else:\n",
        "            self.is_encoder_decoder = is_encoder_decoder\n",
        "\n",
        "        self.is_peft_model = is_peft_available() and isinstance(model, PeftModel)\n",
        "        self.model_adapter_name = model_adapter_name\n",
        "        self.ref_adapter_name = ref_adapter_name\n",
        "\n",
        "        if ref_model:\n",
        "            self.ref_model = ref_model\n",
        "        elif self.is_peft_model:\n",
        "            # The `model` with adapters turned off will be used as the reference model\n",
        "            self.ref_model = None\n",
        "        else:\n",
        "            self.ref_model = create_reference_model(model)\n",
        "\n",
        "        if data_collator is None:\n",
        "            if tokenizer is None:\n",
        "                raise ValueError(\n",
        "                    \"max_length or a tokenizer must be specified when using the default SPINDataCollatorWithPadding\"\n",
        "                )\n",
        "            if max_length is None:\n",
        "                warnings.warn(\n",
        "                    \"When using SPINDataCollatorWithPadding, you should set `max_length` in the SPINTrainer's init\"\n",
        "                    \" it will be set to `512` by default, but you should do it yourself in the future.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "                max_length = 512\n",
        "            if max_prompt_length is None:\n",
        "                warnings.warn(\n",
        "                    \"When using SPINDataCollatorWithPadding, you should set `max_prompt_length` in the SPINTrainer's init\"\n",
        "                    \" it will be set to `128` by default, but you should do it yourself in the future.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "                max_prompt_length = 128\n",
        "\n",
        "            if max_target_length is None and self.is_encoder_decoder:\n",
        "                warnings.warn(\n",
        "                    \"When using SPINDataCollatorWithPadding with an encoder decoder architecture, you should set `max_target_length` in the SPINTrainer's init\"\n",
        "                    \" it will be set to `128` by default, but you should do it yourself in the future.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "                max_target_length = 128\n",
        "\n",
        "            data_collator = DataCollatorWithPadding(\n",
        "                tokenizer,\n",
        "                max_length=max_length,\n",
        "                max_prompt_length=max_prompt_length,\n",
        "                label_pad_token_id=label_pad_token_id,\n",
        "                padding_value=padding_value,\n",
        "                truncation_mode=truncation_mode,\n",
        "                is_encoder_decoder=self.is_encoder_decoder,\n",
        "                max_target_length=max_target_length,\n",
        "            )\n",
        "\n",
        "            if args.remove_unused_columns:\n",
        "                args.remove_unused_columns = False\n",
        "                # warn users\n",
        "                warnings.warn(\n",
        "                    \"When using SPINDataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments\"\n",
        "                    \" we have set it for you, but you should do it yourself in the future.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "\n",
        "            self.use_data_collator = True\n",
        "        else:\n",
        "            self.use_data_collator = False\n",
        "\n",
        "        if disable_dropout:\n",
        "            disable_dropout_in_model(model)\n",
        "            if self.ref_model is not None:\n",
        "                disable_dropout_in_model(self.ref_model)\n",
        "\n",
        "        self.max_length = max_length\n",
        "        self.generate_during_eval = generate_during_eval\n",
        "        self.label_pad_token_id = label_pad_token_id\n",
        "        self.padding_value = padding_value\n",
        "\n",
        "        self.beta = beta\n",
        "        self.loss_type = loss_type\n",
        "\n",
        "        self._stored_metrics = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            args=args,\n",
        "            data_collator=data_collator,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            model_init=model_init,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=callbacks,\n",
        "            optimizers=optimizers,\n",
        "            preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
        "        )\n",
        "\n",
        "        if not hasattr(self, \"accelerator\"):\n",
        "            raise AttributeError(\n",
        "                \"Your `Trainer` does not have an `accelerator` object. Consider upgrading `transformers`.\"\n",
        "            )\n",
        "\n",
        "        if self.ref_model is None:\n",
        "            if not hasattr(self.accelerator.unwrap_model(self.model), \"disable_adapter\"):\n",
        "                raise ValueError(\n",
        "                    \"You are using a `peft` version that does not support `disable_adapter`. Please update your `peft` version to the latest version.\"\n",
        "                )\n",
        "        else:\n",
        "            if self.is_deepspeed_enabled:\n",
        "                self.ref_model = self._prepare_deepspeed(self.ref_model)\n",
        "            else:\n",
        "                self.ref_model = self.accelerator.prepare_model(self.ref_model, evaluation_mode=True)\n",
        "\n",
        "        if disable_dropout and self.ref_model is not None:\n",
        "            disable_dropout_in_model(self.ref_model)\n",
        "\n",
        "\n",
        "    def _prepare_deepspeed(self, model):\n",
        "        # Adapted from accelerate: https://github.com/huggingface/accelerate/blob/739b135f8367becb67ffaada12fe76e3aa60fefd/src/accelerate/accelerator.py#L1473\n",
        "        deepspeed_plugin = self.accelerator.state.deepspeed_plugin\n",
        "        config_kwargs = deepcopy(deepspeed_plugin.deepspeed_config)\n",
        "\n",
        "        if model is not None:\n",
        "            if hasattr(model, \"config\"):\n",
        "                hidden_size = (\n",
        "                    max(model.config.hidden_sizes)\n",
        "                    if getattr(model.config, \"hidden_sizes\", None)\n",
        "                    else getattr(model.config, \"hidden_size\", None)\n",
        "                )\n",
        "                if hidden_size is not None and config_kwargs[\"zero_optimization\"][\"stage\"] == 3:\n",
        "                    # Note that `stage3_prefetch_bucket_size` can produce DeepSpeed messages like: `Invalidate trace cache @ step 0: expected module 1, but got module 0`\n",
        "                    # This is expected and is not an error, see: https://github.com/microsoft/DeepSpeed/discussions/4081\n",
        "                    config_kwargs.update(\n",
        "                        {\n",
        "                            \"zero_optimization.reduce_bucket_size\": hidden_size * hidden_size,\n",
        "                            \"zero_optimization.stage3_param_persistence_threshold\": 10 * hidden_size,\n",
        "                            \"zero_optimization.stage3_prefetch_bucket_size\": 0.9 * hidden_size * hidden_size,\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "        # If ZeRO-3 is used, we shard both the active and reference model.\n",
        "        # Otherwise, we assume the reference model fits in memory and is initialized on each device with ZeRO disabled (stage 0)\n",
        "        if config_kwargs[\"zero_optimization\"][\"stage\"] != 3:\n",
        "            config_kwargs[\"zero_optimization\"][\"stage\"] = 0\n",
        "        model, *_ = deepspeed.initialize(model=model, config=config_kwargs)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def concatenated_inputs(self, batch: Dict[str, Union[List, torch.LongTensor]]) -> Dict[str, torch.LongTensor]:\n",
        "        \"\"\"Concatenate the real and generated inputs into a single tensor.\n",
        "\n",
        "        Args:\n",
        "            batch: A batch of data. Must contain the keys 'åreal_input_ids' and 'generated_input_ids', which are tensors of shape (batch_size, sequence_length).\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the concatenated inputs under the key 'concatenated_input_ids'.\n",
        "        \"\"\"\n",
        "        concatenated_batch = {}\n",
        "\n",
        "        if self.is_encoder_decoder:\n",
        "            max_length = max(batch[\"real_labels\"].shape[1], batch[\"generated_labels\"].shape[1])\n",
        "        else:\n",
        "            max_length = max(batch[\"real_input_ids\"].shape[1], batch[\"generated_input_ids\"].shape[1])\n",
        "\n",
        "        for k in batch:\n",
        "            if k.startswith(\"real\") and isinstance(batch[k], torch.Tensor):\n",
        "                pad_value = self.label_pad_token_id if \"labels\" in k or self.is_encoder_decoder else self.padding_value\n",
        "                concatenated_key = k.replace(\"real\", \"concatenated\")\n",
        "                concatenated_batch[concatenated_key] = pad_to_length(batch[k], max_length, pad_value=pad_value)\n",
        "        for k in batch:\n",
        "            if k.startswith(\"generated\") and isinstance(batch[k], torch.Tensor):\n",
        "                pad_value = self.label_pad_token_id if \"labels\" in k or self.is_encoder_decoder else self.padding_value\n",
        "                concatenated_key = k.replace(\"generated\", \"concatenated\")\n",
        "                concatenated_batch[concatenated_key] = torch.cat(\n",
        "                    (\n",
        "                        concatenated_batch[concatenated_key],\n",
        "                        pad_to_length(batch[k], max_length, pad_value=pad_value),\n",
        "                    ),\n",
        "                    dim=0,\n",
        "                ).to(self.accelerator.device)\n",
        "\n",
        "        if self.is_encoder_decoder:\n",
        "            concatenated_batch[\"concatenated_input_ids\"] = batch[\"prompt_input_ids\"].repeat(2, 1)\n",
        "            concatenated_batch[\"concatenated_attention_mask\"] = batch[\"prompt_attention_mask\"].repeat(2, 1)\n",
        "\n",
        "        return concatenated_batch\n",
        "\n",
        "    def spin_loss(\n",
        "        self,\n",
        "        policy_real_logps: torch.FloatTensor,\n",
        "        policy_generated_logps: torch.FloatTensor,\n",
        "        opponent_real_logps: torch.FloatTensor,\n",
        "        opponent_generated_logps: torch.FloatTensor,\n",
        "        reference_free: bool = False,\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
        "        \"\"\"Compute the SPIN loss for a batch of policy and reference model log probabilities.\n",
        "\n",
        "        Args:\n",
        "            policy_real_logps: Log probabilities of the policy model for the real responses. Shape: (batch_size,)\n",
        "            policy_generated_logps: Log probabilities of the policy model for the generated responses. Shape: (batch_size,)\n",
        "            opponent_real_logps: Log probabilities of the reference model for the real responses. Shape: (batch_size,)\n",
        "            opponent_generated_logps: Log probabilities of the reference model for the generated responses. Shape: (batch_size,)\n",
        "            beta: Temperature parameter for the SPIN loss, typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
        "            reference_free: If True, we ignore the _provided_ reference model and implicitly use a reference model that assigns equal probability to all responses.\n",
        "\n",
        "        Returns:\n",
        "            A tuple of three tensors: (losses, real_rewards, generated_rewards).\n",
        "            The losses tensor contains the SPIN loss for each example in the batch.\n",
        "            The real_rewards and generated_rewards tensors contain the rewards for the real and generated responses, respectively.\n",
        "        \"\"\"\n",
        "        pi_logratios = policy_real_logps - policy_generated_logps\n",
        "        ref_logratios = opponent_real_logps - opponent_generated_logps\n",
        "\n",
        "        if reference_free:\n",
        "            ref_logratios = 0\n",
        "\n",
        "        logits = pi_logratios - ref_logratios\n",
        "\n",
        "        if self.loss_type == \"sigmoid\":\n",
        "            losses = -F.logsigmoid(self.beta * logits)\n",
        "        elif self.loss_type == \"hinge\":\n",
        "            losses = torch.relu(1 - self.beta * logits)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss type: {self.loss_type}. Should be one of ['sigmoid', 'hinge']\")\n",
        "\n",
        "        real_rewards = self.beta * (policy_real_logps - opponent_real_logps).detach()\n",
        "        generated_rewards = self.beta * (policy_generated_logps - opponent_generated_logps).detach()\n",
        "\n",
        "        print(f\"losses: {losses}\")\n",
        "        print(f\"policy_real_logps: {policy_real_logps}\")\n",
        "        print(f\"policy_generated_logps: {policy_generated_logps}\")\n",
        "        print(f\"opponent_real_logps: {opponent_real_logps}\")\n",
        "        print(f\"opponent_generated_logps: {opponent_generated_logps}\")\n",
        "        print(f\"logits: {logits}\")\n",
        "        print(f\"real_rewards: {real_rewards}\")\n",
        "        print(f\"generated_rewards: {generated_rewards}\")\n",
        "\n",
        "        return losses, real_rewards, generated_rewards\n",
        "\n",
        "    def _get_batch_logps(\n",
        "        self,\n",
        "        logits: torch.FloatTensor,\n",
        "        labels: torch.LongTensor,\n",
        "        average_log_prob: bool = False,\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"Compute the log probabilities of the given labels under the given logits.\n",
        "\n",
        "        Args:\n",
        "            logits: Logits of the model (unnormalized). Shape: (batch_size, sequence_length, vocab_size)\n",
        "            labels: Labels for which to compute the log probabilities. Label tokens with a value of label_pad_token_id are ignored. Shape: (batch_size, sequence_length)\n",
        "            average_log_prob: If True, return the average log probability per (non-masked) token. Otherwise, return the sum of the log probabilities of the (non-masked) tokens.\n",
        "\n",
        "        Returns:\n",
        "            A tensor of shape (batch_size,) containing the average/sum log probabilities of the given labels under the given logits.\n",
        "        \"\"\"\n",
        "        if logits.shape[:-1] != labels.shape:\n",
        "            raise ValueError(\"Logits (batch and sequence length dim) and labels must have the same shape.\")\n",
        "\n",
        "        if not self.is_encoder_decoder:\n",
        "            labels = labels[:, 1:].clone()\n",
        "            logits = logits[:, :-1, :]\n",
        "        loss_mask = labels != self.label_pad_token_id\n",
        "\n",
        "        # dummy token; we'll ignore the losses on these tokens later\n",
        "        labels[labels == self.label_pad_token_id] = 0\n",
        "\n",
        "        per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        if average_log_prob:\n",
        "            return (per_token_logps * loss_mask).sum(-1) / loss_mask.sum(-1)\n",
        "        else:\n",
        "            return (per_token_logps * loss_mask).sum(-1)\n",
        "\n",
        "    def concatenated_forward(\n",
        "        self, model: nn.Module, batch: Dict[str, Union[List, torch.LongTensor]]\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
        "        \"\"\"Run the given model on the given batch of inputs, concatenating the real and generated inputs together.\n",
        "\n",
        "        We do this to avoid doing two forward passes, because it's faster for FSDP.\n",
        "        \"\"\"\n",
        "        concatenated_batch = self.concatenated_inputs(batch)\n",
        "        len_real = batch[\"real_labels\"].shape[0]\n",
        "\n",
        "        model_kwargs = (\n",
        "            {\n",
        "                \"labels\": concatenated_batch[\"concatenated_labels\"],\n",
        "                \"decoder_input_ids\": concatenated_batch.pop(\"concatenated_decoder_input_ids\", None),\n",
        "            }\n",
        "            if self.is_encoder_decoder\n",
        "            else {}\n",
        "        )\n",
        "        all_logits = model(\n",
        "            concatenated_batch[\"concatenated_input_ids\"],\n",
        "            attention_mask=concatenated_batch[\"concatenated_attention_mask\"],\n",
        "            **model_kwargs,\n",
        "        ).logits.to(torch.float32)\n",
        "\n",
        "        all_logps = self._get_batch_logps(\n",
        "            all_logits,\n",
        "            concatenated_batch[\"concatenated_labels\"],\n",
        "            average_log_prob=False,\n",
        "        )\n",
        "\n",
        "        real_logps = all_logps[:len_real]\n",
        "        generated_logps = all_logps[len_real:]\n",
        "\n",
        "        real_logits = all_logits[:len_real]\n",
        "        generated_logits = all_logits[len_real:]\n",
        "\n",
        "        return (real_logps, generated_logps, real_logits, generated_logits)\n",
        "\n",
        "    @contextmanager\n",
        "    def null_ref_context(self):\n",
        "        \"\"\"Context manager for handling null reference model (that is, peft adapter manipulation).\"\"\"\n",
        "        with self.accelerator.unwrap_model(\n",
        "            self.model\n",
        "        ).disable_adapter() if self.is_peft_model and not self.ref_adapter_name else nullcontext():\n",
        "            if self.ref_adapter_name:\n",
        "                self.model.set_adapter(self.ref_adapter_name)\n",
        "            yield\n",
        "            if self.ref_adapter_name:\n",
        "                self.model.set_adapter(self.model_adapter_name or \"default\")\n",
        "\n",
        "    def get_batch_metrics(\n",
        "        self,\n",
        "        model,\n",
        "        batch: Dict[str, Union[List, torch.LongTensor]],\n",
        "        train_eval: Literal[\"train\", \"eval\"] = \"train\",\n",
        "    ):\n",
        "        \"\"\"Compute the SPIN loss and other metrics for the given batch of inputs for train or test.\"\"\"\n",
        "        metrics = {}\n",
        "\n",
        "        (\n",
        "            policy_real_logps,\n",
        "            policy_generated_logps,\n",
        "            policy_real_logits,\n",
        "            policy_generated_logits,\n",
        "        ) = self.concatenated_forward(model, batch)\n",
        "        with torch.no_grad():\n",
        "            if self.ref_model is None:\n",
        "                with self.null_ref_context():\n",
        "                    (\n",
        "                        opponent_real_logps,\n",
        "                        opponent_generated_logps,\n",
        "                        _,\n",
        "                        _,\n",
        "                    ) = self.concatenated_forward(self.model, batch)\n",
        "            else:\n",
        "                (\n",
        "                    opponent_real_logps,\n",
        "                    opponent_generated_logps,\n",
        "                    _,\n",
        "                    _,\n",
        "                ) = self.concatenated_forward(self.ref_model, batch)\n",
        "\n",
        "        losses, real_rewards, generated_rewards = self.spin_loss(\n",
        "            policy_real_logps,\n",
        "            policy_generated_logps,\n",
        "            opponent_real_logps,\n",
        "            opponent_generated_logps,\n",
        "        )\n",
        "        reward_accuracies = (real_rewards > generated_rewards).float()\n",
        "\n",
        "        prefix = \"eval_\" if train_eval == \"eval\" else \"\"\n",
        "        metrics[f\"{prefix}rewards/real\"] = real_rewards.cpu().mean()\n",
        "        metrics[f\"{prefix}rewards/generated\"] = generated_rewards.cpu().mean()\n",
        "        metrics[f\"{prefix}rewards/accuracies\"] = reward_accuracies.cpu().mean()\n",
        "        metrics[f\"{prefix}rewards/margins\"] = (real_rewards - generated_rewards).cpu().mean()\n",
        "        metrics[f\"{prefix}logps/generated\"] = policy_generated_logps.detach().cpu().mean()\n",
        "        metrics[f\"{prefix}logps/real\"] = policy_real_logps.detach().cpu().mean()\n",
        "        metrics[f\"{prefix}logits/generated\"] = policy_generated_logits.detach().cpu().mean()\n",
        "        metrics[f\"{prefix}logits/real\"] = policy_real_logits.detach().cpu().mean()\n",
        "\n",
        "        return losses.mean(), metrics\n",
        "\n",
        "    def compute_loss(\n",
        "        self,\n",
        "        model: Union[PreTrainedModel, nn.Module],\n",
        "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
        "        return_outputs=False,\n",
        "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, Dict[str, torch.Tensor]]]:\n",
        "        if not self.use_data_collator:\n",
        "            warnings.warn(\n",
        "                \"compute_loss is only implemented for SPINDataCollatorWithPadding, and you passed a datacollator that is different than \"\n",
        "                \"SPINDataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\"\n",
        "            )\n",
        "        loss, metrics = self.get_batch_metrics(model, inputs, train_eval=\"train\")\n",
        "\n",
        "        # force log the metrics\n",
        "        if self.accelerator.is_main_process:\n",
        "            self.store_metrics(metrics, train_eval=\"train\")\n",
        "\n",
        "        if return_outputs:\n",
        "            return (loss, metrics)\n",
        "        return loss\n",
        "\n",
        "    def get_batch_samples(self, model, batch: Dict[str, torch.LongTensor]) -> Tuple[str, str]:\n",
        "        \"\"\"Generate samples from the model and reference model for the given batch of inputs.\"\"\"\n",
        "\n",
        "        policy_output = model.generate(\n",
        "            input_ids=batch[\"prompt_input_ids\"],\n",
        "            attention_mask=batch[\"prompt_attention_mask\"],\n",
        "            max_length=self.max_length,\n",
        "            do_sample=True,\n",
        "            pad_token_id=self.tokenizer.pad_token_id,\n",
        "        )\n",
        "\n",
        "        if self.ref_model is None:\n",
        "            with self.accelerator.unwrap_model(self.model).disable_adapter():\n",
        "                reference_output = self.model.generate(\n",
        "                    batch[\"prompt_input_ids\"],\n",
        "                    attention_mask=batch[\"prompt_attention_mask\"],\n",
        "                    max_length=self.max_length,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.pad_token_id,\n",
        "                )\n",
        "        else:\n",
        "            reference_output = self.ref_model.generate(\n",
        "                batch[\"prompt_input_ids\"],\n",
        "                attention_mask=batch[\"prompt_attention_mask\"],\n",
        "                max_length=self.max_length,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.pad_token_id,\n",
        "            )\n",
        "\n",
        "        policy_output = pad_to_length(policy_output, self.max_length, self.tokenizer.pad_token_id)\n",
        "        policy_output_decoded = self.tokenizer.batch_decode(policy_output, skip_special_tokens=True)\n",
        "\n",
        "        reference_output = pad_to_length(reference_output, self.max_length, self.tokenizer.pad_token_id)\n",
        "        reference_output_decoded = self.tokenizer.batch_decode(reference_output, skip_special_tokens=True)\n",
        "\n",
        "        return policy_output_decoded, reference_output_decoded\n",
        "\n",
        "    def prediction_step(\n",
        "        self,\n",
        "        model: Union[PreTrainedModel, nn.Module],\n",
        "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
        "        prediction_loss_only: bool,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "    ):\n",
        "        if not self.use_data_collator:\n",
        "            warnings.warn(\n",
        "                \"prediction_step is only implemented for SPINDataCollatorWithPadding, and you passed a datacollator that is different than \"\n",
        "                \"SPINDataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator\"\n",
        "            )\n",
        "        if ignore_keys is None:\n",
        "            if hasattr(model, \"config\"):\n",
        "                ignore_keys = getattr(model.config, \"keys_to_ignore_at_inference\", [])\n",
        "            else:\n",
        "                ignore_keys = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss, metrics = self.get_batch_metrics(model, inputs, train_eval=\"eval\")\n",
        "\n",
        "        # force log the metrics\n",
        "        if self.accelerator.is_main_process:\n",
        "            self.store_metrics(metrics, train_eval=\"eval\")\n",
        "\n",
        "        if prediction_loss_only:\n",
        "            return (loss.detach(), None, None)\n",
        "\n",
        "        # logits for the real and generated samples from model\n",
        "        logits_dict = {\n",
        "            \"eval_logits/real\": metrics[\"eval_logits/real\"],\n",
        "            \"eval_logits/generated\": metrics[\"eval_logits/generated\"],\n",
        "        }\n",
        "        logits = tuple(v.unsqueeze(dim=0) for k, v in logits_dict.items() if k not in ignore_keys)\n",
        "        logits = torch.stack(logits).mean(axis=1).to(self.accelerator.device)\n",
        "        labels = torch.zeros(logits.shape[0], device=self.accelerator.device)\n",
        "\n",
        "        return (loss.detach(), logits, labels)\n",
        "\n",
        "    def store_metrics(self, metrics: Dict[str, float], train_eval: Literal[\"train\", \"eval\"] = \"train\") -> None:\n",
        "        for key, value in metrics.items():\n",
        "            self._stored_metrics[train_eval][key].append(value)\n",
        "\n",
        "    def evaluation_loop(\n",
        "        self,\n",
        "        dataloader: DataLoader,\n",
        "        description: str,\n",
        "        prediction_loss_only: Optional[bool] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> EvalLoopOutput:\n",
        "        \"\"\"\n",
        "        Overriding built-in evaluation loop to store metrics for each batch.\n",
        "        Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\n",
        "\n",
        "        Works both with or without labels.\n",
        "        \"\"\"\n",
        "\n",
        "        # Sample and save to game log if requested (for one batch to save time)\n",
        "        if self.generate_during_eval:\n",
        "            # Generate random indices within the range of the total number of samples\n",
        "            num_samples = len(dataloader.dataset)\n",
        "            random_indices = random.sample(range(num_samples), k=self.args.eval_batch_size)\n",
        "\n",
        "            # Use dataloader.dataset.select to get the random batch without iterating over the DataLoader\n",
        "            random_batch_dataset = dataloader.dataset.select(random_indices)\n",
        "            random_batch = self.data_collator(random_batch_dataset)\n",
        "            random_batch = self._prepare_inputs(random_batch)\n",
        "\n",
        "            policy_output_decoded, ref_output_decoded = self.get_batch_samples(self.model, random_batch)\n",
        "\n",
        "            self.log(\n",
        "                {\n",
        "                    \"game_log\": wandb.Table(\n",
        "                        columns=[\"Prompt\", \"Policy\", \"Ref Model\"],\n",
        "                        rows=[\n",
        "                            [prompt, pol[len(prompt) :], ref[len(prompt) :]]\n",
        "                            for prompt, pol, ref in zip(\n",
        "                                random_batch[\"prompt\"], policy_output_decoded, ref_output_decoded\n",
        "                            )\n",
        "                        ],\n",
        "                    )\n",
        "                }\n",
        "            )\n",
        "            self.state.log_history.pop()\n",
        "\n",
        "        # Base evaluation\n",
        "        initial_output = super().evaluation_loop(\n",
        "            dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix\n",
        "        )\n",
        "\n",
        "        return initial_output\n",
        "\n",
        "    def log(self, logs: Dict[str, float]) -> None:\n",
        "        \"\"\"\n",
        "        Log `logs` on the various objects watching training, including stored metrics.\n",
        "\n",
        "        Args:\n",
        "            logs (`Dict[str, float]`):\n",
        "                The values to log.\n",
        "        \"\"\"\n",
        "        # logs either has 'loss' or 'eval_loss'\n",
        "        train_eval = \"train\" if \"loss\" in logs else \"eval\"\n",
        "        # Add averaged stored metrics to logs\n",
        "        for key, metrics in self._stored_metrics[train_eval].items():\n",
        "            logs[key] = torch.tensor(metrics).mean().item()\n",
        "        del self._stored_metrics[train_eval]\n",
        "        return super().log(logs)\n"
      ],
      "metadata": {
        "id": "2tYkrDdybrvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "549yHdnVao1w"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f4518db013f47ba8f016731e8bafaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_603174f1cf664768a03c634a679545cf",
              "IPY_MODEL_92914d1d4cc141fa8ab75b645353055e",
              "IPY_MODEL_87182e8fd02b4ed596cf935f6510289c"
            ],
            "layout": "IPY_MODEL_fd53a31116d44d8590c455ab1445a02d"
          }
        },
        "603174f1cf664768a03c634a679545cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c43048129d64db1bd7daf64cab84460",
            "placeholder": "​",
            "style": "IPY_MODEL_0f42fba990ac4885bcea2c2b3acc00b0",
            "value": "README.md: 100%"
          }
        },
        "92914d1d4cc141fa8ab75b645353055e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205a1af6d9e546728a07b60401a9a5c8",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c3d54b1be9c4043bf56a018e2b11a28",
            "value": 7940
          }
        },
        "87182e8fd02b4ed596cf935f6510289c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_643fe7f0af394d38aea9c42baf7ef2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_c8bb4057ec2c4620939c9a503be0b4d7",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 240kB/s]"
          }
        },
        "fd53a31116d44d8590c455ab1445a02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c43048129d64db1bd7daf64cab84460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f42fba990ac4885bcea2c2b3acc00b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "205a1af6d9e546728a07b60401a9a5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3d54b1be9c4043bf56a018e2b11a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "643fe7f0af394d38aea9c42baf7ef2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bb4057ec2c4620939c9a503be0b4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa81d75047f347fb900b141a19d4d62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23302160b0d6478f9d238a4d55c8be07",
              "IPY_MODEL_9cd09181f59a433bb395c5ca83a7c1c8",
              "IPY_MODEL_254241a8d89249a8b4757de5aacedcc8"
            ],
            "layout": "IPY_MODEL_80e073d2b22e479c8d24aa2738fe5322"
          }
        },
        "23302160b0d6478f9d238a4d55c8be07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173d3010db714e3fb1ff2582ba2b1ff8",
            "placeholder": "​",
            "style": "IPY_MODEL_d86d87f222e44c86bcd3e66d2c2744ba",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "9cd09181f59a433bb395c5ca83a7c1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44624ec41b0d4ba694b6fbb1a7c59a50",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df201a1ea6cf4b7c821f28365f90eb06",
            "value": 2306545
          }
        },
        "254241a8d89249a8b4757de5aacedcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c3f143688e41978b8b7761d2f4e9a4",
            "placeholder": "​",
            "style": "IPY_MODEL_7adb7c8cab2a4802ad7fee84d732291d",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 37.2MB/s]"
          }
        },
        "80e073d2b22e479c8d24aa2738fe5322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173d3010db714e3fb1ff2582ba2b1ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86d87f222e44c86bcd3e66d2c2744ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44624ec41b0d4ba694b6fbb1a7c59a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df201a1ea6cf4b7c821f28365f90eb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9c3f143688e41978b8b7761d2f4e9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adb7c8cab2a4802ad7fee84d732291d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3512374e48124836a4c5a50cefa8afa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f8c064eab514909aff4c668b6303869",
              "IPY_MODEL_ad677f5bb6bc4b3094d3db6b3648dbb6",
              "IPY_MODEL_2089b8ffde5846d8afe931d879f2ca29"
            ],
            "layout": "IPY_MODEL_d14d10fa1b5b4f01b33af2216a70130d"
          }
        },
        "5f8c064eab514909aff4c668b6303869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bcd3fa67cf74aa2b877f34db4eb0146",
            "placeholder": "​",
            "style": "IPY_MODEL_4369939f51634591bc805ff77e376820",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "ad677f5bb6bc4b3094d3db6b3648dbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6660f38e3e94d84b63da62d34a07054",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_432834a28b484871a52ce6c143383a80",
            "value": 419088
          }
        },
        "2089b8ffde5846d8afe931d879f2ca29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3659bc79773d4ed1879b9fa8275267c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e9769e0332a74ab0913295b99e33e646",
            "value": " 419k/419k [00:00&lt;00:00, 8.52MB/s]"
          }
        },
        "d14d10fa1b5b4f01b33af2216a70130d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcd3fa67cf74aa2b877f34db4eb0146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4369939f51634591bc805ff77e376820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6660f38e3e94d84b63da62d34a07054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432834a28b484871a52ce6c143383a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3659bc79773d4ed1879b9fa8275267c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9769e0332a74ab0913295b99e33e646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a674d5c5241e4714980f679f024b5976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a5a3b298a4494088c2c9c929c7efaf",
              "IPY_MODEL_6a01c29cfcb24eff9658c2aaeb4cbb47",
              "IPY_MODEL_4ec9185604af49788f88467d2b7cea8a"
            ],
            "layout": "IPY_MODEL_acb981d824404a1caf0c8b38f5c78003"
          }
        },
        "89a5a3b298a4494088c2c9c929c7efaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10cdb1fd1ca4fe394bebded8961efb5",
            "placeholder": "​",
            "style": "IPY_MODEL_008aaa00f4cc4393a985ead019f88f86",
            "value": "Generating train split: 100%"
          }
        },
        "6a01c29cfcb24eff9658c2aaeb4cbb47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a4756cafef4312b228f1166438072c",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fb0d7a7f5bf4e71aeaeadeec02dc381",
            "value": 7473
          }
        },
        "4ec9185604af49788f88467d2b7cea8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bec6458ad5f4d1ca0333971e7828681",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6e4820e1df47b8bd7c5469b0ec3a64",
            "value": " 7473/7473 [00:00&lt;00:00, 7455.43 examples/s]"
          }
        },
        "acb981d824404a1caf0c8b38f5c78003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10cdb1fd1ca4fe394bebded8961efb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008aaa00f4cc4393a985ead019f88f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a4756cafef4312b228f1166438072c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb0d7a7f5bf4e71aeaeadeec02dc381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bec6458ad5f4d1ca0333971e7828681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6e4820e1df47b8bd7c5469b0ec3a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae1ffec497f5438a86b954f73831b934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c04e62b1464118bfdaa2287d3c505c",
              "IPY_MODEL_da1d16c6626f435fa5748398a07828b5",
              "IPY_MODEL_b4fa8cd6894b4c6fbd69680bf48faa3b"
            ],
            "layout": "IPY_MODEL_db6f686722d241e8a808e6c58939a623"
          }
        },
        "e2c04e62b1464118bfdaa2287d3c505c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_429362dc369e47938429dbb3bfdff66b",
            "placeholder": "​",
            "style": "IPY_MODEL_8052e131d26c40ae9e51a7a4c760d8ba",
            "value": "Generating test split: 100%"
          }
        },
        "da1d16c6626f435fa5748398a07828b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215a2212d1084bd1aa44673698feda65",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd54a46d12874d699940636f51a333a5",
            "value": 1319
          }
        },
        "b4fa8cd6894b4c6fbd69680bf48faa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219d364b27fb42349fe77aabbd8d8714",
            "placeholder": "​",
            "style": "IPY_MODEL_a943c0d1f6804cf7b5a13f4f3bc65f45",
            "value": " 1319/1319 [00:00&lt;00:00, 14470.46 examples/s]"
          }
        },
        "db6f686722d241e8a808e6c58939a623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429362dc369e47938429dbb3bfdff66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8052e131d26c40ae9e51a7a4c760d8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215a2212d1084bd1aa44673698feda65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd54a46d12874d699940636f51a333a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "219d364b27fb42349fe77aabbd8d8714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a943c0d1f6804cf7b5a13f4f3bc65f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1dda09d93db4713bf9e415d70c75033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1717dbfb76534dd4891639e2effcf051",
              "IPY_MODEL_8e188c07cf74402ab562f8c0c5004ce9",
              "IPY_MODEL_28ddac5738bb43028601c7867def334f"
            ],
            "layout": "IPY_MODEL_bf5c6b5e5f064f3c9f33f4a0abe7a2e7"
          }
        },
        "1717dbfb76534dd4891639e2effcf051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e6c5742edf4f40bcffd5f41a5b1c88",
            "placeholder": "​",
            "style": "IPY_MODEL_f642280d8a27493a95b0221219c4f15f",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "8e188c07cf74402ab562f8c0c5004ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31c38377bf34953bc591c246f95e765",
            "max": 2677259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_165a0752484a4a3bb7d3c662d5550a3e",
            "value": 2677259
          }
        },
        "28ddac5738bb43028601c7867def334f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca2f295cd8e4de09f96cbb2157c9ee3",
            "placeholder": "​",
            "style": "IPY_MODEL_e53567ab10574686af47650ffe59fe76",
            "value": " 2.68M/2.68M [00:00&lt;00:00, 73.0MB/s]"
          }
        },
        "bf5c6b5e5f064f3c9f33f4a0abe7a2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e6c5742edf4f40bcffd5f41a5b1c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f642280d8a27493a95b0221219c4f15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a31c38377bf34953bc591c246f95e765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165a0752484a4a3bb7d3c662d5550a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aca2f295cd8e4de09f96cbb2157c9ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53567ab10574686af47650ffe59fe76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c64b4b51815468c9832d4e3312f0375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a010d598a4774b5abef66193d6dfe0c0",
              "IPY_MODEL_b20ac6056b7545de8c3709aedf18fcf2",
              "IPY_MODEL_18bde319cc514cea997706d9f10d1dec"
            ],
            "layout": "IPY_MODEL_1111c2c9964f49f583a97cb3e6aea956"
          }
        },
        "a010d598a4774b5abef66193d6dfe0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc5d1beebe44f5080a55209f0fc28ec",
            "placeholder": "​",
            "style": "IPY_MODEL_dbba694433864af28e2aa51ecf556802",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "b20ac6056b7545de8c3709aedf18fcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e0d4db60dae4916b6da11ddd3c0390b",
            "max": 486995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04ac5116eaa7479280da8a0b3ac2bc39",
            "value": 486995
          }
        },
        "18bde319cc514cea997706d9f10d1dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13dae3fb7fbb4ec692923794ed6979bd",
            "placeholder": "​",
            "style": "IPY_MODEL_cd07779102544e42b311bb05b0af0bf9",
            "value": " 487k/487k [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "1111c2c9964f49f583a97cb3e6aea956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc5d1beebe44f5080a55209f0fc28ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbba694433864af28e2aa51ecf556802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e0d4db60dae4916b6da11ddd3c0390b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ac5116eaa7479280da8a0b3ac2bc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13dae3fb7fbb4ec692923794ed6979bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd07779102544e42b311bb05b0af0bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf631a93cd584ad78d12b2c0e20f426a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8dbf2bc65a04b8a82c271176a428b3a",
              "IPY_MODEL_4d27cea275dc404c9610144711b7b55b",
              "IPY_MODEL_775cd8af5ae8478aabfe144772be7021"
            ],
            "layout": "IPY_MODEL_9695fc6bc6bc4fe7af76f714ad155466"
          }
        },
        "c8dbf2bc65a04b8a82c271176a428b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c98936ebe146978a69f944957a738a",
            "placeholder": "​",
            "style": "IPY_MODEL_4d33d796bf134f4e9b695a510599ef3b",
            "value": "Generating train split: 100%"
          }
        },
        "4d27cea275dc404c9610144711b7b55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b06d226dee44468510342c3541f34c",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a32675f2952742c8810d885030afcd3f",
            "value": 7473
          }
        },
        "775cd8af5ae8478aabfe144772be7021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f22a29fc97f4d29926d162dbb658d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_0c392623c4314fc590ecdfc1bedc63bc",
            "value": " 7473/7473 [00:00&lt;00:00, 60057.78 examples/s]"
          }
        },
        "9695fc6bc6bc4fe7af76f714ad155466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c98936ebe146978a69f944957a738a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d33d796bf134f4e9b695a510599ef3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67b06d226dee44468510342c3541f34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32675f2952742c8810d885030afcd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f22a29fc97f4d29926d162dbb658d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c392623c4314fc590ecdfc1bedc63bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36a720e2791d4c559ef5f95009f4997c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e63ac12eaf34d808c2a04f77c03519e",
              "IPY_MODEL_0bcfb8c55e3c4c19bb8a63ceb736f676",
              "IPY_MODEL_281d360a51f647a6adc89c5a7ba64e88"
            ],
            "layout": "IPY_MODEL_6ded1ac78f204c698fe70b83c0373863"
          }
        },
        "7e63ac12eaf34d808c2a04f77c03519e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fc86122ee24a478c107d5139bbe6fe",
            "placeholder": "​",
            "style": "IPY_MODEL_be5bbf67fe074e7993f47d6cb622db4a",
            "value": "Generating test split: 100%"
          }
        },
        "0bcfb8c55e3c4c19bb8a63ceb736f676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c14e8c8fdd4cf3a4fb496a709fc8b5",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_318ede025c4e4b0f937409a40df714f0",
            "value": 1319
          }
        },
        "281d360a51f647a6adc89c5a7ba64e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56639be934b406c8fe4ddaf14de79a6",
            "placeholder": "​",
            "style": "IPY_MODEL_3394522336b6454fa58b4ea1cfe41f67",
            "value": " 1319/1319 [00:00&lt;00:00, 8245.08 examples/s]"
          }
        },
        "6ded1ac78f204c698fe70b83c0373863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fc86122ee24a478c107d5139bbe6fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5bbf67fe074e7993f47d6cb622db4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c14e8c8fdd4cf3a4fb496a709fc8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318ede025c4e4b0f937409a40df714f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a56639be934b406c8fe4ddaf14de79a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3394522336b6454fa58b4ea1cfe41f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47e9f7ca50f547618825e60d207abc51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9020dce0628e40fdbe89ed59eaa4ecf2",
              "IPY_MODEL_c827704c72cb4fb0bb4d8bf0c62d98d2",
              "IPY_MODEL_b00e578121cd42af88cb77543940fd0f"
            ],
            "layout": "IPY_MODEL_624321bc7c404aa79f2575a49950cd49"
          }
        },
        "9020dce0628e40fdbe89ed59eaa4ecf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76b37b26202946e283a22df66aab676e",
            "placeholder": "​",
            "style": "IPY_MODEL_e3be7df0b8af4598b3807c8fe38ca93e",
            "value": "Map: 100%"
          }
        },
        "c827704c72cb4fb0bb4d8bf0c62d98d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59aa8f81b9545c58c25f34de09087a5",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0676b7582963499b8f9c865e6008ab21",
            "value": 3000
          }
        },
        "b00e578121cd42af88cb77543940fd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e048d44bdb441d880dabc655a08c005",
            "placeholder": "​",
            "style": "IPY_MODEL_68187f0b7a0c4f18bba2568c706eeabf",
            "value": " 3000/3000 [00:07&lt;00:00, 439.79 examples/s]"
          }
        },
        "624321bc7c404aa79f2575a49950cd49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b37b26202946e283a22df66aab676e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3be7df0b8af4598b3807c8fe38ca93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d59aa8f81b9545c58c25f34de09087a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0676b7582963499b8f9c865e6008ab21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e048d44bdb441d880dabc655a08c005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68187f0b7a0c4f18bba2568c706eeabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e754f83a39cf44c6942e9c48a8fc5b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a4f3e484ced4ab09fdd0b71be9e31a4",
              "IPY_MODEL_cb5ccc20dc35446693ea42be8604b2ae",
              "IPY_MODEL_1b98bb69c60a4d358aa65ae8049e56c2"
            ],
            "layout": "IPY_MODEL_da0396b78e1a430e9c1b410a5aadb5b6"
          }
        },
        "5a4f3e484ced4ab09fdd0b71be9e31a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1460d5bd1e0144b783ba0e16bcbee139",
            "placeholder": "​",
            "style": "IPY_MODEL_42eee685f16e4aa59e5575a4d5cbc9a8",
            "value": "Map: 100%"
          }
        },
        "cb5ccc20dc35446693ea42be8604b2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0170a2d3d8aa4b1fa71e5666116fef4c",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fddd0734b584a58a9e36111564aa8d8",
            "value": 1319
          }
        },
        "1b98bb69c60a4d358aa65ae8049e56c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030ef5e4b90c493cac58dbf92a556dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_1cae6794fa004cb0863e301ba7a73d6d",
            "value": " 1319/1319 [00:03&lt;00:00, 419.49 examples/s]"
          }
        },
        "da0396b78e1a430e9c1b410a5aadb5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1460d5bd1e0144b783ba0e16bcbee139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42eee685f16e4aa59e5575a4d5cbc9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0170a2d3d8aa4b1fa71e5666116fef4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fddd0734b584a58a9e36111564aa8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "030ef5e4b90c493cac58dbf92a556dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cae6794fa004cb0863e301ba7a73d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc0cf80f4aa4cbabed4eebf3ac8af02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c54ce85f5a324d2a9053c9dda910fa11",
              "IPY_MODEL_77ceec90adc44a36a85fe1ef976b72f9",
              "IPY_MODEL_ce03b09fee624e17aec23fd73736a3f1"
            ],
            "layout": "IPY_MODEL_340837bbe79f48e0a396b2bb3d334ea7"
          }
        },
        "c54ce85f5a324d2a9053c9dda910fa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53473547fd7d4b4a92bbbecd379def23",
            "placeholder": "​",
            "style": "IPY_MODEL_4e778c4fc7034e49b5e985d9e0f7c8e2",
            "value": "README.md: 100%"
          }
        },
        "77ceec90adc44a36a85fe1ef976b72f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7cef2021d74963bc5ded0b1593feb8",
            "max": 3899,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06705d048dae430ab025c8a0933e9223",
            "value": 3899
          }
        },
        "ce03b09fee624e17aec23fd73736a3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b27e10917d4784ba40792e16c7234b",
            "placeholder": "​",
            "style": "IPY_MODEL_b1610d8f56fc480f939110acc060829a",
            "value": " 3.90k/3.90k [00:00&lt;00:00, 359kB/s]"
          }
        },
        "340837bbe79f48e0a396b2bb3d334ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53473547fd7d4b4a92bbbecd379def23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e778c4fc7034e49b5e985d9e0f7c8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7cef2021d74963bc5ded0b1593feb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06705d048dae430ab025c8a0933e9223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65b27e10917d4784ba40792e16c7234b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1610d8f56fc480f939110acc060829a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129109f6cf2c4c2b850aa844ab133911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69a11b64c19a4cd7a7e6f850372fe22d",
              "IPY_MODEL_c53cc8a5d02041179bb84d30b44af9f4",
              "IPY_MODEL_ce83278fff8e42a48a623b59d70ecc8c"
            ],
            "layout": "IPY_MODEL_d6a2ba39f506497a8833dc35bf9594e2"
          }
        },
        "69a11b64c19a4cd7a7e6f850372fe22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b8ee9619a243aa9f47b83b5832ab3f",
            "placeholder": "​",
            "style": "IPY_MODEL_bcef9db476474ef990f0d086af8364c2",
            "value": "(…)-00000-of-00003-a3ecf92756993583.parquet: 100%"
          }
        },
        "c53cc8a5d02041179bb84d30b44af9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_508bfa67bc7d4a87a5d30fcffa1b73c6",
            "max": 243999189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9bd5c74f53b4e26937d01264e6eca2a",
            "value": 243999189
          }
        },
        "ce83278fff8e42a48a623b59d70ecc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811a1a5f66fd4b9cbd913a608cd42071",
            "placeholder": "​",
            "style": "IPY_MODEL_4575b6c1063a43d395e042c79c29ba5b",
            "value": " 244M/244M [00:01&lt;00:00, 229MB/s]"
          }
        },
        "d6a2ba39f506497a8833dc35bf9594e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b8ee9619a243aa9f47b83b5832ab3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcef9db476474ef990f0d086af8364c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "508bfa67bc7d4a87a5d30fcffa1b73c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bd5c74f53b4e26937d01264e6eca2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "811a1a5f66fd4b9cbd913a608cd42071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4575b6c1063a43d395e042c79c29ba5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d2ae52b0e9481d87ecd0a1dc2151ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df67f546be3746618dbee09ba9c062c8",
              "IPY_MODEL_a11bcb37f6714f63a40918566c2ad424",
              "IPY_MODEL_cb6568d89ee6436d99642cec6d10ce08"
            ],
            "layout": "IPY_MODEL_0873f799b8154173abc96f7b9136e41a"
          }
        },
        "df67f546be3746618dbee09ba9c062c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb34d00b5cb4320862f0d7464279b54",
            "placeholder": "​",
            "style": "IPY_MODEL_0c10203fdd2e459690ec4cc44eb450a4",
            "value": "(…)-00001-of-00003-0a1804bcb6ae68c6.parquet: 100%"
          }
        },
        "a11bcb37f6714f63a40918566c2ad424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85461f29f85e46898f337742dbf2e413",
            "max": 243897199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99eaa1a0749448a58c440d4ec8a68f05",
            "value": 243897199
          }
        },
        "cb6568d89ee6436d99642cec6d10ce08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c2cb64e65fa4bf2a98f0901b448a043",
            "placeholder": "​",
            "style": "IPY_MODEL_46b44b011afb4aaa8575dea429b9314d",
            "value": " 244M/244M [00:01&lt;00:00, 204MB/s]"
          }
        },
        "0873f799b8154173abc96f7b9136e41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb34d00b5cb4320862f0d7464279b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c10203fdd2e459690ec4cc44eb450a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85461f29f85e46898f337742dbf2e413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99eaa1a0749448a58c440d4ec8a68f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c2cb64e65fa4bf2a98f0901b448a043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b44b011afb4aaa8575dea429b9314d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8670eec6bea1440fb3c79e7356d0bc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eab5cc1ca16c4fa5ab5bb7061f215c2b",
              "IPY_MODEL_2932c37098a74f68b8a64968ddf894be",
              "IPY_MODEL_303c5205fc50450bb953c449ec9f6003"
            ],
            "layout": "IPY_MODEL_2bf36dd3bcc44621a2147da13248f572"
          }
        },
        "eab5cc1ca16c4fa5ab5bb7061f215c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717b7ce100784145a7ae693ae46c9844",
            "placeholder": "​",
            "style": "IPY_MODEL_039ee33d882a4497975403fe5188efe3",
            "value": "(…)-00002-of-00003-ee46ed25cfae92c6.parquet: 100%"
          }
        },
        "2932c37098a74f68b8a64968ddf894be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312cda29b4aa40d18e3ead3617e91bfe",
            "max": 244131731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f838b196d37f4924b80027c003580ceb",
            "value": 244131731
          }
        },
        "303c5205fc50450bb953c449ec9f6003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7537213b3cd643d599ab704d7258aa13",
            "placeholder": "​",
            "style": "IPY_MODEL_fea2665bc3de421bb58e9c7f6144a6e8",
            "value": " 244M/244M [00:01&lt;00:00, 198MB/s]"
          }
        },
        "2bf36dd3bcc44621a2147da13248f572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717b7ce100784145a7ae693ae46c9844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039ee33d882a4497975403fe5188efe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312cda29b4aa40d18e3ead3617e91bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f838b196d37f4924b80027c003580ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7537213b3cd643d599ab704d7258aa13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea2665bc3de421bb58e9c7f6144a6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5486ed2b2d74f23b74c5133f995fa87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d3bd8193b3b4c6ead3cd81c68be3603",
              "IPY_MODEL_0909e9d2790b4ecc844158a37e2306c4",
              "IPY_MODEL_86151317d7084977be22798cf5038dec"
            ],
            "layout": "IPY_MODEL_50bff602a2bc45548fa153047a76468b"
          }
        },
        "8d3bd8193b3b4c6ead3cd81c68be3603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e307d5d31241a68eec3770fdd59bed",
            "placeholder": "​",
            "style": "IPY_MODEL_e33340525234469aa134e1f14b8a4ef9",
            "value": "(…)-00000-of-00001-f7dfac4afe5b93f4.parquet: 100%"
          }
        },
        "0909e9d2790b4ecc844158a37e2306c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ae457c88324cf98aaea7529a8c26ac",
            "max": 81176553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ca7c514296401d8158e17faf841c79",
            "value": 81176553
          }
        },
        "86151317d7084977be22798cf5038dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701ad11494004bafb6a9a1727fcacbc4",
            "placeholder": "​",
            "style": "IPY_MODEL_b06983b4847943e993d6fb5438384cf2",
            "value": " 81.2M/81.2M [00:00&lt;00:00, 274MB/s]"
          }
        },
        "50bff602a2bc45548fa153047a76468b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e307d5d31241a68eec3770fdd59bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33340525234469aa134e1f14b8a4ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ae457c88324cf98aaea7529a8c26ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ca7c514296401d8158e17faf841c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "701ad11494004bafb6a9a1727fcacbc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06983b4847943e993d6fb5438384cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06f58424b7d4545be10c50a76cc90f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18cb0a858002426dae97635cfd915604",
              "IPY_MODEL_2cbd9d7dd57e46d7a231b5c3c6b646d9",
              "IPY_MODEL_84e77de13d854a2da2d9321512cc6d21"
            ],
            "layout": "IPY_MODEL_b79e665908b6443b9143a35d869bf226"
          }
        },
        "18cb0a858002426dae97635cfd915604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f891becbf5c44f491af8123195b16bf",
            "placeholder": "​",
            "style": "IPY_MODEL_1c54a1d03cc041efa577f526872ed18a",
            "value": "(…)-00000-of-00003-a6c9fb894be3e50b.parquet: 100%"
          }
        },
        "2cbd9d7dd57e46d7a231b5c3c6b646d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a81a5fbbebc446a8e81a3b3d62b6724",
            "max": 243687391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_945f78ab75d14e3f9ba5300063af1a78",
            "value": 243687391
          }
        },
        "84e77de13d854a2da2d9321512cc6d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef7657d34c14e5c8802a1280e42ab39",
            "placeholder": "​",
            "style": "IPY_MODEL_da6c38cf81d64f86968e44e7970934a6",
            "value": " 244M/244M [00:01&lt;00:00, 166MB/s]"
          }
        },
        "b79e665908b6443b9143a35d869bf226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f891becbf5c44f491af8123195b16bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c54a1d03cc041efa577f526872ed18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a81a5fbbebc446a8e81a3b3d62b6724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945f78ab75d14e3f9ba5300063af1a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eef7657d34c14e5c8802a1280e42ab39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6c38cf81d64f86968e44e7970934a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7b1e06be0054e5084a22ad1cb5cec90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f62737c6f3004af58b000dd0eeccab31",
              "IPY_MODEL_82fed2b25087428dac4f24ab10fdb304",
              "IPY_MODEL_a27dcaed95034de1b8d62b83803333c0"
            ],
            "layout": "IPY_MODEL_5cdbbffbd86f4bfaaacb9132754bddd5"
          }
        },
        "f62737c6f3004af58b000dd0eeccab31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3284dd64069437e95c50ca3a3b6aec3",
            "placeholder": "​",
            "style": "IPY_MODEL_270a629ca0e348bbbe65fac72e134859",
            "value": "(…)-00001-of-00003-d6a0402e417f35ca.parquet: 100%"
          }
        },
        "82fed2b25087428dac4f24ab10fdb304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e644e591056d45cdb2dc84040c43a344",
            "max": 243300397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d02ececb04b4c9aa028182a22f7a7f9",
            "value": 243300397
          }
        },
        "a27dcaed95034de1b8d62b83803333c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9fe853ce8243ce8fd2f573b8ffcab9",
            "placeholder": "​",
            "style": "IPY_MODEL_6caa0f5d1b6d407f838e88f0690a7b7f",
            "value": " 243M/243M [00:01&lt;00:00, 186MB/s]"
          }
        },
        "5cdbbffbd86f4bfaaacb9132754bddd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3284dd64069437e95c50ca3a3b6aec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270a629ca0e348bbbe65fac72e134859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e644e591056d45cdb2dc84040c43a344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d02ececb04b4c9aa028182a22f7a7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9fe853ce8243ce8fd2f573b8ffcab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6caa0f5d1b6d407f838e88f0690a7b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ead27161f8f454c989816ffccf884c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edeee90b44ab42cb9cd21235fdcd8000",
              "IPY_MODEL_f3c268f412fb485285b40d6c208a1753",
              "IPY_MODEL_08680b03bf194c7c8aa421d14ba363a5"
            ],
            "layout": "IPY_MODEL_619afd85a80f454494996df7839cf744"
          }
        },
        "edeee90b44ab42cb9cd21235fdcd8000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b264557294794e2a8b002a2ac0831b89",
            "placeholder": "​",
            "style": "IPY_MODEL_ec55df8b446343ee8b258493f77bff22",
            "value": "(…)-00002-of-00003-c0db75b92a2f48fd.parquet: 100%"
          }
        },
        "f3c268f412fb485285b40d6c208a1753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f554659d4244b278a2054bd27bf3521",
            "max": 243497356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5977003e876f4cd9a951b71298a5aa48",
            "value": 243497356
          }
        },
        "08680b03bf194c7c8aa421d14ba363a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2662da3cf9714128adeb4158004afbc6",
            "placeholder": "​",
            "style": "IPY_MODEL_e6b9c981a4104240b0f0a37087795edc",
            "value": " 243M/243M [00:01&lt;00:00, 182MB/s]"
          }
        },
        "619afd85a80f454494996df7839cf744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b264557294794e2a8b002a2ac0831b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec55df8b446343ee8b258493f77bff22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f554659d4244b278a2054bd27bf3521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5977003e876f4cd9a951b71298a5aa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2662da3cf9714128adeb4158004afbc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b9c981a4104240b0f0a37087795edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8c95fbcff8043f485f937a04c18edc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d9fbaf1e32b4f06a36b5dd00eb2af65",
              "IPY_MODEL_bc260a702ecb4525838afc021f65b771",
              "IPY_MODEL_ac74f6a8ae6447a9a03cdd90e4bcac3a"
            ],
            "layout": "IPY_MODEL_64b771abd79641bd91e2bc85729da97a"
          }
        },
        "9d9fbaf1e32b4f06a36b5dd00eb2af65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fffc4d9e34f2423fa62b8eeededccfb4",
            "placeholder": "​",
            "style": "IPY_MODEL_0e8032231547496493f15c714eaa74b3",
            "value": "(…)-00000-of-00001-3d4cd8309148a71f.parquet: 100%"
          }
        },
        "bc260a702ecb4525838afc021f65b771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f1c86a02924e058e4d387443d802e5",
            "max": 80359907,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62a6d504dee34a66bfc904275eb21f68",
            "value": 80359907
          }
        },
        "ac74f6a8ae6447a9a03cdd90e4bcac3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305f8d3e9b594be1ab2a3691b41b2dae",
            "placeholder": "​",
            "style": "IPY_MODEL_6c672ee3af2c4b309951a9882e0ab5da",
            "value": " 80.4M/80.4M [00:01&lt;00:00, 57.5MB/s]"
          }
        },
        "64b771abd79641bd91e2bc85729da97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffc4d9e34f2423fa62b8eeededccfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8032231547496493f15c714eaa74b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f1c86a02924e058e4d387443d802e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a6d504dee34a66bfc904275eb21f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "305f8d3e9b594be1ab2a3691b41b2dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c672ee3af2c4b309951a9882e0ab5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f7fc4eba8c4ed9b9715ea34d7deadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_474cfcdc6c154a70b0673fa3e5d125b7",
              "IPY_MODEL_5900747e4650400695b8e7f6608c4205",
              "IPY_MODEL_4720a751ab2f47cb9af7a747cf9e7871"
            ],
            "layout": "IPY_MODEL_2d6ddaf50bec44ccb7ee0fa3ecd7bb4c"
          }
        },
        "474cfcdc6c154a70b0673fa3e5d125b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e489bf56c34020b651723dd5497571",
            "placeholder": "​",
            "style": "IPY_MODEL_c5307deb99be419a847aa63d88a5255b",
            "value": "Generating train_sft split: 100%"
          }
        },
        "5900747e4650400695b8e7f6608c4205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b831d4073e40c398874905c80df9be",
            "max": 207865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50e1a323a2874941b185112e21d52fef",
            "value": 207865
          }
        },
        "4720a751ab2f47cb9af7a747cf9e7871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e96d3e57f54e25bbdb8db340d092cb",
            "placeholder": "​",
            "style": "IPY_MODEL_1349a0e1d1434532ba6f2063b7cf0f5b",
            "value": " 207865/207865 [00:11&lt;00:00, 18188.04 examples/s]"
          }
        },
        "2d6ddaf50bec44ccb7ee0fa3ecd7bb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e489bf56c34020b651723dd5497571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5307deb99be419a847aa63d88a5255b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b831d4073e40c398874905c80df9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e1a323a2874941b185112e21d52fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6e96d3e57f54e25bbdb8db340d092cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1349a0e1d1434532ba6f2063b7cf0f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb0c4b479a184d4daf9ea881ee2b224b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e24b6114cb44c9abe6b5c9cc933503f",
              "IPY_MODEL_5708d3e5e6404806b6eeb1703c5c2c26",
              "IPY_MODEL_3e302d58b7294c95ab325501e424a726"
            ],
            "layout": "IPY_MODEL_7ba78dbd7bea4967b1b2657bba6ce81e"
          }
        },
        "3e24b6114cb44c9abe6b5c9cc933503f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b5a575829d423899842d8081935aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_1420649a21c04885bf4d167b64d787df",
            "value": "Generating test_sft split: 100%"
          }
        },
        "5708d3e5e6404806b6eeb1703c5c2c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c858caa1750400b8d3374d57e4389ca",
            "max": 23110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86d77fd7f1be4402a7e29e0063d87da1",
            "value": 23110
          }
        },
        "3e302d58b7294c95ab325501e424a726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7b6869201740c8a30d7a56d4bf983d",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0dbc1c191f4f0f8970be475022095c",
            "value": " 23110/23110 [00:01&lt;00:00, 14180.56 examples/s]"
          }
        },
        "7ba78dbd7bea4967b1b2657bba6ce81e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b5a575829d423899842d8081935aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1420649a21c04885bf4d167b64d787df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c858caa1750400b8d3374d57e4389ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d77fd7f1be4402a7e29e0063d87da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a7b6869201740c8a30d7a56d4bf983d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0dbc1c191f4f0f8970be475022095c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db220faea264a6997a488ce0eee0b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ba3b78a7c14dd6adca43006b87420a",
              "IPY_MODEL_57faec1e2a6749e98caebeeac60c0757",
              "IPY_MODEL_c1b425f2698044c19998a3ca634bb8ab"
            ],
            "layout": "IPY_MODEL_f1aed59fee2c461c98b21a3961a3fd1c"
          }
        },
        "75ba3b78a7c14dd6adca43006b87420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caf6e946ff8841cdbd4726999a2fae29",
            "placeholder": "​",
            "style": "IPY_MODEL_c577b7605fef4dd099495036c9183c26",
            "value": "Generating train_gen split: 100%"
          }
        },
        "57faec1e2a6749e98caebeeac60c0757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2611b89b134906a102580fc0378783",
            "max": 256032,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e5e4a513dc145439256f35b0a43d161",
            "value": 256032
          }
        },
        "c1b425f2698044c19998a3ca634bb8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c71b9cd8d74022bd48569893db7f55",
            "placeholder": "​",
            "style": "IPY_MODEL_4b19e986d6ae4f10a0609af5b62b6079",
            "value": " 256032/256032 [00:13&lt;00:00, 17201.68 examples/s]"
          }
        },
        "f1aed59fee2c461c98b21a3961a3fd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf6e946ff8841cdbd4726999a2fae29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c577b7605fef4dd099495036c9183c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b2611b89b134906a102580fc0378783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5e4a513dc145439256f35b0a43d161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4c71b9cd8d74022bd48569893db7f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b19e986d6ae4f10a0609af5b62b6079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f03755c4974eb4a6461c5bdbd87807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c3b5cb5d73424d96d855d8b7be39d4",
              "IPY_MODEL_248008561e6441d898d427afa6a48057",
              "IPY_MODEL_5521a044a60e46eaa1fa14cd37b50ab1"
            ],
            "layout": "IPY_MODEL_df28826c487b4322aed8c0a9ca524ebb"
          }
        },
        "97c3b5cb5d73424d96d855d8b7be39d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e31ca5e79c4300b50f237a42daacfe",
            "placeholder": "​",
            "style": "IPY_MODEL_cce90975169c482ca345f27e67a6b6bc",
            "value": "Generating test_gen split: 100%"
          }
        },
        "248008561e6441d898d427afa6a48057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba8d82417af14abaa4233338beeb9326",
            "max": 28304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f388351b238498d93bee8f6df74df1a",
            "value": 28304
          }
        },
        "5521a044a60e46eaa1fa14cd37b50ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_431a088340804fd89e9bf96ab3f970e1",
            "placeholder": "​",
            "style": "IPY_MODEL_6844400476e64d24bf068183bee54948",
            "value": " 28304/28304 [00:01&lt;00:00, 18933.73 examples/s]"
          }
        },
        "df28826c487b4322aed8c0a9ca524ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e31ca5e79c4300b50f237a42daacfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce90975169c482ca345f27e67a6b6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba8d82417af14abaa4233338beeb9326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f388351b238498d93bee8f6df74df1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "431a088340804fd89e9bf96ab3f970e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6844400476e64d24bf068183bee54948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab65d926acf4f518a1bea898683dc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c59740bf40ab4e9c8a2bb1a9037f7111",
              "IPY_MODEL_a07ae49134c94bc1ad1c1357cd35752e",
              "IPY_MODEL_bc1a23a65d9a4d7aa5cefff997800f74"
            ],
            "layout": "IPY_MODEL_a23e1aa224084e84a5f26fadcece5d64"
          }
        },
        "c59740bf40ab4e9c8a2bb1a9037f7111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c2d5d0a8fca4bdcb511fcad7dfabeb5",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9d5ebd66e942fd9703391952dc741a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a07ae49134c94bc1ad1c1357cd35752e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3574e8c76a8491eaeca4a2ab4446e99",
            "max": 7228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bc4e20ccd884074bf12adbd96cabc43",
            "value": 7228
          }
        },
        "bc1a23a65d9a4d7aa5cefff997800f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a3d492e4434564a3554f88e71bed58",
            "placeholder": "​",
            "style": "IPY_MODEL_7196aa0a5ae244a18ceab58176881225",
            "value": " 7.23k/7.23k [00:00&lt;00:00, 750kB/s]"
          }
        },
        "a23e1aa224084e84a5f26fadcece5d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2d5d0a8fca4bdcb511fcad7dfabeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9d5ebd66e942fd9703391952dc741a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3574e8c76a8491eaeca4a2ab4446e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc4e20ccd884074bf12adbd96cabc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23a3d492e4434564a3554f88e71bed58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7196aa0a5ae244a18ceab58176881225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36f6c9f2be664c73be0355af2d3de4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_257623bbd53b4f71b6cc226b3fcccfbb",
              "IPY_MODEL_fef49f363a354fafb249d4fae77a5fd5",
              "IPY_MODEL_cb783b4e62634034893f4b25db87177e"
            ],
            "layout": "IPY_MODEL_3bf8128e58f94ae3899ccd993e77e291"
          }
        },
        "257623bbd53b4f71b6cc226b3fcccfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d803c3fbee44dbb9cc624d9ddc3111",
            "placeholder": "​",
            "style": "IPY_MODEL_53ee87eb5d2944bf8db3ac4b9e409c5e",
            "value": "vocab.json:   0%"
          }
        },
        "fef49f363a354fafb249d4fae77a5fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a46dfa6bf34a6083a126be3fadfc69",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00e64bb1a98b4e67951b693a63be12d7",
            "value": 0
          }
        },
        "cb783b4e62634034893f4b25db87177e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa1581cfff1943aea43f8c36ecb80fcb",
            "placeholder": "​",
            "style": "IPY_MODEL_9a50f09d31844b2cb4456a1a015fc019",
            "value": " 0.00/2.78M [00:02&lt;?, ?B/s]"
          }
        },
        "3bf8128e58f94ae3899ccd993e77e291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d803c3fbee44dbb9cc624d9ddc3111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ee87eb5d2944bf8db3ac4b9e409c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8a46dfa6bf34a6083a126be3fadfc69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e64bb1a98b4e67951b693a63be12d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa1581cfff1943aea43f8c36ecb80fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a50f09d31844b2cb4456a1a015fc019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f75e1dad81d4f98a8fc23176ac9b1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6b30cf9b0ed418fa0ae79fed85f5f9d",
              "IPY_MODEL_32cebbb8cafb4894afab3e9f61803d0c",
              "IPY_MODEL_2bbb98f945144d57949ec31600ae1a63"
            ],
            "layout": "IPY_MODEL_38e26098934b4529a08820c0f62284da"
          }
        },
        "b6b30cf9b0ed418fa0ae79fed85f5f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6661e7227e1a416eb865b0fdbf723eea",
            "placeholder": "​",
            "style": "IPY_MODEL_09fbe4bf5d474f3ba37ef998b15f1a9d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "32cebbb8cafb4894afab3e9f61803d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a61f090a007472dabb6a067cecf2888",
            "max": 7305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fc83aedecd64cfe996f78d8904e2d24",
            "value": 7305
          }
        },
        "2bbb98f945144d57949ec31600ae1a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf39fcb86a9403a9dd4ce5df36b6731",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc8d078388c45aa82d05a6744f3ecfd",
            "value": " 7.30k/7.30k [00:00&lt;00:00, 466kB/s]"
          }
        },
        "38e26098934b4529a08820c0f62284da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6661e7227e1a416eb865b0fdbf723eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09fbe4bf5d474f3ba37ef998b15f1a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a61f090a007472dabb6a067cecf2888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc83aedecd64cfe996f78d8904e2d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bf39fcb86a9403a9dd4ce5df36b6731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc8d078388c45aa82d05a6744f3ecfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bde5263313f14dd7974af3b37900d0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14e9055c58b040deb84332e340f7d0c8",
              "IPY_MODEL_d5e4b40d1d99419684ccc0e61e7c4769",
              "IPY_MODEL_4839db4c6f614c18b493fa1a9fa5bcfc"
            ],
            "layout": "IPY_MODEL_aae026abe2a44d4f9c3e4d306f596e53"
          }
        },
        "14e9055c58b040deb84332e340f7d0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a8da54f6b54cec854157ea01479411",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a8a5e2e8d84898ac7c7978499d6ac6",
            "value": "vocab.json: 100%"
          }
        },
        "d5e4b40d1d99419684ccc0e61e7c4769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9018f8f24a9347afbbc897a66bf64a1a",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9f8c0f30cfb48ce912bb754928e6bf3",
            "value": 2776833
          }
        },
        "4839db4c6f614c18b493fa1a9fa5bcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f078cc5232248648ed8b9f4304cd6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_c32e10b7c81244baab288538c6789bf4",
            "value": " 2.78M/2.78M [00:00&lt;00:00, 4.31MB/s]"
          }
        },
        "aae026abe2a44d4f9c3e4d306f596e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a8da54f6b54cec854157ea01479411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a8a5e2e8d84898ac7c7978499d6ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9018f8f24a9347afbbc897a66bf64a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f8c0f30cfb48ce912bb754928e6bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f078cc5232248648ed8b9f4304cd6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32e10b7c81244baab288538c6789bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7347b45a850453fae5ad43878167c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04c3af5b0d6a46e68cf42fc4f13ba237",
              "IPY_MODEL_a362b0d0d2aa4b2cbf43273831561767",
              "IPY_MODEL_9a9671342e5b4b03a02cb53de7d41680"
            ],
            "layout": "IPY_MODEL_5df80f65b6b1411b9e76ce71f4b9c390"
          }
        },
        "04c3af5b0d6a46e68cf42fc4f13ba237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9b1b1b6dec44c2904b957566911fb4",
            "placeholder": "​",
            "style": "IPY_MODEL_8b69afc1897c4a4ca7bf42eed4e08387",
            "value": "merges.txt: 100%"
          }
        },
        "a362b0d0d2aa4b2cbf43273831561767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7e668fea2e4d719b8f16ee9a5a8f5b",
            "max": 1671839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f23cab6e74ef43a0a0a661c8fcb060e5",
            "value": 1671839
          }
        },
        "9a9671342e5b4b03a02cb53de7d41680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92c446290a947dbb8fdad40e64cbc00",
            "placeholder": "​",
            "style": "IPY_MODEL_ead0d76f67864f60a8f63429098e0b84",
            "value": " 1.67M/1.67M [00:02&lt;00:00, 752kB/s]"
          }
        },
        "5df80f65b6b1411b9e76ce71f4b9c390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9b1b1b6dec44c2904b957566911fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b69afc1897c4a4ca7bf42eed4e08387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7e668fea2e4d719b8f16ee9a5a8f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23cab6e74ef43a0a0a661c8fcb060e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c92c446290a947dbb8fdad40e64cbc00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead0d76f67864f60a8f63429098e0b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "491bfd5686454787b54c19ce4c879e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd7c6916bb654badbb8be09874c64dd1",
              "IPY_MODEL_9a8f40316d5c4d86833e55b8897b8ba6",
              "IPY_MODEL_ea37a563467e4625b1f876e01a5e5ae9"
            ],
            "layout": "IPY_MODEL_8d16c5e406e941cca58bbb998ee1d3d4"
          }
        },
        "dd7c6916bb654badbb8be09874c64dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa301a14340b492a90a8fae8606881e8",
            "placeholder": "​",
            "style": "IPY_MODEL_88c69a72d5bd4431b2b8dbbc830a06c2",
            "value": "tokenizer.json: 100%"
          }
        },
        "9a8f40316d5c4d86833e55b8897b8ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9148f3c2062475aa711d4dd6eae03ea",
            "max": 7031645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4a249795ad244b6b5aef6191009fd92",
            "value": 7031645
          }
        },
        "ea37a563467e4625b1f876e01a5e5ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547a37ea310c4818a48e47a5ec8a2408",
            "placeholder": "​",
            "style": "IPY_MODEL_723d2561419e43ad83d72d3bf45bb4d0",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 8.15MB/s]"
          }
        },
        "8d16c5e406e941cca58bbb998ee1d3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa301a14340b492a90a8fae8606881e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c69a72d5bd4431b2b8dbbc830a06c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9148f3c2062475aa711d4dd6eae03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a249795ad244b6b5aef6191009fd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "547a37ea310c4818a48e47a5ec8a2408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723d2561419e43ad83d72d3bf45bb4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "194599d89f354f138d5a7160b5ceff56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6b62da3fb6a40c18d43ef55dff498bf",
              "IPY_MODEL_ecf21e7c6eed4462ac7b9a8dc586595b",
              "IPY_MODEL_adfdf8e5f05f495ebcf9608199387c3a"
            ],
            "layout": "IPY_MODEL_bc593a848b9b46bc80db226b6df023f8"
          }
        },
        "b6b62da3fb6a40c18d43ef55dff498bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1cd90258d0f47a9b2bc5b0c1bdf1bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_bf233d1c37a1473db8d65fb9b37dcb96",
            "value": "config.json: 100%"
          }
        },
        "ecf21e7c6eed4462ac7b9a8dc586595b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abca94b4c5d401793acece8430ad217",
            "max": 659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a3184e6d0e64e5697e7478efaeb186d",
            "value": 659
          }
        },
        "adfdf8e5f05f495ebcf9608199387c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3d09aa0529426a9c537d9626578cec",
            "placeholder": "​",
            "style": "IPY_MODEL_e1139a4e994e497cac3950d7af860221",
            "value": " 659/659 [00:00&lt;00:00, 68.9kB/s]"
          }
        },
        "bc593a848b9b46bc80db226b6df023f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1cd90258d0f47a9b2bc5b0c1bdf1bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf233d1c37a1473db8d65fb9b37dcb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abca94b4c5d401793acece8430ad217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3184e6d0e64e5697e7478efaeb186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3d09aa0529426a9c537d9626578cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1139a4e994e497cac3950d7af860221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95320aaebea44139863b8d69b67f825a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d3f009656214b3db27ba74eb863cf32",
              "IPY_MODEL_3679731329f44ad7bf637b5d31f4be6a",
              "IPY_MODEL_62cda8c7dd9142c6b96c473ac6058635"
            ],
            "layout": "IPY_MODEL_2ed62e930b434604b3b70052a3fa281a"
          }
        },
        "2d3f009656214b3db27ba74eb863cf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81917d44f2ee4574a883680a02dbebdb",
            "placeholder": "​",
            "style": "IPY_MODEL_0cb48070cb394598ae8ce2a4c99bd25e",
            "value": "model.safetensors: 100%"
          }
        },
        "3679731329f44ad7bf637b5d31f4be6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10c89f762844869a88a830083c56e4c",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d334a22e446e4163b7f636d14074cc3f",
            "value": 988097824
          }
        },
        "62cda8c7dd9142c6b96c473ac6058635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0bdaf5925b470090b360f6b251de64",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b7b5499ef74fa3bc8d93ecf2dd0c17",
            "value": " 988M/988M [00:05&lt;00:00, 220MB/s]"
          }
        },
        "2ed62e930b434604b3b70052a3fa281a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81917d44f2ee4574a883680a02dbebdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb48070cb394598ae8ce2a4c99bd25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c10c89f762844869a88a830083c56e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d334a22e446e4163b7f636d14074cc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed0bdaf5925b470090b360f6b251de64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b7b5499ef74fa3bc8d93ecf2dd0c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e816e24cee4ff38506fbdf561c6590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6a9bdbb46446de9079d842a504a1f3",
              "IPY_MODEL_c9e0950a53584ce1951c6494a7320453",
              "IPY_MODEL_fbed3d31eed2479d99a210079d7bfed6"
            ],
            "layout": "IPY_MODEL_551bf3ec955842aeaf1639d655443014"
          }
        },
        "ab6a9bdbb46446de9079d842a504a1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934bb4b2d4b0413ab483e0b9e01136a0",
            "placeholder": "​",
            "style": "IPY_MODEL_df4728374af74700a8ff70831fe2dca4",
            "value": "generation_config.json: 100%"
          }
        },
        "c9e0950a53584ce1951c6494a7320453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4094d731df84cffacbc7cd6efdcbde9",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3358f72568ea45ca872bd2b52f2341e8",
            "value": 242
          }
        },
        "fbed3d31eed2479d99a210079d7bfed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4afc073e2de545e884cf65c36b775f9b",
            "placeholder": "​",
            "style": "IPY_MODEL_d31eab4229834d8f831903d179ae6e7f",
            "value": " 242/242 [00:00&lt;00:00, 26.8kB/s]"
          }
        },
        "551bf3ec955842aeaf1639d655443014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934bb4b2d4b0413ab483e0b9e01136a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4728374af74700a8ff70831fe2dca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4094d731df84cffacbc7cd6efdcbde9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3358f72568ea45ca872bd2b52f2341e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4afc073e2de545e884cf65c36b775f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31eab4229834d8f831903d179ae6e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889f4b26d3674035bd2c07415a2458f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_630a4949057e41b6a21ec980bd8f6a8a",
              "IPY_MODEL_c4fef17f02974fbcbfa74c59d01693ea",
              "IPY_MODEL_f08fb3b79db5473f91d4d3ef805f94db"
            ],
            "layout": "IPY_MODEL_3afa7fbdeb744332a480b0d4dc935007"
          }
        },
        "630a4949057e41b6a21ec980bd8f6a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8f769d56e64800940de8712aed0f6d",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5cc69e12754297b53a19464c59ed45",
            "value": "Map: 100%"
          }
        },
        "c4fef17f02974fbcbfa74c59d01693ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2efcc9b9245c4e8b888593eefd276936",
            "max": 2079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c48b0fff3c5469e9e1747373d8432ec",
            "value": 2079
          }
        },
        "f08fb3b79db5473f91d4d3ef805f94db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381099b81c22414ba23b8215fa9dc3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_960e4bb6dec54e88a2ad10004ac94886",
            "value": " 2079/2079 [00:00&lt;00:00, 3277.38 examples/s]"
          }
        },
        "3afa7fbdeb744332a480b0d4dc935007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8f769d56e64800940de8712aed0f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5cc69e12754297b53a19464c59ed45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2efcc9b9245c4e8b888593eefd276936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c48b0fff3c5469e9e1747373d8432ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381099b81c22414ba23b8215fa9dc3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "960e4bb6dec54e88a2ad10004ac94886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ae447e0e2d341b889b671bf0a79fbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c40f9fd254a9496e9a7db2fd038fef45",
              "IPY_MODEL_35001240c8b549c1bd61ed2dea1b18c8",
              "IPY_MODEL_6a576816b3e24270955cafcf7ca41d00"
            ],
            "layout": "IPY_MODEL_daf6008760884f9cb44f10bbb624f676"
          }
        },
        "c40f9fd254a9496e9a7db2fd038fef45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd5ed3a214f4a8b847e21eb4960f5f2",
            "placeholder": "​",
            "style": "IPY_MODEL_4589eb432cd04b4eb6c0ffa6a5c28b82",
            "value": "Map: 100%"
          }
        },
        "35001240c8b549c1bd61ed2dea1b18c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dd1726b5fe24309b338f31844941dab",
            "max": 231,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc1d62a81a8e4edd90e074d90854ea77",
            "value": 231
          }
        },
        "6a576816b3e24270955cafcf7ca41d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3bf4a5253704adeb8e4229dacb5dcea",
            "placeholder": "​",
            "style": "IPY_MODEL_3b5a0cd46195462daab434f7d8e0ff8a",
            "value": " 231/231 [00:00&lt;00:00, 3180.50 examples/s]"
          }
        },
        "daf6008760884f9cb44f10bbb624f676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd5ed3a214f4a8b847e21eb4960f5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4589eb432cd04b4eb6c0ffa6a5c28b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dd1726b5fe24309b338f31844941dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1d62a81a8e4edd90e074d90854ea77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3bf4a5253704adeb8e4229dacb5dcea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5a0cd46195462daab434f7d8e0ff8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9077938685e147cbbad64cafab93501c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65208b490bf44bffbc6417438b74343e",
              "IPY_MODEL_aa1c5ab1624549bc8bc14abce6eda316",
              "IPY_MODEL_976927f381134d4086756d5d1be5c49b"
            ],
            "layout": "IPY_MODEL_8780e6c909354acabee6baaf2e56191d"
          }
        },
        "65208b490bf44bffbc6417438b74343e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b9d784e6e94c7c8f0dfbbb27980ab9",
            "placeholder": "​",
            "style": "IPY_MODEL_9b44c117200b4f3a84607e5cc0593631",
            "value": "config.json: 100%"
          }
        },
        "aa1c5ab1624549bc8bc14abce6eda316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9030305a422c4069ba4a3875ea0f7db3",
            "max": 659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_934a68a81ddc4601a962f4184ff39929",
            "value": 659
          }
        },
        "976927f381134d4086756d5d1be5c49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25932f71fa440adb3e949f00da79efd",
            "placeholder": "​",
            "style": "IPY_MODEL_41de536d75744495ac1a8f8d2a0ce8a6",
            "value": " 659/659 [00:00&lt;00:00, 74.1kB/s]"
          }
        },
        "8780e6c909354acabee6baaf2e56191d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b9d784e6e94c7c8f0dfbbb27980ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b44c117200b4f3a84607e5cc0593631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9030305a422c4069ba4a3875ea0f7db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934a68a81ddc4601a962f4184ff39929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f25932f71fa440adb3e949f00da79efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41de536d75744495ac1a8f8d2a0ce8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd308fe2c44b4795b5c2b753da93fc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ac16c61b3f469881407bba72a45cdf",
              "IPY_MODEL_350b2a08239f4e5780cc4d43e6b0960f",
              "IPY_MODEL_1ba49290a4f149339ef061fcc0a7992f"
            ],
            "layout": "IPY_MODEL_92d5b3fd7a66482d9184a75d0de69c23"
          }
        },
        "23ac16c61b3f469881407bba72a45cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dce531ed97447ed818dd53c7d93e020",
            "placeholder": "​",
            "style": "IPY_MODEL_c59af4da09204ddb8c4973a40d43247d",
            "value": "model.safetensors: 100%"
          }
        },
        "350b2a08239f4e5780cc4d43e6b0960f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9f1800d9754cdc8d24d763b8bbbd98",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26d0f02c364144248c113408a9f49135",
            "value": 988097824
          }
        },
        "1ba49290a4f149339ef061fcc0a7992f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a7bcdfedf943a9ba0f6c88e897d7d6",
            "placeholder": "​",
            "style": "IPY_MODEL_15cfa5bd0d5548d9ba6f51a2022cebf1",
            "value": " 988M/988M [00:02&lt;00:00, 436MB/s]"
          }
        },
        "92d5b3fd7a66482d9184a75d0de69c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dce531ed97447ed818dd53c7d93e020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59af4da09204ddb8c4973a40d43247d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9f1800d9754cdc8d24d763b8bbbd98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d0f02c364144248c113408a9f49135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49a7bcdfedf943a9ba0f6c88e897d7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cfa5bd0d5548d9ba6f51a2022cebf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a07eff9134bf47dea8dca28ff8419c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c286393695c40f7a69068f254d7c4c9",
              "IPY_MODEL_05e2e9c868c64ae3acad8e34a7cb9dac",
              "IPY_MODEL_60ccd06e4cd2470a9176778312a5b968"
            ],
            "layout": "IPY_MODEL_030623b1199b47e79b8dbc6b47c6d1ca"
          }
        },
        "6c286393695c40f7a69068f254d7c4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13770f1781b4bb188924ca57c0f8227",
            "placeholder": "​",
            "style": "IPY_MODEL_de1f23f0a47745deae0da1150b7b6db6",
            "value": "generation_config.json: 100%"
          }
        },
        "05e2e9c868c64ae3acad8e34a7cb9dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc6b44fef2b498090db87ade9546077",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_941370c5b34b4d40b1fa5a468485d779",
            "value": 242
          }
        },
        "60ccd06e4cd2470a9176778312a5b968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb465e6c44048cdb378c1da6973a6e1",
            "placeholder": "​",
            "style": "IPY_MODEL_766be20ab09d47dd8fe953866ac8dadd",
            "value": " 242/242 [00:00&lt;00:00, 31.4kB/s]"
          }
        },
        "030623b1199b47e79b8dbc6b47c6d1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d13770f1781b4bb188924ca57c0f8227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1f23f0a47745deae0da1150b7b6db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dc6b44fef2b498090db87ade9546077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941370c5b34b4d40b1fa5a468485d779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffb465e6c44048cdb378c1da6973a6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766be20ab09d47dd8fe953866ac8dadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}