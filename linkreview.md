# Link Review

-------

> Articles "Self-Play Fine-Tuning Converts ...", "Self-play fine-tuning of diffusion ...", "Self-Play Preference Optimization ..." were written by the same team. 


| Topic                 | Title                                                                                                                                   | Year | Authors             | Paper                                                                                                                           | Code                                                                      | Opinion                                                                             |
|:----------------------|:----------------------------------------------------------------------------------------------------------------------------------------|-----:|:--------------------|:--------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------|:------------------------------------------------------------------------------------|
| Main article          | Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models                                                           | 2024 | Zixiang Chen et al. | [arXiv](https://arxiv.org/abs/2401.01335), [OpenReview](https://openreview.net/forum?id=O4cHTxW9BS)                             | [Git](https://github.com/uclaml/SPIN)                                     | TODO                                                                                |
|                       | Self-play fine-tuning of diffusion models for text-to-image generation                                                                  | 2025 | Huizhuo Yuan et al. | [NeurIPS](https://papers.nips.cc/paper_files/paper/2024/hash/860c1c657deafe09f64c013c2888bd7b-Abstract-Conference.html)         | [Git](https://github.com/uclaml/SPIN-Diffusion)                           | Applicaiton (specification) of SPIN                                                 |
| Competitor            | Direct Preference Optimization: Your Language Model is Secretly a Reward Model                                                          | 2023 | Rafailov et al.     | [NeurIPS](https://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html)         | TODO                                                                      | TODO                                                                                |
|                       | Some things are more cringe than others: Preference opti- mization with the pairwise cringe loss.                                       | 2023 | Jing Xu et al.      | [arXiv](https://arxiv.org/abs/2312.16682)                                                                                       | TODO                                                                      | "Iterative" DPO                                                                     |
|                       | Self-Rewarding Language Models                                                                                                          | 2024 | Jing Xu et al.      | [OpenReview](https://openreview.net/forum?id=0NphYCmgua)                                                                        | TODO                                                                      | TODO                                                                                |
|                       | Self-Play Preference Optimization for Language Model Alignment                                                                          | 2024 | Yue Wu et al.       | [arXiv](https://arxiv.org/abs/2405.00675)                                                                                       | [Git](https://github.com/uclaml/SPPO)                                     | Self-play DPO, written by the team of SPIN's authors                                |
|                       | The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models           | 2025 | Ke ji et al         | [arXiv](https://arxiv.org/abs/2503.02875)                                                                                       | TODO                                                                      | New and questionable article, but UPFT doesn't need labeled data, as it was claimed |
| Supporting article    | LORA: LOW-RANK ADAPTATION OF LARGE LAN- GUAGE MODELS                                                                                    | 2021 | Edward Hu et al.    | [OpenReview](https://openreview.net/forum?id=nZeVKeeFYf9)                                                                       | [Git](https://github.com/microsoft/LoRA)                                  | TODO                                                                                |
| Additional literature | ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search                                                                     | 2024 | Dan Zhang et al.    | [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/hash/76ec4dc30e9faaf0e4b6093eaa377218-Abstract-Conference.html) | [Site](https://rest-mcts.github.io)                                       | Combination of RL and self-play approaches                                          |
| Model Report          | Qwen2.5-1M Technical Report                                                                                                             | 2025 | Yang An et al.      | [arXiv](https://arxiv.org/abs/2501.15383)                                                                                       | TODO                                                                      | TODO                                                                                |

------

## Datasets


| Title      | Link                                                                          | Description |
|:-----------|:------------------------------------------------------------------------------|:------------|
| GSM8K      | [HuggingFace](https://huggingface.co/datasets/openai/gsm8k)                   | TODO        |
| Hellaswag  | [HuggingFace](https://huggingface.co/datasets/Rowan/hellaswag)                | TODO        |
| Winogrande | [AllenAI](https://leaderboard.allenai.org/winogrande/submissions/get-started) | TODO        |
| MMLU-PRO   | [Git](https://github.com/TIGER-AI-Lab/MMLU-Pro)                               | TODO        |
| MMLU       | [HuggingFace](https://huggingface.co/datasets/lukaemon/mmlu)                  | TODO        |

